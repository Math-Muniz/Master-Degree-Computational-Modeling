{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mw0-kmUEjicH",
        "aIUcAyY9dz5p",
        "kC1sa1aUxPmz",
        "_k-D-IWz84ot",
        "qNAOVi0nZlxY",
        "VqcCkBB4FqmO",
        "IhALXh6BFjnO",
        "mB6ly0MdFly1",
        "-p8VImlCmfjb",
        "ErGmJf4-bQ80",
        "aoDqlJgiaGjh",
        "O9wllLokD7n8",
        "2Pf1VQNtaI89"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Universidade Federal de Juiz de Fora\n",
        "\n",
        "## Aluno: Matheus Muniz Damasco\n",
        "\n",
        "## Professor: Jairo Francisco de Souza\n",
        "\n",
        "## Matéria: Tópicos Especiais em Aplicações da Computação\n"
      ],
      "metadata": {
        "id": "4Dsfb8Bz-CD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trabalho 2: Criando modelo de linguagem\n",
        "\n",
        "**Objetivos**\n",
        "\n",
        "Neste trabalho, nosso objetivo é que o aluno faça uma prática com treinamento de modelos de linguagem usando ferramentas já existentes. A ideia é que seja realizado um autoaprendizado, fomentando a discussão e o aprendizado através da experimentação.\n",
        "\n",
        "**Organização**\n",
        "\n",
        "Você irá trabalhar com o SRILM (http://www.speech.sri.com/projects/srilm/). Você deve fazer um relatório explicando os detalhes dos seus experimentos, com passo a passo de cada comando utilizado e análises de cada resultado, além de breve explicação dos métodos utilizados (métodos de descontos – smoothing –, backoffs, etc).\n",
        "\n",
        "**Metodologia**\n",
        "\n",
        "Para os experimentos, caberá a você determinar sua base de treinamento e sua base de testes. Recomenda-se o uso de bases grandes o suficiente para obter resultados satisfatórios. Existem bases\n",
        "de treinamento disponíveis na web (Google ngram, Yahoo Labs ngram, bases como o Bosque, Floresta Sintactica e Amazonia para o português ou até mesmo textos da wikipedia que podem ser coletados via\n",
        "Dbpedia).\n",
        "\n",
        "**Experimentos a serem realizados**\n",
        "\n",
        "Neste trabalho, espera-se que o aluno se debruce sobre as formas de treinamento, problemas que podem surgir e analisar os dados que estão sendo gerados (nem sempre números maiores/menores são bons, certo?).\n",
        "\n",
        "**Minimamente, alguns tipos de análise devem ser feitas:**\n",
        "\n",
        "• Usar métodos intrínsecos de avaliação: (1) melhorar perplexidade, adotar normalizações no texto, inserção ou remoção de textos na base de treinamento, etc para alcançar melhores valores de perplexidade; (2) contagem de ngrams singletons: quantidade de ngrams com contagem igual a 1 (quanto mais, tende a ser pior); (3) quantidade de OOVs.\n",
        "\n",
        "• Avaliação empírica I: no seu conjunto de testes, coloque frases que estão corretamente escritas e frases que não fazem sentido. O objetivo do teu LM é ser capaz de classificar corretamente\n",
        "frases bem escritas e frases mal escritas. Calcular acurácia do teu LM nessa base de testes.\n",
        "\n",
        "• Avaliação empírica II: para avaliar o quão especializado teu LM está, utilize o método de visualização de Shannon para gerar frases com teu LM. Não sei se existe uma ferramenta própria pra isso. Imagino que você terá que criar um algoritmo para gerar essa visualização do teu LM (mas o método é bem simples). Permita que a frase seja iniciada aleatoriamente ou através de\n",
        "um input de texto (primeiras palavras da frase).\n",
        "\n",
        "• Realizar experimentos com teu modelo alterando as formas de generalização do modelo. Testar, necessariamente: (1) interpolação; (2) backoff; (3) diferentes métodos de suavização. Não se preocupe, essas ferramentas já lhe oferecem os métodos prontos. Mas é necessário entendê-los. Tente usar um stupid backoff, se possível. Explore os métodos de desconto disponíveis (K-ney, WB, etc).\n",
        "\n",
        "• Extra: um bom LM é aquele onde o seu P(W) é o mais alto para uma frase W que faça sentido para o LM. Como você poderia usar um LM como classificador? Crie um pequeno script que permita classificar uma frase em, digamos, esporte x música ou poesia x prosa, etc."
      ],
      "metadata": {
        "id": "M3UjGlLpcPu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação\n",
        "\n",
        "Foi feita a instalação do [SRILM](http://www.speech.sri.com/projects/srilm/download.html) usando o WSL Ubuntu que foi instalado via Windows PowerShell."
      ],
      "metadata": {
        "id": "CiBgye9ad3vJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Escolhido:\n",
        "\n",
        "Foi escolhido o Dataset 'árvores deitadas' da lista 'Parte do\n",
        "CETEMPúblico' com o formato comprimido contido no [link](https://www.linguateca.pt/floresta/corpus.html#download)."
      ],
      "metadata": {
        "id": "Yb7DXlWfdbqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bibliotecas Usadas"
      ],
      "metadata": {
        "id": "mw0-kmUEjicH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "import subprocess\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xAkfifY1jm5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analise do Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "aIUcAyY9dz5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Verificar o Conteúdo do Corpus\n",
        "\n",
        "Input:\n",
        "\n",
        "```\n",
        "head Bosque_CP_8.0.ad.txt\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "<ext n=1 sec=clt sem=92b>\n",
        "\n",
        "<t>\n",
        "<s>\n",
        "\n",
        "SOURCE: CETEMPblico n=1 sec=clt sem=92b\n",
        "CP1-1 Um revivalismo refrescante\n",
        "A1\n",
        "UTT:np\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "5Oyr0tlnwz1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Limpar, Normalizar e Ajustar nosso Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "kC1sa1aUxPmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se o arquivo está disponível no caminho correto\n",
        "!ls /content/"
      ],
      "metadata": {
        "id": "p3gRePuT1Q7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar o tokenizer (apenas uma vez)\n",
        "nltk.download('punkt')\n",
        "# Definir a seed\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "pSf8A9rZMI8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrir o arquivo original para leitura\n",
        "with open('/content/Bosque_CP_8.0.ad.txt', 'r', encoding='ISO-8859-1') as original_file:\n",
        "    content = original_file.readlines()\n",
        "\n",
        "# Remover tags <t>, <p> e <s>\n",
        "content_cleaned = [re.sub(r'</?[stp]>', '', line) for line in content]\n",
        "\n",
        "# Remover 'A1', 'A2' e 'A3' de cada linha\n",
        "for i in range(1, 4):\n",
        "    content_cleaned = [re.sub(fr'\\bA{i}\\b', '', line) for line in content_cleaned]\n",
        "\n",
        "# Filtrar linhas que NÃO começam com palavras desnecessárias\n",
        "content_cleaned = [\n",
        "    line.strip() for line in content_cleaned\n",
        "    if not line.startswith(('SOURCE', '=', 'UTT', 'STA', 'QUE', 'EXC'))\n",
        "]\n",
        "\n",
        "# Remover variações de <ext ...> e </ext>\n",
        "content_cleaned = [re.sub(r'<\\/?ext\\b[^>]*>', '', line) for line in content_cleaned]\n",
        "\n",
        "# Remover identificadores 'CPX-Y'\n",
        "content_cleaned = [re.sub(r'^CP\\d+-\\d+\\s*', '', line) for line in content_cleaned]\n",
        "\n",
        "# Substituir « e » por strings vazias e limpar símbolos\n",
        "content_cleaned = [line.replace('«', '').replace('»', '')\n",
        "                  .replace('&&', '').replace('--', '').replace('X:x', '')\n",
        "                  .replace('...', '').replace('-', ' ')\n",
        "                  for line in content_cleaned]\n",
        "\n",
        "# Remover linhas vazias\n",
        "content_cleaned = [line for line in content_cleaned if line]\n",
        "# Colocar o texto para minusculo\n",
        "content_cleaned = [line.lower() for line in content_cleaned]\n",
        "# Removendo a pontuação\n",
        "content_cleaned = [line.translate(str.maketrans('', '', string.punctuation)) for line in content_cleaned]\n",
        "\n",
        "# Tokenizar cada sentença e adicionar <s> e </s> corretamente\n",
        "tokenized_sentences = [\n",
        "    f\"<s> {' '.join(nltk.word_tokenize(line))} </s>\"\n",
        "    for line in content_cleaned\n",
        "]\n",
        "\n",
        "# Remover duplicações de tags <s> e </s> (se existirem)\n",
        "tokenized_sentences = [\n",
        "    re.sub(r'<s>\\s*</s>', '', line) for line in tokenized_sentences\n",
        "]\n",
        "\n",
        "# Salvar o corpus limpo e tokenizado em corpus_final.txt\n",
        "with open('corpus_final.txt', 'w', encoding='utf-8') as new_file:\n",
        "    new_file.write('\\n'.join(tokenized_sentences) + '\\n')\n",
        "\n",
        "print(\"Arquivo copiado e limpo com sucesso para 'corpus_final.txt'.\")"
      ],
      "metadata": {
        "id": "OaL2rL4bIQ8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Dividir nosso Dataset Filtrado em Treino e Teste"
      ],
      "metadata": {
        "id": "_k-D-IWz84ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrir o arquivo com o corpus completo\n",
        "with open('corpus_final.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Definir a proporção de treino e teste\n",
        "train_ratio = 0.7\n",
        "train_size = int(len(lines) * train_ratio)\n",
        "\n",
        "# Embaralhar as sentenças para garantir aleatoriedade\n",
        "random.shuffle(lines)\n",
        "\n",
        "# Dividir o corpus\n",
        "train_data = lines[:train_size]\n",
        "test_data = lines[train_size:]\n",
        "\n",
        "# Salvar os dados de treino e teste em arquivos separados\n",
        "with open('corpus_train.txt', 'w', encoding='utf-8') as train_file:\n",
        "    train_file.writelines(train_data)\n",
        "\n",
        "with open('corpus_test.txt', 'w', encoding='utf-8') as test_file:\n",
        "    test_file.writelines(test_data)\n",
        "\n",
        "print(\"Divisão do corpus em treino e teste concluída com sucesso.\")"
      ],
      "metadata": {
        "id": "KJ8AQeco89Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SRILM\n",
        "\n"
      ],
      "metadata": {
        "id": "kzZaX6kB9qK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos e Análises Intrínsecas:"
      ],
      "metadata": {
        "id": "qNAOVi0nZlxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unigrams"
      ],
      "metadata": {
        "id": "VqcCkBB4FqmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "ngram-count -text corpus_train.txt -order 1 -write corpus_tr1.count\n",
        "```\n",
        "\n",
        "```\n",
        "ngram-count -text corpus_train.txt -order 1 -addsmooth 0 -lm corpus_tr1.lm\n",
        "```\n",
        "\n",
        "#### Calculo de Perplexidade:\n",
        "```\n",
        "ngram -lm corpus_tr1.lm -ppl corpus_test.txt\n",
        "```\n",
        "Output:\n",
        "```\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "0 zeroprobs, logprob= -90987.42 ppl= 845.3804 ppl1= 1203.815\n",
        "```"
      ],
      "metadata": {
        "id": "bsS6tNw1EBcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contagem de N-grams Singletons:\n",
        "```\n",
        "ngram-count -read corpus_tr1.count -order 1 -write ngram_1gram.count\n",
        "```\n",
        "```\n",
        "grep -P '\\s+1$' ngram_1gram.count > ngram_singletons.count\n",
        "\n",
        "```\n",
        "Output:\n",
        "```\n",
        "...\n",
        "ronaldoà\t1\n",
        "castigados\t1\n",
        "badaladas\t1\n",
        "jan\t1\n",
        "específico\t1\n",
        "geneterapia\t1\n",
        "niall\t1\n",
        "eternidade\t1\n",
        "alertaram\t1\n",
        "charme\t1\n",
        "iniciada\t1\n",
        "536\t1\n",
        "erguidas\t1\n",
        "indisponibilidade\t1\n",
        "pintora\t1\n",
        "congestionada\t1\n",
        "ordenado\t1\n",
        "fixação\t1\n",
        "incubadora\t1\n",
        "celestial\t1\n",
        "xiaoping\t1\n",
        "convivas\t1\n",
        "deserdados\t1\n",
        "levem\t1\n",
        "dera\t1\n",
        "ditadura\t1\n",
        "preenche\t1\n",
        "149\t1\n",
        "erguer\t1\n",
        "elevadíssima\t1\n",
        "matadouros\t1\n",
        "gravíssima\t1\n",
        "desmobilizado\t1\n",
        "descuidos\t1\n",
        "endereços\t1\n",
        "sacchi\t1\n",
        "nortenha\t1\n",
        "tornam\t1\n",
        "bénard\t1\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "3oJJIihSK3Ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contagem de OOVs (Out-of-Vocabulary Words):\n",
        "\n",
        "```\n",
        "ngram -lm corpus_tr1.lm -ppl corpus_test.txt -debug 2\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "...\n",
        "<s> por si sós aos numerosos pequenos investidores que não estão incluídos nos 50 cabe uma fatia de 25 milhões de contos </s>\n",
        "        p( por | <s> )  = [1gram] 0.006947123 [ -2.158195 ]\n",
        "        p( si | por ...)        = [1gram] 0.0001565208 [ -3.805428 ]\n",
        "        p( <unk> | si ...)      = [OOV] 0 [ -inf ]\n",
        "        p( aos | <unk> ...)     = [1gram] 0.001480928 [ -2.829466 ]\n",
        "        p( <unk> | aos ...)     = [OOV] 0 [ -inf ]\n",
        "        p( pequenos | <unk> ...)        = [1gram] 0.0001324408 [ -3.877978 ]\n",
        "        p( investidores | pequenos ...)         = [1gram] 7.224036e-05 [ -4.14122 ]\n",
        "        p( que | investidores ...)      = [1gram] 0.02535636 [ -1.595913 ]\n",
        "        p( não | que ...)       = [1gram] 0.00740464 [ -2.130496 ]\n",
        "        p( estão | não ...)     = [1gram] 0.0006862842 [ -3.163496 ]\n",
        "        p( incluídos | estão ...)       = [1gram] 1.204007e-05 [ -4.919371 ]\n",
        "        p( nos | incluídos ...)         = [1gram] 0.001962534 [ -2.707183 ]\n",
        "        p( 50 | nos ...)        = [1gram] 0.0001565208 [ -3.805428 ]\n",
        "        p( cabe | 50 ...)       = [1gram] 3.612021e-05 [ -4.44225 ]\n",
        "        p( uma | cabe ...)      = [1gram] 0.008741098 [ -2.058434 ]\n",
        "        p( fatia | uma ...)     = [1gram] 1.204007e-05 [ -4.919371 ]\n",
        "        p( de | fatia ...)      = [1gram] 0.04725731 [ -1.325531 ]\n",
        "        p( 25 | de ...)         = [1gram] 0.0002769217 [ -3.557643 ]\n",
        "        p( milhões | 25 ...)    = [1gram] 0.001011365 [ -2.995092 ]\n",
        "        p( de | milhões ...)    = [1gram] 0.04725731 [ -1.325531 ]\n",
        "        p( contos | de ...)     = [1gram] 0.001155846 [ -2.9371 ]\n",
        "        p( </s> | contos ...)   = [1gram] 0.04350078 [ -1.361503 ]\n",
        "1 sentences, 21 words, 2 OOVs\n",
        "0 zeroprobs, logprob= -60.05663 ppl= 1006.541 ppl1= 1448.356\n",
        "\n",
        "<s> p e porquê </s>\n",
        "        p( p | <s> )    = [1gram] 0.0002769217 [ -3.557643 ]\n",
        "        p( e | p ...)   = [1gram] 0.02418851 [ -1.616391 ]\n",
        "        p( porquê | e ...)      = [1gram] 4.81603e-05 [ -4.317311 ]\n",
        "        p( </s> | porquê ...)   = [1gram] 0.04350078 [ -1.361503 ]\n",
        "1 sentences, 3 words, 0 OOVs\n",
        "0 zeroprobs, logprob= -10.85285 ppl= 516.6684 ppl1= 4145.872\n",
        "\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "0 zeroprobs, logprob= -90987.42 ppl= 845.3804 ppl1= 1203.815\n",
        "```"
      ],
      "metadata": {
        "id": "RCEwbeJtK7Mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigrams"
      ],
      "metadata": {
        "id": "IhALXh6BFjnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "ngram-count -text corpus_train.txt -order 2 -write corpus_tr2.count\n",
        "```\n",
        "\n",
        "```\n",
        "ngram-count -text corpus_train.txt -order 2 -addsmooth 0 -lm corpus_tr2.lm\n",
        "\n",
        "```\n",
        "\n",
        "#### Calculo de Perplexidade:\n",
        "```\n",
        "ngram -lm corpus_tr2.lm -ppl corpus_test.txt\n",
        "```\n",
        "Output:\n",
        "```\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "12929 zeroprobs, logprob= -34346.51 ppl= 77.93711 ppl1= 117.0024\n",
        "```"
      ],
      "metadata": {
        "id": "K0MknzNFD8TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contagem de N-grams Singletons:\n",
        "```\n",
        "ngram-count -read corpus_tr2.count -order 2 -write ngram_2gram.count\n",
        "```\n",
        "```\n",
        "grep -P '\\s+1$' ngram_2gram.count > ngram_2singletons.count\n",
        "```\n",
        "Output:\n",
        "```\n",
        "...\n",
        "dessexuados\t1\n",
        "dessexuados black\t1\n",
        "queima </s>\t1\n",
        "veiga francisco\t1\n",
        "veiga simão\t1\n",
        "candidatar pela\t1\n",
        "candidatar </s>\t1\n",
        "moleculares\t1\n",
        "moleculares e\t1\n",
        "inenarrável\t1\n",
        "inenarrável caos\t1\n",
        "detectavam\t1\n",
        "detectavam sismos\t1\n",
        "alugada\t1\n",
        "alugada pelo\t1\n",
        "reduzidas devido\t1\n",
        "reduzidas </s>\t1\n",
        "fados até\t1\n",
        "alentejo assegurando\t1\n",
        "alentejo e\t1\n",
        "sese\t1\n",
        "sese seko\t1\n",
        "tanger\t1\n",
        "tanger sublinhou\t1\n",
        "deferíveis\t1\n",
        "deferíveis situações\t1\n",
        "dirigido por\t1\n",
        "dirigido pelo\t1\n",
        "dirigido a\t1\n",
        "dirigido e\t1\n",
        "restará\t1\n",
        "restará um\t1\n",
        "câmaras da\t1\n",
        "siza </s>\t1\n",
        "relevância\t1\n",
        "relevância para\t1\n",
        "acentuada\t1\n",
        "acentuada da\t1\n",
        "garagem\t1\n",
        "garagem particular\t1\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "P-HmmaY4L0q5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contagem de OOVs (Out-of-Vocabulary Words):\n",
        "\n",
        "```\n",
        "ngram -lm corpus_tr2.lm -ppl corpus_test.txt -debug 2\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "...\n",
        "<s> fantasmas preocupantes </s>\n",
        "        p( <unk> | <s> )        = [OOV] 0 [ -inf ]\n",
        "        p( <unk> | <unk> ...)   = [OOV] 0 [ -inf ]\n",
        "        p( </s> | <unk> ...)    = [1gram] 0.04350078 [ -1.361503 ]\n",
        "1 sentences, 2 words, 2 OOVs\n",
        "0 zeroprobs, logprob= -1.361503 ppl= 22.9881 ppl1= undefined\n",
        "\n",
        "<s> por si sós aos numerosos pequenos investidores que não estão incluídos nos 50 cabe uma fatia de 25 milhões de contos </s>\n",
        "        p( por | <s> )  = [2gram] 0.0102408 [ -1.989666 ]\n",
        "        p( si | por ...)        = [2gram] 0.005199302 [ -2.284055 ]\n",
        "        p( <unk> | si ...)      = [OOV] 0 [ -inf ]\n",
        "        p( aos | <unk> ...)     = [1gram] 0.001480928 [ -2.829466 ]\n",
        "        p( <unk> | aos ...)     = [OOV] 0 [ -inf ]\n",
        "        p( pequenos | <unk> ...)        = [1gram] 0.0001324408 [ -3.877978 ]\n",
        "        p( investidores | pequenos ...)         = [1gram] 0 [ -inf ]\n",
        "        p( que | investidores ...)      = [1gram] 0 [ -inf ]\n",
        "        p( não | que ...)       = [2gram] 0.02943967 [ -1.531067 ]\n",
        "        p( estão | não ...)     = [2gram] 0.003252034 [ -2.487845 ]\n",
        "        p( incluídos | estão ...)       = [1gram] 0 [ -inf ]\n",
        "        p( nos | incluídos ...)         = [1gram] 0 [ -inf ]\n",
        "        p( 50 | nos ...)        = [1gram] 0 [ -inf ]\n",
        "        p( cabe | 50 ...)       = [1gram] 0 [ -inf ]\n",
        "        p( uma | cabe ...)      = [1gram] 0 [ -inf ]\n",
        "        p( fatia | uma ...)     = [1gram] 0 [ -inf ]\n",
        "        p( de | fatia ...)      = [1gram] 0 [ -inf ]\n",
        "        p( 25 | de ...)         = [1gram] 0 [ -inf ]\n",
        "        p( milhões | 25 ...)    = [2gram] 0.2608695 [ -0.5835766 ]\n",
        "        p( de | milhões ...)    = [2gram] 0.8333333 [ -0.07918125 ]\n",
        "        p( contos | de ...)     = [2gram] 0.0155414 [ -1.80851 ]\n",
        "        p( </s> | contos ...)   = [2gram] 0.3020833 [ -0.5198733 ]\n",
        "1 sentences, 21 words, 2 OOVs\n",
        "10 zeroprobs, logprob= -17.99122 ppl= 62.96828 ppl1= 99.77558\n",
        "\n",
        "<s> p e porquê </s>\n",
        "        p( p | <s> )    = [2gram] 0.005812338 [ -2.235649 ]\n",
        "        p( e | p ...)   = [2gram] 0.04347825 [ -1.361728 ]\n",
        "        p( porquê | e ...)      = [1gram] 0 [ -inf ]\n",
        "        p( </s> | porquê ...)   = [2gram] 0.7500001 [ -0.1249387 ]\n",
        "1 sentences, 3 words, 0 OOVs\n",
        "1 zeroprobs, logprob= -3.722316 ppl= 17.40892 ppl1= 72.637\n",
        "\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "12929 zeroprobs, logprob= -34346.51 ppl= 77.93711 ppl1= 117.0024\n",
        "```"
      ],
      "metadata": {
        "id": "He5cSArsL06Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trigrams"
      ],
      "metadata": {
        "id": "mB6ly0MdFly1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "ngram-count -text corpus_train.txt -order 3 -write corpus_tr3.count\n",
        "```\n",
        "\n",
        "```\n",
        "ngram-count -text corpus_train.txt -order 3 -addsmooth 0 -lm corpus_tr3.lm\n",
        "```\n",
        "\n",
        "#### Calculo de Perplexidade:\n",
        "```\n",
        "ngram -lm corpus_tr3.lm -ppl corpus_test.txt\n",
        "```\n",
        "Output:\n",
        "```\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "12929 zeroprobs, logprob= -33960.03 ppl= 74.20921 ppl1= 110.8977\n",
        "```"
      ],
      "metadata": {
        "id": "MTkPkts2ECbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contagem de N-grams Singletons:\n",
        "```\n",
        "ngram-count -read corpus_tr3.count -order 3 -write ngram_3gram.count\n",
        "```\n",
        "```\n",
        "grep -P '\\s+1$' ngram_3gram.count > ngram_3singletons.count\n",
        "```\n",
        "Output:\n",
        "```\n",
        "...\n",
        "identificação é\t1\n",
        "identificação é suficiente\t1\n",
        "identificação dos\t1\n",
        "identificação dos dois\t1\n",
        "identificação do\t1\n",
        "identificação do segundo\t1\n",
        "reeditado\t1\n",
        "reeditado numa\t1\n",
        "reeditado numa compilação\t1\n",
        "sócios vão\t1\n",
        "sócios vão poder\t1\n",
        "sócios franceses\t1\n",
        "sócios franceses do\t1\n",
        "sócios e\t1\n",
        "sócios e sete\t1\n",
        "sócios para\t1\n",
        "sócios para a\t1\n",
        "sócios quatro\t1\n",
        "sócios quatro disparos\t1\n",
        "sócios da\t1\n",
        "sócios da empresa\t1\n",
        "17h\t1\n",
        "17h </s>\t1\n",
        "coragem revelada\t1\n",
        "coragem revelada pelos\t1\n",
        "coragem de um\t1\n",
        "coragem de dar\t1\n",
        "coragem ideológica\t1\n",
        "coragem ideológica </s>\t1\n",
        "raffaelli\t1\n",
        "raffaelli o\t1\n",
        "raffaelli o mesmo\t1\n",
        "restany\t1\n",
        "restany e\t1\n",
        "restany e trabalhos\t1\n",
        "pensamos em\t1\n",
        "pensamos em mais\t1\n",
        "pensamos de\t1\n",
        "pensamos de forma\t1\n",
        "totally\t1\n",
        "totally kaos\t1\n",
        "totally kaos mais\t1\n",
        "erundina de\t1\n",
        "erundina de 58\t1\n",
        "erundina que\t1\n",
        "erundina que contrariou\t1\n",
        "15 metros\t1\n",
        "15 metros de\t1\n",
        "15 novas\t1\n",
        "15 novas experiências\t1\n",
        "15 de janeiro\t1\n",
        "15 de agosto\t1\n",
        "15 de julho\t1\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "-quvcQ_kO7bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contagem de OOVs (Out-of-Vocabulary Words):\n",
        "\n",
        "```\n",
        "ngram -lm corpus_tr3.lm -ppl corpus_test.txt -debug 2\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "...\n",
        "<s> por si sós aos numerosos pequenos investidores que não estão incluídos nos 50 cabe uma fatia de 25 milhões de contos </s>\n",
        "        p( por | <s> )  = [2gram] 0.0102408 [ -1.989666 ]\n",
        "        p( si | por ...)        = [2gram] 0.002173304 [ -2.662879 ]\n",
        "        p( <unk> | si ...)      = [OOV] 0 [ -inf ]\n",
        "        p( aos | <unk> ...)     = [1gram] 0.001480928 [ -2.829466 ]\n",
        "        p( <unk> | aos ...)     = [OOV] 0 [ -inf ]\n",
        "        p( pequenos | <unk> ...)        = [1gram] 0.0001324408 [ -3.877978 ]\n",
        "        p( investidores | pequenos ...)         = [1gram] 0 [ -inf ]\n",
        "        p( que | investidores ...)      = [1gram] 0 [ -inf ]\n",
        "        p( não | que ...)       = [2gram] 0.02943967 [ -1.531067 ]\n",
        "        p( estão | não ...)     = [2gram] 0.00270508 [ -2.56782 ]\n",
        "        p( incluídos | estão ...)       = [1gram] 0 [ -inf ]\n",
        "        p( nos | incluídos ...)         = [1gram] 0 [ -inf ]\n",
        "        p( 50 | nos ...)        = [1gram] 0 [ -inf ]\n",
        "        p( cabe | 50 ...)       = [1gram] 0 [ -inf ]\n",
        "        p( uma | cabe ...)      = [1gram] 0 [ -inf ]\n",
        "        p( fatia | uma ...)     = [1gram] 0 [ -inf ]\n",
        "        p( de | fatia ...)      = [1gram] 0 [ -inf ]\n",
        "        p( 25 | de ...)         = [1gram] 0 [ -inf ]\n",
        "        p( milhões | 25 ...)    = [2gram] 0.2608695 [ -0.5835766 ]\n",
        "        p( de | milhões ...)    = [3gram] 0.8333333 [ -0.07918125 ]\n",
        "        p( contos | de ...)     = [3gram] 0.7285714 [ -0.1375279 ]\n",
        "        p( </s> | contos ...)   = [3gram] 0.2786885 [ -0.5548809 ]\n",
        "1 sentences, 21 words, 2 OOVs\n",
        "10 zeroprobs, logprob= -16.81404 ppl= 48.01803 ppl1= 73.82901\n",
        "\n",
        "<s> p e porquê </s>\n",
        "        p( p | <s> )    = [2gram] 0.005812338 [ -2.235649 ]\n",
        "        p( e | p ...)   = [2gram] 0.04260651 [ -1.370524 ]\n",
        "        p( porquê | e ...)      = [1gram] 0 [ -inf ]\n",
        "        p( </s> | porquê ...)   = [2gram] 0.7500001 [ -0.1249387 ]\n",
        "1 sentences, 3 words, 0 OOVs\n",
        "1 zeroprobs, logprob= -3.731112 ppl= 17.52685 ppl1= 73.37632\n",
        "\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "12929 zeroprobs, logprob= -33960.03 ppl= 74.20921 ppl1= 110.8977\n",
        "```"
      ],
      "metadata": {
        "id": "ntyeHDo0O1oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação Empírica I:"
      ],
      "metadata": {
        "id": "-p8VImlCmfjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algumas Frases Incorretas e Algumas sem sentidos achadas no Conjunto de Teste\n",
        "\n",
        "1. 'antes de mes parents e muito antes dos livros sida '\n",
        "2. 'foi sol de pouca dura '\n",
        "3. 'o beira mar a outra equipa da cidade de aveiro procedeu também no início desta semana à substituição do norte americano mike smith pelo seu compatriota deshon washington '\n",
        "4. 'este assunto aliás foi também discutido na ccpm que quinta feira efectuou a sua 27ª plenária após um interregno de 20 dias'\n",
        "\n",
        "### Calculo da Acurácia do LM:\n",
        "\n"
      ],
      "metadata": {
        "id": "ErGmJf4-bQ80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar as perplexidades\n",
        "perplexities = []\n",
        "\n",
        "# Ler as perplexidades do arquivo ppl_output.txt\n",
        "with open('ppl_output3.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        if 'ppl=' in line:\n",
        "            # Tente extrair o valor da perplexidade, ignorando valores 'undefined'\n",
        "            try:\n",
        "                perplexity = float(line.split('ppl=')[1].split()[0])\n",
        "                perplexities.append(perplexity)\n",
        "            except ValueError:\n",
        "                # Ignorar se houver 'undefined'\n",
        "                continue\n",
        "\n",
        "# Verificar se temos perplexidades válidas\n",
        "if perplexities:\n",
        "    # Calcular a mediana das perplexidades\n",
        "    mean_perplexity = np.mean(perplexities)\n",
        "\n",
        "    # Classificar as frases: 1 (correta) se perplexidade < media, 0 (incorreta) se perplexidade ≥ media\n",
        "    predictions = [1 if p < mean_perplexity else 0 for p in perplexities]\n",
        "\n",
        "    # Calcular a \"acurácia\" com base na divisão pela mediana\n",
        "    accuracy = sum(predictions) / len(predictions)\n",
        "\n",
        "    print(f\"Perplexidades válidas: {len(perplexities)}\")\n",
        "    print(f\"Média das perplexidades: {mean_perplexity}\")\n",
        "    print(f\"Acurácia (baseada na média): {accuracy}\")\n",
        "else:\n",
        "    print(\"Nenhuma perplexidade válida foi encontrada.\")"
      ],
      "metadata": {
        "id": "X-0yNowZjXVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A saída indica que:\n",
        "\n",
        "* Nos temos 1544 frases no conjunto de testes com perplexidades válidas.\n",
        "* A média das perplexidades é 255.013, o que é um ponto de referência para a nossa classificação.\n",
        "* Com base na média das perplexidades, sua acurácia foi calculada como 0.9307. Isso significa que de acordo com a minha suposição, cerca de 93% das frases têm perplexidades abaixo da média (sendo classificadas como \"corretas\").\n",
        "\n",
        "( Acredito que apos usar esse metodo e analisando algumas sentenças geradas cheguei a conclusão que ele não consegue apresentar uma boa noção do nosso modelo por que a média pode ser influenciada facilmente pelos Outliers. )"
      ],
      "metadata": {
        "id": "NfRFjnWpmBAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação empírica II:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aoDqlJgiaGjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shannon Visualization Method:\n",
        "\n",
        "Os passos para o metodo de visualização de Shannon são:\n",
        "\n",
        "▪ Escolha um bigrama aleatório $(<s>, w)$ de acordo com sua probabilidade\n",
        "\n",
        "▪ Agora escolha um bigrama aleatório $(w, x)$ de acordo com sua probabilidade\n",
        "\n",
        "▪ E assim por diante até escolhermos $</s>$\n",
        "\n",
        "▪ Então, junte as palavras para formar a frase"
      ],
      "metadata": {
        "id": "O9wllLokD7n8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1_WNyDJ177qNDAkTPBDCGCYw.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "sfxjl6UV_Pus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Modelo:\n",
        "```\n",
        "ngram-count -read corpus_tr2.count -order 2 -addsmooth 0 -lm corpus_tr2.lm\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S4sCq7Vw2z6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geração de 10 frases:\n",
        "\n",
        "```\n",
        "ngram -lm corpus_tr2.lm -gen 10\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3yk6pwCT8NIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_frase_shannon(modelo_lm, input_text=None):\n",
        "    if input_text:\n",
        "        frase = input_text.split()\n",
        "    else:\n",
        "        frase = ['<s>']\n",
        "\n",
        "    while True:\n",
        "        comando = [\n",
        "            'ngram',\n",
        "            '-lm', modelo_lm,\n",
        "            '-ppl', '-',\n",
        "            '-debug', '2'\n",
        "        ]\n",
        "        processo = subprocess.Popen(comando, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        stdout, _ = processo.communicate(input=\" \".join(frase) + \" \\n\")\n",
        "        palavras_previsao = []\n",
        "        for linha in stdout.split('\\n'):\n",
        "            match = re.search(r'p\\(\\s*(\\w+)', linha)\n",
        "            if match:\n",
        "                palavra = match.group(1)\n",
        "                palavras_previsao.append(palavra)\n",
        "\n",
        "        if not palavras_previsao:\n",
        "            print(\"Nenhuma palavra prevista, encerrando.\")\n",
        "            break\n",
        "        proxima_palavra = random.choice(palavras_previsao)\n",
        "        frase.append(proxima_palavra)\n",
        "        if proxima_palavra == '</s>':\n",
        "            break\n",
        "\n",
        "    return \" \".join(frase)\n",
        "\n",
        "modelo_lm = 'corpus_tr2.lm'\n",
        "input_text = input(\"Digite as primeiras palavras da frase (ou deixe em branco para aleatório): \").strip()\n",
        "if input_text:\n",
        "    frase_gerada = gerar_frase_shannon(modelo_lm, input_text)\n",
        "else:\n",
        "    frase_gerada = gerar_frase_shannon(modelo_lm)\n",
        "\n",
        "print(f\"A frase gerada é: {frase_gerada}\")"
      ],
      "metadata": {
        "id": "wMyum7J39KAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos:"
      ],
      "metadata": {
        "id": "2Pf1VQNtaI89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpolação:\n",
        "\n",
        "Para usarmos a interpolação só precisamos adicionar -interpolate na nossa função. Interpolação é uma técnica comum usada em modelos de n-gramas para calcular a probabilidade de uma palavra combinando probabilidades de diferentes ordens de n-gramas (unigrama, bigrama, trigramas, etc.). O conceito básico é criar uma nova probabilidade ponderando e combinando as probabilidades dos diferentes n-gramas.\n",
        "\n",
        "Inputs:\n",
        "```\n",
        "ngram-count -order 3 -text corpus_train.txt -lm corpus_tr3.lm -addsmooth 1 -interpolate\n",
        "```\n",
        "```\n",
        "ngram -lm corpus_tr3.lm -ppl corpus_test.txt\n",
        "```\n",
        "Output:\n",
        "```\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "0 zeroprobs, logprob= -100908.8 ppl= 1762.879 ppl1= 2608.968\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "MQ5xjFfbmPCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backoff:\n",
        "\n",
        "Quando usamos o 'Witten-Bell discounting' sem a opção -interpolate, temos a versão com backoff, que é implementada tomando $f(a_z)$ como sendo o mesmo que o $g(a_z)$ interpolado.\n",
        "\n",
        "Inputs:\n",
        "```\n",
        "ngram-count -order 3 -text corpus_train.txt -lm corpus_tr3.lm -wbdiscount\n",
        "```\n",
        "```\n",
        "ngram -lm corpus_tr3.lm -ppl corpus_test.txt\n",
        "```\n",
        "Output:\n",
        "```\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "0 zeroprobs, logprob= -83467.25 ppl= 484.3167 ppl1= 669.807\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ID0aeIomXqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Suavização:\n",
        "\n",
        "#### 1. Kneser-Ney Discounting (KND):\n",
        "Kneser-Ney Discounting é um dos métodos de suavização mais eficazes e amplamente utilizados em modelos de linguagem. Sua principal característica é melhorar a suavização em n-gramas raros, tornando o modelo mais robusto para palavras e combinações de palavras pouco frequentes.\n",
        "\n",
        "\n",
        "Inputs:\n",
        "```\n",
        "ngram-count -order 3 -text corpus_train.txt -lm corpus_tr3.lm -kndiscount\n",
        "```\n",
        "```\n",
        "ngram -lm corpus_tr3.lm -ppl corpus_test.txt\n",
        "```\n",
        "Output:\n",
        "```\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "0 zeroprobs, logprob= -83006.54 ppl= 468.0677 ppl1= 646.1771\n",
        "```\n",
        "#### 2. Ristad's Natural Discounting Law:\n",
        "Ristad’s Natural Discounting Law é um método de suavização proposto por Ristad que tenta modelar a suavização com base em princípios naturais de frequência e probabilidade. A suavização \"N-Discount\" redistribui a probabilidade de maneira a ajustar mais suavemente os n-gramas com base em uma função de probabilidade que se assemelha à forma como os humanos processam e lidam com frequências de palavras raras e frequentes.\n",
        "\n",
        "Inputs:\n",
        "```\n",
        "ngram-count -order 3 -text corpus_train.txt -lm corpus_tr3.lm -ndiscount\n",
        "```\n",
        "```\n",
        "ngram -lm corpus_tr3.lm -ppl corpus_test.txt\n",
        "```\n",
        "Output:\n",
        "```\n",
        "file corpus_test.txt: 1549 sentences, 33457 words, 3921 OOVs\n",
        "0 zeroprobs, logprob= -82878.51 ppl= 463.6495 ppl1= 639.7595\n",
        "```\n"
      ],
      "metadata": {
        "id": "rxTn7kXUmR-E"
      }
    }
  ]
}