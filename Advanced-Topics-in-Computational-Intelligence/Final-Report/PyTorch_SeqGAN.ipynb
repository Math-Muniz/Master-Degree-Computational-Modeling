{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSAtCAGcQgJP"
      },
      "source": [
        "**Prefácio:**\n",
        "\n",
        "**Implementação baseada no trabalho de:** ...\n",
        "\n",
        "**Os resultados deste trabalho são apresentados no artigo (se utilizado, consulte o trabalho a seguir):** ...\n",
        "\n",
        "**Amostras de dados:**\n",
        ">* Legendas de imagens em inglês da amostra de legendas de imagens do COCO\n",
        "* Poemas em russo do site stihi.ru\n",
        "\n",
        "**Descrição do trabalho:**\n",
        "> Neste trabalho, foram realizados a implementação, o treinamento e o teste de redes neurais para geração de textos curtos aleatórios. Redes neurais como LSTM e SeqGAN são utilizadas. A qualidade da geração de texto foi avaliada com base na métrica BLEU. Os seguintes exemplos de dados são usados ​​para treinamento e teste:\n",
        "* Legendas de imagens em inglês da coleção COCO Image Captions\n",
        "* Poemas em russo do site stihi.ru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBqFdGkPPxCg"
      },
      "source": [
        "Lista de todas as bibliotecas instaladas e suas versões"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAl5Uo2vP12W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3918a0-8a7d-456e-e149-867f637c42e0"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                            Version\n",
            "---------------------------------- -------------------\n",
            "absl-py                            1.4.0\n",
            "accelerate                         1.2.1\n",
            "aiohappyeyeballs                   2.4.4\n",
            "aiohttp                            3.11.11\n",
            "aiosignal                          1.3.2\n",
            "alabaster                          1.0.0\n",
            "albucore                           0.0.19\n",
            "albumentations                     1.4.20\n",
            "altair                             5.5.0\n",
            "annotated-types                    0.7.0\n",
            "anyio                              3.7.1\n",
            "argon2-cffi                        23.1.0\n",
            "argon2-cffi-bindings               21.2.0\n",
            "array_record                       0.6.0\n",
            "arviz                              0.20.0\n",
            "astropy                            6.1.7\n",
            "astropy-iers-data                  0.2025.1.20.0.32.27\n",
            "astunparse                         1.6.3\n",
            "atpublic                           4.1.0\n",
            "attrs                              24.3.0\n",
            "audioread                          3.0.1\n",
            "autograd                           1.7.0\n",
            "babel                              2.16.0\n",
            "backcall                           0.2.0\n",
            "beautifulsoup4                     4.12.3\n",
            "bigframes                          1.33.0\n",
            "bigquery-magics                    0.5.0\n",
            "bleach                             6.2.0\n",
            "blinker                            1.9.0\n",
            "blis                               0.7.11\n",
            "blosc2                             3.0.0\n",
            "bokeh                              3.6.2\n",
            "Bottleneck                         1.4.2\n",
            "bqplot                             0.12.44\n",
            "branca                             0.8.1\n",
            "CacheControl                       0.14.2\n",
            "cachetools                         5.5.1\n",
            "catalogue                          2.0.10\n",
            "certifi                            2024.12.14\n",
            "cffi                               1.17.1\n",
            "chardet                            5.2.0\n",
            "charset-normalizer                 3.4.1\n",
            "chex                               0.1.88\n",
            "clarabel                           0.9.0\n",
            "click                              8.1.8\n",
            "cloudpathlib                       0.20.0\n",
            "cloudpickle                        3.1.1\n",
            "cmake                              3.31.4\n",
            "cmdstanpy                          1.2.5\n",
            "colorcet                           3.1.0\n",
            "colorlover                         0.3.0\n",
            "colour                             0.1.5\n",
            "community                          1.0.0b1\n",
            "confection                         0.1.5\n",
            "cons                               0.4.6\n",
            "contourpy                          1.3.1\n",
            "cryptography                       43.0.3\n",
            "cuda-python                        12.2.1\n",
            "cudf-cu12                          24.10.1\n",
            "cufflinks                          0.17.3\n",
            "cupy-cuda12x                       12.2.0\n",
            "cvxopt                             1.3.2\n",
            "cvxpy                              1.6.0\n",
            "cycler                             0.12.1\n",
            "cyipopt                            1.5.0\n",
            "cymem                              2.0.11\n",
            "Cython                             3.0.11\n",
            "dask                               2024.10.0\n",
            "datascience                        0.17.6\n",
            "db-dtypes                          1.4.0\n",
            "dbus-python                        1.2.18\n",
            "debugpy                            1.8.0\n",
            "decorator                          4.4.2\n",
            "defusedxml                         0.7.1\n",
            "Deprecated                         1.2.15\n",
            "diffusers                          0.32.2\n",
            "distro                             1.9.0\n",
            "dlib                               19.24.2\n",
            "dm-tree                            0.1.8\n",
            "docker-pycreds                     0.4.0\n",
            "docstring_parser                   0.16\n",
            "docutils                           0.21.2\n",
            "dopamine_rl                        4.1.0\n",
            "duckdb                             1.1.3\n",
            "earthengine-api                    1.4.6\n",
            "easydict                           1.13\n",
            "editdistance                       0.8.1\n",
            "eerepr                             0.1.0\n",
            "einops                             0.8.0\n",
            "en-core-web-sm                     3.7.1\n",
            "entrypoints                        0.4\n",
            "et_xmlfile                         2.0.0\n",
            "etils                              1.11.0\n",
            "etuples                            0.3.9\n",
            "eval_type_backport                 0.2.2\n",
            "fastai                             2.7.18\n",
            "fastcore                           1.7.28\n",
            "fastdownload                       0.0.7\n",
            "fastjsonschema                     2.21.1\n",
            "fastprogress                       1.0.3\n",
            "fastrlock                          0.8.3\n",
            "filelock                           3.17.0\n",
            "firebase-admin                     6.6.0\n",
            "Flask                              3.1.0\n",
            "flatbuffers                        25.1.21\n",
            "flax                               0.10.2\n",
            "folium                             0.19.4\n",
            "fonttools                          4.55.5\n",
            "frozendict                         2.4.6\n",
            "frozenlist                         1.5.0\n",
            "fsspec                             2024.10.0\n",
            "future                             1.0.0\n",
            "gast                               0.6.0\n",
            "gcsfs                              2024.10.0\n",
            "GDAL                               3.6.4\n",
            "gdown                              5.2.0\n",
            "geemap                             0.35.1\n",
            "gensim                             4.3.3\n",
            "geocoder                           1.38.1\n",
            "geographiclib                      2.0\n",
            "geopandas                          1.0.1\n",
            "geopy                              2.4.1\n",
            "gin-config                         0.5.0\n",
            "gitdb                              4.0.12\n",
            "GitPython                          3.1.44\n",
            "glob2                              0.7\n",
            "google                             2.0.3\n",
            "google-ai-generativelanguage       0.6.15\n",
            "google-api-core                    2.19.2\n",
            "google-api-python-client           2.155.0\n",
            "google-auth                        2.27.0\n",
            "google-auth-httplib2               0.2.0\n",
            "google-auth-oauthlib               1.2.1\n",
            "google-cloud-aiplatform            1.74.0\n",
            "google-cloud-bigquery              3.25.0\n",
            "google-cloud-bigquery-connection   1.17.0\n",
            "google-cloud-bigquery-storage      2.27.0\n",
            "google-cloud-bigtable              2.28.1\n",
            "google-cloud-core                  2.4.1\n",
            "google-cloud-datastore             2.20.2\n",
            "google-cloud-firestore             2.19.0\n",
            "google-cloud-functions             1.19.0\n",
            "google-cloud-iam                   2.17.0\n",
            "google-cloud-language              2.16.0\n",
            "google-cloud-pubsub                2.25.0\n",
            "google-cloud-resource-manager      1.14.0\n",
            "google-cloud-storage               2.19.0\n",
            "google-cloud-translate             3.19.0\n",
            "google-colab                       1.0.0\n",
            "google-crc32c                      1.6.0\n",
            "google-genai                       0.3.0\n",
            "google-generativeai                0.8.4\n",
            "google-pasta                       0.2.0\n",
            "google-resumable-media             2.7.2\n",
            "googleapis-common-protos           1.66.0\n",
            "googledrivedownloader              0.4\n",
            "graphviz                           0.20.3\n",
            "greenlet                           3.1.1\n",
            "grpc-google-iam-v1                 0.14.0\n",
            "grpcio                             1.69.0\n",
            "grpcio-status                      1.62.3\n",
            "gspread                            6.1.4\n",
            "gspread-dataframe                  4.0.0\n",
            "gym                                0.25.2\n",
            "gym-notices                        0.0.8\n",
            "h11                                0.14.0\n",
            "h5netcdf                           1.4.1\n",
            "h5py                               3.12.1\n",
            "highspy                            1.9.0\n",
            "holidays                           0.65\n",
            "holoviews                          1.20.0\n",
            "html5lib                           1.1\n",
            "httpcore                           1.0.7\n",
            "httpimport                         1.4.0\n",
            "httplib2                           0.22.0\n",
            "httpx                              0.28.1\n",
            "huggingface-hub                    0.27.1\n",
            "humanize                           4.11.0\n",
            "hyperopt                           0.2.7\n",
            "ibis-framework                     9.2.0\n",
            "idna                               3.10\n",
            "imageio                            2.36.1\n",
            "imageio-ffmpeg                     0.6.0\n",
            "imagesize                          1.4.1\n",
            "imbalanced-learn                   0.13.0\n",
            "imgaug                             0.4.0\n",
            "immutabledict                      4.2.1\n",
            "importlib_metadata                 8.6.1\n",
            "importlib_resources                6.5.2\n",
            "imutils                            0.5.4\n",
            "inflect                            7.5.0\n",
            "iniconfig                          2.0.0\n",
            "intel-cmplr-lib-ur                 2025.0.4\n",
            "intel-openmp                       2025.0.4\n",
            "ipyevents                          2.0.2\n",
            "ipyfilechooser                     0.6.0\n",
            "ipykernel                          5.5.6\n",
            "ipyleaflet                         0.19.2\n",
            "ipyparallel                        8.8.0\n",
            "ipython                            7.34.0\n",
            "ipython-genutils                   0.2.0\n",
            "ipython-sql                        0.5.0\n",
            "ipytree                            0.2.2\n",
            "ipywidgets                         7.7.1\n",
            "itsdangerous                       2.2.0\n",
            "jax                                0.4.33\n",
            "jax-cuda12-pjrt                    0.4.33\n",
            "jax-cuda12-plugin                  0.4.33\n",
            "jaxlib                             0.4.33\n",
            "jeepney                            0.7.1\n",
            "jellyfish                          1.1.0\n",
            "jieba                              0.42.1\n",
            "Jinja2                             3.1.5\n",
            "jiter                              0.8.2\n",
            "joblib                             1.4.2\n",
            "jsonpatch                          1.33\n",
            "jsonpickle                         4.0.1\n",
            "jsonpointer                        3.0.0\n",
            "jsonschema                         4.23.0\n",
            "jsonschema-specifications          2024.10.1\n",
            "jupyter-client                     6.1.12\n",
            "jupyter-console                    6.1.0\n",
            "jupyter_core                       5.7.2\n",
            "jupyter-leaflet                    0.19.2\n",
            "jupyter-server                     1.24.0\n",
            "jupyterlab_pygments                0.3.0\n",
            "jupyterlab_widgets                 3.0.13\n",
            "kaggle                             1.6.17\n",
            "kagglehub                          0.3.6\n",
            "keras                              3.5.0\n",
            "keyring                            23.5.0\n",
            "kiwisolver                         1.4.8\n",
            "langchain                          0.3.15\n",
            "langchain-core                     0.3.31\n",
            "langchain-text-splitters           0.3.5\n",
            "langcodes                          3.5.0\n",
            "langsmith                          0.3.1\n",
            "language_data                      1.3.0\n",
            "launchpadlib                       1.10.16\n",
            "lazr.restfulclient                 0.14.4\n",
            "lazr.uri                           1.0.6\n",
            "lazy_loader                        0.4\n",
            "libclang                           18.1.1\n",
            "libcudf-cu12                       24.10.1\n",
            "librosa                            0.10.2.post1\n",
            "lightgbm                           4.5.0\n",
            "linkify-it-py                      2.0.3\n",
            "llvmlite                           0.43.0\n",
            "locket                             1.0.0\n",
            "logical-unification                0.4.6\n",
            "lxml                               5.3.0\n",
            "marisa-trie                        1.2.1\n",
            "Markdown                           3.7\n",
            "markdown-it-py                     3.0.0\n",
            "MarkupSafe                         3.0.2\n",
            "matplotlib                         3.10.0\n",
            "matplotlib-inline                  0.1.7\n",
            "matplotlib-venn                    1.1.1\n",
            "mdit-py-plugins                    0.4.2\n",
            "mdurl                              0.1.2\n",
            "miniKanren                         1.0.3\n",
            "missingno                          0.5.2\n",
            "mistune                            3.1.0\n",
            "mizani                             0.13.1\n",
            "mkl                                2025.0.1\n",
            "ml-dtypes                          0.4.1\n",
            "mlxtend                            0.23.3\n",
            "more-itertools                     10.5.0\n",
            "moviepy                            1.0.3\n",
            "mpmath                             1.3.0\n",
            "msgpack                            1.1.0\n",
            "multidict                          6.1.0\n",
            "multipledispatch                   1.0.0\n",
            "multitasking                       0.0.11\n",
            "murmurhash                         1.0.12\n",
            "music21                            9.3.0\n",
            "namex                              0.0.8\n",
            "narwhals                           1.23.0\n",
            "natsort                            8.4.0\n",
            "nbclassic                          1.2.0\n",
            "nbclient                           0.10.2\n",
            "nbconvert                          7.16.5\n",
            "nbformat                           5.10.4\n",
            "ndindex                            1.9.2\n",
            "nest-asyncio                       1.6.0\n",
            "networkx                           3.4.2\n",
            "nibabel                            5.3.2\n",
            "nltk                               3.9.1\n",
            "notebook                           6.5.5\n",
            "notebook_shim                      0.2.4\n",
            "numba                              0.60.0\n",
            "numexpr                            2.10.2\n",
            "numpy                              1.26.4\n",
            "nvidia-cublas-cu12                 12.1.3.1\n",
            "nvidia-cuda-cupti-cu12             12.1.105\n",
            "nvidia-cuda-nvcc-cu12              12.6.85\n",
            "nvidia-cuda-nvrtc-cu12             12.1.105\n",
            "nvidia-cuda-runtime-cu12           12.1.105\n",
            "nvidia-cudnn-cu12                  9.1.0.70\n",
            "nvidia-cufft-cu12                  11.0.2.54\n",
            "nvidia-curand-cu12                 10.3.2.106\n",
            "nvidia-cusolver-cu12               11.4.5.107\n",
            "nvidia-cusparse-cu12               12.1.0.106\n",
            "nvidia-nccl-cu12                   2.21.5\n",
            "nvidia-nvjitlink-cu12              12.6.85\n",
            "nvidia-nvtx-cu12                   12.1.105\n",
            "nvtx                               0.2.10\n",
            "nx-cugraph-cu12                    24.10.0\n",
            "oauth2client                       4.1.3\n",
            "oauthlib                           3.2.2\n",
            "openai                             1.59.9\n",
            "opencv-contrib-python              4.10.0.84\n",
            "opencv-python                      4.10.0.84\n",
            "opencv-python-headless             4.11.0.86\n",
            "openpyxl                           3.1.5\n",
            "opentelemetry-api                  1.16.0\n",
            "opentelemetry-sdk                  1.16.0\n",
            "opentelemetry-semantic-conventions 0.37b0\n",
            "opt_einsum                         3.4.0\n",
            "optax                              0.2.4\n",
            "optree                             0.14.0\n",
            "orbax-checkpoint                   0.6.4\n",
            "orjson                             3.10.15\n",
            "osqp                               0.6.7.post3\n",
            "packaging                          24.2\n",
            "pandas                             2.2.2\n",
            "pandas-datareader                  0.10.0\n",
            "pandas-gbq                         0.26.1\n",
            "pandas-stubs                       2.2.2.240909\n",
            "pandocfilters                      1.5.1\n",
            "panel                              1.5.5\n",
            "param                              2.2.0\n",
            "parso                              0.8.4\n",
            "parsy                              2.1\n",
            "partd                              1.4.2\n",
            "pathlib                            1.0.1\n",
            "patsy                              1.0.1\n",
            "peewee                             3.17.8\n",
            "peft                               0.14.0\n",
            "pexpect                            4.9.0\n",
            "pickleshare                        0.7.5\n",
            "pillow                             11.1.0\n",
            "pip                                24.1.2\n",
            "platformdirs                       4.3.6\n",
            "plotly                             5.24.1\n",
            "plotnine                           0.14.5\n",
            "pluggy                             1.5.0\n",
            "ply                                3.11\n",
            "polars                             1.9.0\n",
            "pooch                              1.8.2\n",
            "portpicker                         1.5.2\n",
            "preshed                            3.0.9\n",
            "prettytable                        3.12.0\n",
            "proglog                            0.1.10\n",
            "progressbar2                       4.5.0\n",
            "prometheus_client                  0.21.1\n",
            "promise                            2.3\n",
            "prompt_toolkit                     3.0.50\n",
            "propcache                          0.2.1\n",
            "prophet                            1.1.6\n",
            "proto-plus                         1.25.0\n",
            "protobuf                           4.25.5\n",
            "psutil                             5.9.5\n",
            "psycopg2                           2.9.10\n",
            "ptyprocess                         0.7.0\n",
            "py-cpuinfo                         9.0.0\n",
            "py4j                               0.10.9.7\n",
            "pyarrow                            17.0.0\n",
            "pyasn1                             0.6.1\n",
            "pyasn1_modules                     0.4.1\n",
            "pycocotools                        2.0.8\n",
            "pycparser                          2.22\n",
            "pydantic                           2.10.5\n",
            "pydantic_core                      2.27.2\n",
            "pydata-google-auth                 1.9.0\n",
            "pydot                              3.0.4\n",
            "pydotplus                          2.0.2\n",
            "PyDrive                            1.3.1\n",
            "PyDrive2                           1.21.3\n",
            "pyerfa                             2.0.1.5\n",
            "pygame                             2.6.1\n",
            "pygit2                             1.16.0\n",
            "Pygments                           2.18.0\n",
            "PyGObject                          3.42.1\n",
            "PyJWT                              2.10.1\n",
            "pylibcudf-cu12                     24.10.1\n",
            "pylibcugraph-cu12                  24.10.0\n",
            "pylibraft-cu12                     24.10.0\n",
            "pymc                               5.19.1\n",
            "pymystem3                          0.2.0\n",
            "pynvjitlink-cu12                   0.4.0\n",
            "pyogrio                            0.10.0\n",
            "Pyomo                              6.8.2\n",
            "PyOpenGL                           3.1.9\n",
            "pyOpenSSL                          24.2.1\n",
            "pyparsing                          3.2.1\n",
            "pyperclip                          1.9.0\n",
            "pyproj                             3.7.0\n",
            "pyshp                              2.3.1\n",
            "PySocks                            1.7.1\n",
            "pyspark                            3.5.4\n",
            "pytensor                           2.26.4\n",
            "pytest                             8.3.4\n",
            "python-apt                         0.0.0\n",
            "python-box                         7.3.2\n",
            "python-dateutil                    2.8.2\n",
            "python-louvain                     0.16\n",
            "python-slugify                     8.0.4\n",
            "python-utils                       3.9.1\n",
            "pytz                               2024.2\n",
            "pyviz_comms                        3.0.4\n",
            "PyYAML                             6.0.2\n",
            "pyzmq                              24.0.1\n",
            "qdldl                              0.1.7.post5\n",
            "ratelim                            0.1.6\n",
            "referencing                        0.36.1\n",
            "regex                              2024.11.6\n",
            "requests                           2.32.3\n",
            "requests-oauthlib                  1.3.1\n",
            "requests-toolbelt                  1.0.0\n",
            "requirements-parser                0.9.0\n",
            "rich                               13.9.4\n",
            "rmm-cu12                           24.10.0\n",
            "rpds-py                            0.22.3\n",
            "rpy2                               3.4.2\n",
            "rsa                                4.9\n",
            "safetensors                        0.5.2\n",
            "scikit-image                       0.25.0\n",
            "scikit-learn                       1.6.1\n",
            "scipy                              1.13.1\n",
            "scooby                             0.10.0\n",
            "scs                                3.2.7.post2\n",
            "seaborn                            0.13.2\n",
            "SecretStorage                      3.3.1\n",
            "Send2Trash                         1.8.3\n",
            "sentence-transformers              3.3.1\n",
            "sentencepiece                      0.2.0\n",
            "sentry-sdk                         2.20.0\n",
            "setproctitle                       1.3.4\n",
            "setuptools                         75.1.0\n",
            "shap                               0.46.0\n",
            "shapely                            2.0.6\n",
            "shellingham                        1.5.4\n",
            "simple-parsing                     0.1.7\n",
            "six                                1.17.0\n",
            "sklearn-compat                     0.1.3\n",
            "sklearn-pandas                     2.2.0\n",
            "slicer                             0.0.8\n",
            "smart-open                         7.1.0\n",
            "smmap                              5.0.2\n",
            "sniffio                            1.3.1\n",
            "snowballstemmer                    2.2.0\n",
            "soundfile                          0.13.0\n",
            "soupsieve                          2.6\n",
            "soxr                               0.5.0.post1\n",
            "spacy                              3.7.5\n",
            "spacy-legacy                       3.0.12\n",
            "spacy-loggers                      1.0.5\n",
            "Sphinx                             8.1.3\n",
            "sphinxcontrib-applehelp            2.0.0\n",
            "sphinxcontrib-devhelp              2.0.0\n",
            "sphinxcontrib-htmlhelp             2.1.0\n",
            "sphinxcontrib-jsmath               1.0.1\n",
            "sphinxcontrib-qthelp               2.0.0\n",
            "sphinxcontrib-serializinghtml      2.0.0\n",
            "SQLAlchemy                         2.0.37\n",
            "sqlglot                            25.6.1\n",
            "sqlparse                           0.5.3\n",
            "srsly                              2.5.1\n",
            "stanio                             0.5.1\n",
            "statsmodels                        0.14.4\n",
            "stringzilla                        3.11.3\n",
            "sympy                              1.13.1\n",
            "tables                             3.10.2\n",
            "tabulate                           0.9.0\n",
            "tbb                                2022.0.0\n",
            "tcmlib                             1.2.0\n",
            "tenacity                           9.0.0\n",
            "tensorboard                        2.17.1\n",
            "tensorboard-data-server            0.7.2\n",
            "tensorflow                         2.17.1\n",
            "tensorflow-datasets                4.9.7\n",
            "tensorflow-hub                     0.16.1\n",
            "tensorflow-io-gcs-filesystem       0.37.1\n",
            "tensorflow-metadata                1.16.1\n",
            "tensorflow-probability             0.24.0\n",
            "tensorstore                        0.1.71\n",
            "termcolor                          2.5.0\n",
            "terminado                          0.18.1\n",
            "text-unidecode                     1.3\n",
            "textblob                           0.17.1\n",
            "tf_keras                           2.17.0\n",
            "tf-slim                            1.1.0\n",
            "thinc                              8.2.5\n",
            "threadpoolctl                      3.5.0\n",
            "tifffile                           2025.1.10\n",
            "timm                               1.0.14\n",
            "tinycss2                           1.4.0\n",
            "tokenizers                         0.21.0\n",
            "toml                               0.10.2\n",
            "toolz                              0.12.1\n",
            "torch                              2.5.1+cu121\n",
            "torchaudio                         2.5.1+cu121\n",
            "torchsummary                       1.5.1\n",
            "torchvision                        0.20.1+cu121\n",
            "tornado                            6.3.3\n",
            "tqdm                               4.67.1\n",
            "traitlets                          5.7.1\n",
            "traittypes                         0.2.1\n",
            "transformers                       4.47.1\n",
            "triton                             3.1.0\n",
            "tweepy                             4.14.0\n",
            "typeguard                          4.4.1\n",
            "typer                              0.15.1\n",
            "types-pytz                         2024.2.0.20241221\n",
            "types-setuptools                   75.8.0.20250110\n",
            "typing_extensions                  4.12.2\n",
            "tzdata                             2025.1\n",
            "tzlocal                            5.2\n",
            "uc-micro-py                        1.0.3\n",
            "umf                                0.9.1\n",
            "uritemplate                        4.1.1\n",
            "urllib3                            2.3.0\n",
            "vega-datasets                      0.9.0\n",
            "wadllib                            1.3.6\n",
            "wandb                              0.19.4\n",
            "wasabi                             1.1.3\n",
            "wcwidth                            0.2.13\n",
            "weasel                             0.4.1\n",
            "webcolors                          24.11.1\n",
            "webencodings                       0.5.1\n",
            "websocket-client                   1.8.0\n",
            "websockets                         14.2\n",
            "Werkzeug                           3.1.3\n",
            "wheel                              0.45.1\n",
            "widgetsnbextension                 3.6.10\n",
            "wordcloud                          1.9.4\n",
            "wrapt                              1.17.2\n",
            "xarray                             2025.1.1\n",
            "xarray-einstats                    0.8.0\n",
            "xgboost                            2.1.3\n",
            "xlrd                               2.0.1\n",
            "xyzservices                        2025.1.0\n",
            "yarl                               1.18.3\n",
            "yellowbrick                        1.5\n",
            "yfinance                           0.2.52\n",
            "zipp                               3.21.0\n",
            "zstandard                          0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mRG9mlM3z69"
      },
      "source": [
        "Conexão no Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from math import ceil\n",
        "\n",
        "def prepare_generator_batch(samples, start_letter=0, gpu=False):\n",
        "    \"\"\"\n",
        "    Takes samples (a batch) and returns\n",
        "\n",
        "    Inputs: samples, start_letter, cuda\n",
        "        - samples: batch_size x seq_len (Tensor with a sample in each row)\n",
        "\n",
        "    Returns: inp, target\n",
        "        - inp: batch_size x seq_len (same as target, but with start_letter prepended)\n",
        "        - target: batch_size x seq_len (Variable same as samples)\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, seq_len = samples.size()\n",
        "\n",
        "    inp = torch.zeros(batch_size, seq_len)\n",
        "    target = samples\n",
        "    inp[:, 0] = start_letter\n",
        "    inp[:, 1:] = target[:, :seq_len-1]\n",
        "\n",
        "    inp = Variable(inp).type(torch.LongTensor)\n",
        "    target = Variable(target).type(torch.LongTensor)\n",
        "\n",
        "    if gpu:\n",
        "        inp = inp.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "    return inp, target\n",
        "\n",
        "\n",
        "def prepare_discriminator_data(pos_samples, neg_samples, gpu=False):\n",
        "    \"\"\"\n",
        "    Takes positive (target) samples, negative (generator) samples and prepares inp and target data for discriminator.\n",
        "\n",
        "    Inputs: pos_samples, neg_samples\n",
        "        - pos_samples: pos_size x seq_len\n",
        "        - neg_samples: neg_size x seq_len\n",
        "\n",
        "    Returns: inp, target\n",
        "        - inp: (pos_size + neg_size) x seq_len\n",
        "        - target: pos_size + neg_size (boolean 1/0)\n",
        "    \"\"\"\n",
        "\n",
        "    inp = torch.cat((pos_samples, neg_samples), 0).type(torch.LongTensor)\n",
        "    target = torch.ones(pos_samples.size()[0] + neg_samples.size()[0])\n",
        "    target[pos_samples.size()[0]:] = 0\n",
        "\n",
        "    # shuffle\n",
        "    perm = torch.randperm(target.size()[0])\n",
        "    target = target[perm]\n",
        "    inp = inp[perm]\n",
        "\n",
        "    inp = Variable(inp)\n",
        "    target = Variable(target)\n",
        "\n",
        "    if gpu:\n",
        "        inp = inp.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "    return inp, target\n",
        "\n",
        "\n",
        "def batchwise_sample(gen, num_samples, batch_size):\n",
        "    \"\"\"\n",
        "    Sample num_samples samples batch_size samples at a time from gen.\n",
        "    Does not require gpu since gen.sample() takes care of that.\n",
        "    \"\"\"\n",
        "\n",
        "    samples = []\n",
        "    for i in range(int(ceil(num_samples/float(batch_size)))):\n",
        "        samples.append(gen.sample(batch_size))\n",
        "\n",
        "    return torch.cat(samples, 0)[:num_samples]\n",
        "\n",
        "\n",
        "def batchwise_oracle_nll(gen, oracle, num_samples, batch_size, max_seq_len, start_letter=0, gpu=False):\n",
        "    s = batchwise_sample(gen, num_samples, batch_size)\n",
        "    oracle_nll = 0\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        inp, target = prepare_generator_batch(s[i:i+batch_size], start_letter, gpu)\n",
        "        oracle_loss = oracle.batchNLLLoss(inp, target) / max_seq_len\n",
        "        oracle_nll += oracle_loss.data.item()\n",
        "\n",
        "    return oracle_nll/(num_samples/batch_size)"
      ],
      "metadata": {
        "id": "HP7EKvf50RMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqRu97X9S9A9"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/'\n",
        "os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInBwn4iUsK7"
      },
      "source": [
        "Declarando parâmetros padrão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbtQOz8UUn0Q"
      },
      "source": [
        "from __future__ import print_function\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "DATASET = 'coco_image_captions'  # nome do conjunto de dados, lista de conjuntos de dados: ['stihi_ru', 'coco_image_captions']\n",
        "CUDA = True  # uso do cuda (gpu/tpu): True/False\n",
        "BATCH_SIZE = 1000  # número de exemplos por lote/batch\n",
        "MLE_TRAIN_EPOCHS = 30  # número de épocas ao treinar o gerador usando MLE (máxima verossimilhança)\n",
        "DIS_TRAIN_ITERATIONS = 300  # número de iterações ao treinar o discriminador (iterações contêm várias épocas, em cada iteração os dados de treinamento são atualizados)\n",
        "DIS_TRAIN_EPOCHS = 1  # número de épocas em uma iteração do treinamento do discriminador\n",
        "ADV_TRAIN_EPOCHS = 25  # número de épocas ao treinar o gerador usando aprendizado adversarial/aprendizado por reforço\n",
        "POS_NEG_SAMPLES = 10000\n",
        "\n",
        "GEN_EMBEDDING_DIM = 150  # largura da camada de Embedding do gerador\n",
        "GEN_HIDDEN_DIM = 150  # número de neurônios nas camadas do gerador\n",
        "DIS_EMBEDDING_DIM = 150  # largura da camada de Embedding do discriminador\n",
        "DIS_HIDDEN_DIM = 150  # número de neurônios nas camadas do discriminador\n",
        "\n",
        "# os parâmetros START_LETTER, VOCAB_SIZE, MAX_SEQ_LEN e FILE_PATHS são definidos automaticamente abaixo\n",
        "START_LETTER = None  # palavra inicial (a palavra que é dada primeiro à rede neural do gerador)\n",
        "MAX_SEQ_LEN = None  # comprimento do exemplo gerado\n",
        "VOCAB_SIZE = None  # número de palavras no vocabulário\n",
        "FILE_PATHS = None  # caminhos para os arquivos do conjunto de dados\n",
        "CLOSING_WORD = None  # palavra final / palavra substituta que é colocada no final da sentença\n",
        "\n",
        "# seleção do conjunto de dados e inicialização dos parâmetros globais correspondentes\n",
        "if DATASET == 'stihi_ru':  # conjunto de dados com poesias russas do site stihi_ru (comprimento do exemplo 10 palavras, tamanho do vocabulário 5000 palavras)\n",
        "  START_LETTER = 0\n",
        "  MAX_SEQ_LEN = 10\n",
        "  VOCAB_SIZE = 5000\n",
        "  CLOSING_WORD = 4999  # 4997\n",
        "  FILE_PATHS = {'train': r'/content/stihi_ru_realtrain_cotra.txt', 'test': r'/content/stihi_ru_realtest_coco.txt',\n",
        "                'vocab': r'/content/stihi_ru_vocab_cotra.pkl', 'saved_models': r'/content/'}\n",
        "elif DATASET == 'coco_image_captions':  # conjunto de dados COCO Image Captions (comprimento do exemplo 20 palavras, tamanho do vocabulário 4980 palavras)\n",
        "  START_LETTER = 0\n",
        "  MAX_SEQ_LEN = 20\n",
        "  VOCAB_SIZE = 4838\n",
        "  CLOSING_WORD = 1814\n",
        "  FILE_PATHS = {'train': r'/content/coco_image_captions_train.txt', 'test': r'/content/coco_image_captions_test.txt',\n",
        "                'vocab': r'/content/coco_image_captions_vocab_cotra_test.pkl', 'saved_models': r'/content/'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nZvyD7AVMWl"
      },
      "source": [
        "Inicialização de geradores de números aleatórios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXQAcf0yVL6Q"
      },
      "source": [
        "# inicialização de geradores de números aleatórios.\n",
        "torch.random.manual_seed(50)\n",
        "np.random.seed(50)\n",
        "# aleatoriedade do sistema!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D22oWzXQ3-A-"
      },
      "source": [
        "Declaração de classe do gerador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxd3fgqvLbz"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False):\n",
        "    super(Generator, self).__init__()\n",
        "    self.hidden_dim = hidden_dim # número de elementos na camada oculta\n",
        "    self.embedding_dim = embedding_dim # tamanho da camada de incorporação\n",
        "    self.max_seq_len = max_seq_len # comprimento dos exemplos gerados\n",
        "    self.vocab_size = vocab_size # tamanho do dicionário usado para geração\n",
        "    self.gpu = gpu # uso de cuda (Verdadeiro/Falso)\n",
        "    self.lstm_num_layers = 1 # número de camadas LSTM\n",
        "\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim) # declaração de camada de incorporação\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=self.lstm_num_layers) # Declaração de camada LSTM\n",
        "    self.lstm2out = nn.Linear(hidden_dim, vocab_size) # declaração da camada de saída\n",
        "\n",
        "  def init_hidden(self, batch_size=1):\n",
        "    # inicialização do estado da camada LSTM\n",
        "    h = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim))\n",
        "    c = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim))\n",
        "\n",
        "    if self.gpu:\n",
        "        return h.cuda(), c.cuda()\n",
        "    else:\n",
        "        return h, c\n",
        "\n",
        "  def forward(self, inp, hidden, c):\n",
        "    \"\"\"\n",
        "    Embeds input and applies LSTM one token at a time (seq_len = 1)\n",
        "    \"\"\"\n",
        "    # input dim                                             # batch_size\n",
        "    emb = self.embeddings(inp)                              # batch_size x embedding_dim\n",
        "    emb = emb.view(1, -1, self.embedding_dim)               # 1 x batch_size x embedding_dim\n",
        "    out, (hidden, c) = self.lstm(emb, (hidden, c))                    # 1 x batch_size x hidden_dim (out)\n",
        "    out = self.lstm2out(out.view(-1, self.hidden_dim))       # batch_size x vocab_size\n",
        "    out = F.log_softmax(out, dim=1)\n",
        "    return out, hidden, c\n",
        "\n",
        "  def sample(self, num_samples, start_letter=0, degree=1):\n",
        "    \"\"\"\n",
        "    Samples the network and returns num_samples samples of length max_seq_len.\n",
        "\n",
        "    Outputs: samples, hidden\n",
        "        - samples: num_samples x max_seq_length (a sampled sequence in each row)\n",
        "    \"\"\"\n",
        "\n",
        "    samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
        "\n",
        "    h, c = self.init_hidden(num_samples)\n",
        "    inp = autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
        "    if self.gpu:\n",
        "        samples = samples.cuda()\n",
        "        inp = inp.cuda()\n",
        "\n",
        "    for i in range(self.max_seq_len):\n",
        "        out, h, c = self.forward(inp, h, c)               # out: num_samples x vocab_size\n",
        "        out = torch.exp(out)**degree\n",
        "        out = torch.multinomial(out, 1)  # num_samples x 1 (sampling from each row)\n",
        "        samples[:, i] = out.view(-1).data\n",
        "\n",
        "        inp = out.view(-1)\n",
        "\n",
        "    return samples\n",
        "\n",
        "  def batchNLLLoss(self, inp, target):\n",
        "    \"\"\"\n",
        "    Returns the NLL Loss for predicting target sequence.\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    loss_fn = nn.NLLLoss()\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)           # seq_len x batch_size\n",
        "    target = target.permute(1, 0)     # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        loss += loss_fn(out, target[i])\n",
        "\n",
        "    return loss     # per batch\n",
        "\n",
        "  def batchPGLoss(self, inp, target, reward):\n",
        "    \"\"\"\n",
        "    Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
        "    Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "        - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
        "                  sentence)\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)          # seq_len x batch_size\n",
        "    target = target.permute(1, 0)    # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        # TODO: should h be detached from graph (.detach())?\n",
        "        for j in range(batch_size):\n",
        "            loss += -out[j][target.data[i][j]]*reward[j]#     # log(P(y_t|Y_1:Y_{t-1})) * Q\n",
        "\n",
        "    return loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut2px_RD4HIi"
      },
      "source": [
        "Declarando a classe Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUIXW8JMzAWk"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, dropout=0.2):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim # tamanho da camada oculta\n",
        "        self.embedding_dim = embedding_dim # largura da camada de incorporação\n",
        "        self.max_seq_len = max_seq_len # comprimento do exemplo de entrada\n",
        "        self.gpu = gpu # uso de cuda (Verdadeiro/Falso)\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # Declaração de camada de incorporação\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=3, bidirectional=True, dropout=dropout) # Declaração de camada LSTM\n",
        "\n",
        "        self.lstm2hidden = nn.Linear(2*3*hidden_dim, hidden_dim) # declaração de camada oculta\n",
        "        # self.lstm2hidden = nn.Linear(max_seq_len*hidden_dim*2, hidden_dim) # declaração de camada oculta\n",
        "\n",
        "        self.dropout_linear = nn.Dropout(p=dropout)\n",
        "        self.hidden2out = nn.Linear(hidden_dim, 1) # declaração da camada de saída\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # inicialização de camadas LSTM\n",
        "        h = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "        c = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "\n",
        "        if self.gpu:\n",
        "            return h.cuda(), c.cuda()\n",
        "        else:\n",
        "            return h, c\n",
        "\n",
        "    def forward(self, input, hidden, c):\n",
        "        # input dim                                                # batch_size x seq_len\n",
        "        # print(input.shape)\n",
        "        emb = self.embeddings(input)                               # batch_size x seq_len x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        emb = emb.permute(1, 0, 2)                                 # seq_len x batch_size x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        out_lstm, (hidden, c) = self.lstm(emb, (hidden, c))                          # 4 x batch_size x hidden_dim\n",
        "\n",
        "        hidden = hidden.permute(1, 0, 2).contiguous()              # batch_size x 4 x hidden_dim\n",
        "        # hidden = out_lstm\n",
        "        # print(hidden.shape, hidden.view(-1, self.max_seq_len*self.hidden_dim).shape)\n",
        "        # print(hidden.permute(1, 0, 2).contiguous().shape, hidden.permute(1, 0, 2).contiguous().view(-1, self.max_seq_len*self.hidden_dim*2).shape)\n",
        "\n",
        "        out = self.lstm2hidden(hidden.view(-1, 6*self.hidden_dim))  # batch_size x 4*hidden_dim\n",
        "        # out = self.lstm2hidden(hidden.view(-1, self.max_seq_len*self.hidden_dim*2))  # batch_size x 4*hidden_dim\n",
        "\n",
        "        out = torch.relu(out)\n",
        "        # out = out * torch.sigmoid(0.1 * out) # функция активации Swish: x * sigmoid(b*x)\n",
        "        out = self.dropout_linear(out)\n",
        "        out = self.hidden2out(out)                                 # batch_size x 1\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def batchClassify(self, inp):\n",
        "        \"\"\"\n",
        "        Classifies a batch of sequences.\n",
        "\n",
        "        Inputs: inp\n",
        "            - inp: batch_size x seq_len\n",
        "\n",
        "        Returns: out\n",
        "            - out: batch_size ([0,1] score)\n",
        "        \"\"\"\n",
        "\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return out.view(-1)\n",
        "\n",
        "    def batchBCELoss(self, inp, target):\n",
        "        \"\"\"\n",
        "        Returns Binary Cross Entropy Loss for discriminator.\n",
        "\n",
        "         Inputs: inp, target\n",
        "            - inp: batch_size x seq_len\n",
        "            - target: batch_size (binary 1/0)\n",
        "        \"\"\"\n",
        "\n",
        "        loss_fn = nn.BCELoss()\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return loss_fn(out, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czr-pzJe4KTW"
      },
      "source": [
        "Declarando funções que retornam dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQ2qmEm3xZ9"
      },
      "source": [
        "# função de geração de dados reais\n",
        "def sampler_example(batch_size):\n",
        "  x = data_file_train[np.random.randint(0, len(data_file_train), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y\n",
        "\n",
        "# função de geração de dados reais\n",
        "def sampler_example_test(batch_size):\n",
        "  x = data_file_test[np.random.randint(0, len(data_file_test), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YpbTp_a5L1W"
      },
      "source": [
        "Funções de treinamento do gerador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx23T6ef5MTA"
      },
      "source": [
        "# Função de aprendizagem do gerador baseada em MLE\n",
        "def train_generator_MLE(gen, gen_opt, real_samples_train, real_samples_test, epochs):\n",
        "    \"\"\"\n",
        "    Max Likelihood Pretraining for the generator\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print('epoch %d : ' % (epoch + 1), end='')\n",
        "        sys.stdout.flush()\n",
        "        total_loss = 0\n",
        "\n",
        "        # treinamento\n",
        "        for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "            inp_train, target_train = prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                          gpu=CUDA)\n",
        "            gen_opt.zero_grad()\n",
        "            loss = gen.batchNLLLoss(inp_train, target_train)\n",
        "            loss.backward()\n",
        "            gen_opt.step()\n",
        "\n",
        "            total_loss += loss.data.item()\n",
        "\n",
        "            if (i / BATCH_SIZE) % ceil(\n",
        "                            ceil(len(real_samples_train) / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                print('.', end='')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        # each loss in a batch is loss per sample\n",
        "        total_loss = total_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_train_NLL = %.4f' % total_loss, end='')\n",
        "\n",
        "        # testando\n",
        "        test_loss = 0\n",
        "\n",
        "        for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "            inp_test, target_test = prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                              gpu=CUDA)\n",
        "            loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "            test_loss += loss.data.item()\n",
        "        test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "def test_mle(gen, real_samples_train, real_samples_test):\n",
        "  '''\n",
        "  Testando o gerador em amostras de treinamento e teste.\n",
        "  '''\n",
        "  # testando no treinamento\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "      inp_test, target_test = prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print('average_train_NLL = %.4f' % test_loss, end='')\n",
        "\n",
        "  # testando em teste\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "      inp_test, target_test = prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "# função de aprendizagem do gerador baseada em aprendizagem por reforço RL\n",
        "def train_generator_PG(gen, gen_opt, dis, num_batches): # !renomear!\n",
        "    \"\"\"\n",
        "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
        "    Training is done for num_batches batches.\n",
        "    \"\"\"\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        s = gen.sample(BATCH_SIZE*4)        # 64 works best\n",
        "        inp, target = prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
        "        rewards = dis.batchClassify(target)\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
        "        pg_loss.backward()\n",
        "        gen_opt.step()\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx5xFCA35pKw"
      },
      "source": [
        "Função de aprendizagem discriminadora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSi-RHh45pk3"
      },
      "source": [
        "# função de aprendizagem discriminadora\n",
        "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, d_steps, epochs):\n",
        "    \"\"\"\n",
        "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
        "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # generating a small validation set before training\n",
        "    pos_val = real_data_samples[np.random.randint(0, len(real_data_samples), 500)] #sampler_example(250)\n",
        "    neg_val = generator.sample(500)\n",
        "    val_inp, val_target = prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
        "\n",
        "    for d_step in range(d_steps):\n",
        "        s = batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
        "        dis_inp, dis_target = prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
        "        val_pred = discriminator.batchClassify(val_inp)\n",
        "        print('ANTES DO TREINO: val_acc = %.4f' % (\n",
        "            torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))\n",
        "        for epoch in range(epochs):\n",
        "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
        "            sys.stdout.flush()\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
        "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
        "                dis_opt.zero_grad()\n",
        "                out = discriminator.batchClassify(inp)\n",
        "                loss_fn = nn.BCELoss()\n",
        "                loss = loss_fn(out, target)\n",
        "                loss.backward()\n",
        "                dis_opt.step()\n",
        "\n",
        "                total_loss += loss.data.item()\n",
        "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
        "\n",
        "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
        "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                    print('.', end='')\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
        "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
        "\n",
        "            val_pred = discriminator.batchClassify(val_inp)\n",
        "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
        "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBuFdlsb55XU"
      },
      "source": [
        "Função de avaliação da qualidade da geração de texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_D3lTI654PU"
      },
      "source": [
        "# avaliação de qualidade pela métrica BLEU\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "import random\n",
        "from scipy import stats\n",
        "\n",
        "# função para avaliar a qualidade da geração de texto usando a métrica BLEU\n",
        "def BLEU(reference_sample, test_sample, print_iteration=100, flag_print=True):\n",
        "  if flag_print:\n",
        "    print(\"--- --- ---\\nStart BLEU\")\n",
        "  pad = CLOSING_WORD\n",
        "  #################################################\n",
        "  reference = []\n",
        "  for line in reference_sample:\n",
        "    candidate = []\n",
        "    for i in line:\n",
        "      if i == pad:\n",
        "        break\n",
        "      candidate.append(i)\n",
        "\n",
        "    reference.append(candidate)\n",
        "  #################################################\n",
        "  hypothesis_list_leakgan = []\n",
        "  for line in test_sample:\n",
        "    while line[-1] == str(pad):\n",
        "      line.remove(str(pad))\n",
        "    hypothesis_list_leakgan.append(line)\n",
        "  #################################################\n",
        "  random.shuffle(hypothesis_list_leakgan)\n",
        "  #################################################\n",
        "\n",
        "  smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "  mass_bleu = []\n",
        "  for ngram in range(2,6):\n",
        "      weight = tuple((1. / ngram for _ in range(ngram)))\n",
        "      bleu_leakgan = []\n",
        "      bleu_supervise = []\n",
        "      bleu_base2 = []\n",
        "      num = 0\n",
        "      for h in hypothesis_list_leakgan:\n",
        "          BLEUscore = nltk.translate.bleu_score.sentence_bleu(reference, h, weight, smoothing_function = smoothing_function)\n",
        "          num += 1\n",
        "          bleu_leakgan.append(BLEUscore)\n",
        "\n",
        "          if num%print_iteration == 0 and flag_print:\n",
        "            print(ngram, num, sum(bleu_leakgan)/len(bleu_leakgan))\n",
        "\n",
        "      mass_bleu.append(1.0 * sum(bleu_leakgan) / len(bleu_leakgan))\n",
        "      if flag_print:\n",
        "        print('--- --- ---')\n",
        "        print(len(weight), '-gram BLEU score : ', 1.0 * sum(bleu_leakgan) / len(bleu_leakgan), \"\\n\")\n",
        "  return mass_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlNNlpWxIEM0"
      },
      "source": [
        "Função de salvamento de modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idULo4Q_IC6z"
      },
      "source": [
        "# função para salvar modelos (serialização: modelos geradores e discriminadores, parâmetros padrão, dados de treinamento)\n",
        "def save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer, name):\n",
        "  state = {\n",
        "      'default_parameters': {'VOCAB_SIZE': VOCAB_SIZE, 'MAX_SEQ_LEN': MAX_SEQ_LEN, 'GEN_EMBEDDING_DIM': GEN_EMBEDDING_DIM,\n",
        "                             'GEN_HIDDEN_DIM': GEN_HIDDEN_DIM, 'DIS_EMBEDDING_DIM': DIS_EMBEDDING_DIM, 'DIS_HIDDEN_DIM': DIS_HIDDEN_DIM},\n",
        "      'data_file_tensor_train': data_file_tensor_train,\n",
        "      'gen_state_dict': gen.state_dict(),\n",
        "      'dis_state_dict': dis.state_dict(),\n",
        "      'gen_optimizer': gen_optimizer.state_dict(),\n",
        "      'dis_optimizer': dis_optimizer.state_dict(),\n",
        "  }\n",
        "  torch.save(state, name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg9nWuCKHgZQ"
      },
      "source": [
        "Função de carregamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAlKsfNiHUnZ"
      },
      "source": [
        "# função para carregar modelos (desserializar: modelos geradores e discriminadores, parâmetros padrão, dados de treinamento)\n",
        "def load_models(name):\n",
        "  if CUDA:\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "  print('state')\n",
        "  state = torch.load(name, map_location=device)\n",
        "\n",
        "  print('default_parameters')\n",
        "  VOCAB_SIZE = state['default_parameters']['VOCAB_SIZE']\n",
        "  MAX_SEQ_LEN = state['default_parameters']['MAX_SEQ_LEN']\n",
        "  GEN_EMBEDDING_DIM = state['default_parameters']['GEN_EMBEDDING_DIM']\n",
        "  GEN_HIDDEN_DIM = state['default_parameters']['GEN_HIDDEN_DIM']\n",
        "  DIS_EMBEDDING_DIM = state['default_parameters']['DIS_EMBEDDING_DIM']\n",
        "  DIS_HIDDEN_DIM = state['default_parameters']['DIS_HIDDEN_DIM']\n",
        "\n",
        "  print('data_file_tensor_train')\n",
        "  data_file_tensor_train = torch.tensor(state['data_file_tensor_train'])\n",
        "\n",
        "  print('Generator')\n",
        "  gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  gen.load_state_dict(state['gen_state_dict'])\n",
        "  gen_optimizer = optim.Adam(gen.parameters(), lr=0.001)\n",
        "  gen_optimizer.load_state_dict(state['gen_optimizer'])\n",
        "\n",
        "  print('Discriminator')\n",
        "  dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  dis.load_state_dict(state['dis_state_dict'])\n",
        "  dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "  dis_optimizer.load_state_dict(state['dis_optimizer'])\n",
        "\n",
        "  print('CUDA')\n",
        "  if CUDA:\n",
        "    data_file_tensor_train = data_file_tensor_train.cuda()\n",
        "    gen = gen.cuda()\n",
        "    dis = dis.cuda()\n",
        "\n",
        "  return [data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "          VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vorPpC0M65Lv"
      },
      "source": [
        "Carregando o conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8boRQzJ_sb"
      },
      "source": [
        "# carregando dicionário\n",
        "import pickle\n",
        "\n",
        "vocab_file = FILE_PATHS['vocab']\n",
        "word, vocab = pickle.load(open(vocab_file, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MmMIx2VQmal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6fcd19-546a-4a1f-e726-d1f66f1d9666"
      },
      "source": [
        "# carregamento da amostra de treinamento\n",
        "f = open(FILE_PATHS['train'], 'r')\n",
        "data_file_train = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_train.append(line)\n",
        "data_file_train = np.array(data_file_train)[:, :MAX_SEQ_LEN]\n",
        "print(\"Exemplos na amostra de treinamento: \", len(data_file_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos na amostra de treinamento:  80000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHY_LhDP_o9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b1c1b2-03a5-4352-d506-6344983fadff"
      },
      "source": [
        "# carregamento da amostra de teste\n",
        "f = open(FILE_PATHS['test'], 'r')\n",
        "data_file_test = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_test.append(line)\n",
        "data_file_test = np.array(data_file_test)[:, :MAX_SEQ_LEN]\n",
        "print(\"Exemplos na amostra de teste: \", len(data_file_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos na amostra de teste:  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9jtz0qaQHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96b4013-c1f9-4433-8907-48637660ce50"
      },
      "source": [
        "# exemplos da amostra de treinamento\n",
        "print(\"Exemplos da amostra de treinamento\")\n",
        "samples = sampler_example(50)[0]\n",
        "output_function = []\n",
        "for samp in samples:\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "\n",
        "for i, output in enumerate(output_function):\n",
        "  print(\"#\", i, \"\\tExemplo: \", output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos da amostra de treinamento\n",
            "# 0 \tExemplo:  A street in front of an airport with people going in the entrance .            \n",
            "# 1 \tExemplo:  Blue and green bird sitting on the ground next to plants .                \n",
            "# 2 \tExemplo:  A racer is sitting on a horse in the gates .                  \n",
            "# 3 \tExemplo:  A man skiing a jump , while in the background there is snow melting off the slopes .    \n",
            "# 4 \tExemplo:  A man that is holding a knife and a pot with broccoli .              \n",
            "# 5 \tExemplo:  A bed in a bedroom that has lots of things sitting on top of it .        \n",
            "# 6 \tExemplo:  A skateboarder does a handstand trick on a skate - ramp .                \n",
            "# 7 \tExemplo:  A tall white building with three vehicles parked in front of it .              \n",
            "# 8 \tExemplo:  A man admiring a black and yellow motorcycle on a white background .              \n",
            "# 9 \tExemplo:  A cup of soup , a sandwich and a sweet roll on a table .          \n",
            "# 10 \tExemplo:  Traffic on a busy city road with street lights and Christmas decorations .              \n",
            "# 11 \tExemplo:  The woman is eating a hot dog at the game .                  \n",
            "# 12 \tExemplo:  A bright neon colored bus with no wheels sitting on some rocks .              \n",
            "# 13 \tExemplo:  Two figures in the dark under umbrellas with a light shining on them .            \n",
            "# 14 \tExemplo:  A dog in a field of grass with its tongue out .                \n",
            "# 15 \tExemplo:  Tennis player about to deliver backhand to ball during match .                  \n",
            "# 16 \tExemplo:  A pair of young men stand in a field playing with a frisbee .            \n",
            "# 17 \tExemplo:  A crowd of people standing underneath a snow covered mountain .                  \n",
            "# 18 \tExemplo:  A young boy tossing a green Frisbee in a park .                  \n",
            "# 19 \tExemplo:  A view of a bunch of street lights , during a cloudy day .            \n",
            "# 20 \tExemplo:  A brown and white horse standing in front of a red wall .              \n",
            "# 21 \tExemplo:  The two skiers have on all the gear needed to ski .                \n",
            "# 22 \tExemplo:  Two girls in black , one in pants and one is a skirt , huddle under a black umbrella .\n",
            "# 23 \tExemplo:  A person performing a riding trick on a skate board .                  \n",
            "# 24 \tExemplo:  A commercial airliners taxis toward the runway for take - off .                \n",
            "# 25 \tExemplo:  Sun shines through on a bathroom with a pedestal sink .                  \n",
            "# 26 \tExemplo:  A plate full of food including broccoli , potatoes and tomatoes .                \n",
            "# 27 \tExemplo:  A couple of little girls standing next to each other .                  \n",
            "# 28 \tExemplo:  An open face sandwich and a pile of potato chips on a plate .            \n",
            "# 29 \tExemplo:  A stop sign with the word war added beneath it .                  \n",
            "# 30 \tExemplo:  A baby brushing it ' s teeth with a blue and white tooth brush .          \n",
            "# 31 \tExemplo:  An intersection of two city streets on a rainy day .                  \n",
            "# 32 \tExemplo:  A man and woman dressed in wedding attire walking out of a building together .          \n",
            "# 33 \tExemplo:  Boys stand with skateboards watching others skate at a skatepark .                  \n",
            "# 34 \tExemplo:  A close shot of a shirt with a tie is seen .                \n",
            "# 35 \tExemplo:  The sun shines over a mountain as a skier glides down a snowy slope .          \n",
            "# 36 \tExemplo:  A young boy sitting on a couch with a tooth brush in his mouth .          \n",
            "# 37 \tExemplo:  A train cake , apparently for somebody ' s second birthday .                \n",
            "# 38 \tExemplo:  Three men stand with ski poles on a snowy mountain .                  \n",
            "# 39 \tExemplo:  This is a living room with a black , white , and maroon colored tile floor .      \n",
            "# 40 \tExemplo:  An intersection with a fast food restaurant on the opposite corner .                \n",
            "# 41 \tExemplo:  A cat is laying on the top of a refrigerator in a kitchen .            \n",
            "# 42 \tExemplo:  Skateboarder riding in a concrete with a large cross in the middle .              \n",
            "# 43 \tExemplo:  A picture of a boat that is in the water .                  \n",
            "# 44 \tExemplo:  A close - up of the face of the horse with a woman on the back .      \n",
            "# 45 \tExemplo:  A man riding a skateboard on top of a sidewalk .                  \n",
            "# 46 \tExemplo:  A man is riding a wave on his surf board .                  \n",
            "# 47 \tExemplo:  A bathroom under construction with white tile beside a bedroom .                  \n",
            "# 48 \tExemplo:  A child rests on a fire hydrant while on the street with a woman .          \n",
            "# 49 \tExemplo:  Five people sitting on a long bench in the city .                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtfMO3AXK-yk"
      },
      "source": [
        "Avaliação da qualidade dos exemplos do conjunto de treinamento baseado no BLEU (para comparação com o gerador)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNMHGxTTIQMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33fa1beb-e8b9-4a76-dd11-5cc8ce0bb581"
      },
      "source": [
        "%%time\n",
        "# Avaliação de qualidade com base nos exemplos da amostra de treinamento (para comparação com o gerador)\n",
        "print(\"Avaliação dos exemplos da amostra de treinamento com base no BLEU\")\n",
        "BLEU(data_file_test.tolist(), data_file_train[:500].tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avaliação dos exemplos da amostra de treinamento com base no BLEU\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5668908859860812\n",
            "2 200 0.5565824398207067\n",
            "2 300 0.5492119198714641\n",
            "2 400 0.5467045446976672\n",
            "2 500 0.5499117864293881\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5499117864293881 \n",
            "\n",
            "3 100 0.45817138194805873\n",
            "3 200 0.44736460910970616\n",
            "3 300 0.4359582265418135\n",
            "3 400 0.4304990035415631\n",
            "3 500 0.43699142793369117\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.43699142793369117 \n",
            "\n",
            "4 100 0.34424180007897254\n",
            "4 200 0.32889664912071476\n",
            "4 300 0.3152189334404297\n",
            "4 400 0.3095685622316223\n",
            "4 500 0.3173224414085977\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.3173224414085977 \n",
            "\n",
            "5 100 0.23686041045461245\n",
            "5 200 0.22011932885266372\n",
            "5 300 0.20931541371110826\n",
            "5 400 0.20581532744507264\n",
            "5 500 0.21083373415979104\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.21083373415979104 \n",
            "\n",
            "CPU times: user 5min 44s, sys: 673 ms, total: 5min 45s\n",
            "Wall time: 5min 56s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5499117864293881,\n",
              " 0.43699142793369117,\n",
              " 0.3173224414085977,\n",
              " 0.21083373415979104]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2SVFc57G_h"
      },
      "source": [
        "Criação de redes neurais do gerador e discriminador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LziOsVRduVtC"
      },
      "source": [
        "# Declaração do gerador e discriminador de redes neurais, preparação de amostras de dados para uso pelo pytorch\n",
        "gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "\n",
        "if CUDA:\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()\n",
        "else:\n",
        "  data_file_tensor_train = torch.tensor(data_file_train)\n",
        "  data_file_tensor_test = torch.tensor(data_file_test)\n",
        "\n",
        "gen_optimizer = optim.Adam(gen.parameters(), lr=0.001) # lr=0.001\n",
        "dis_optimizer = optim.Adagrad(dis.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjtGu-Dh7Xn0"
      },
      "source": [
        "Treinando um gerador com base em MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w7pqxEA3jhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18bfc8c-84d0-4329-aef4-608adeddef3e"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 8.5446 average_test_NLL = 8.5451\n",
            "CPU times: user 7.94 s, sys: 115 ms, total: 8.05 s\n",
            "Wall time: 8.12 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ZzVettuZHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67215f2-8df4-439b-ebd5-c0d7726ef13d"
      },
      "source": [
        "%%time\n",
        "# Treinamento de gerador baseado em MLE / pré-treinamento de gerador\n",
        "print('Iniciando o treinamento do gerador baseado em MLE...')\n",
        "gen_optimizer = optim.Adam(gen.parameters()) # lr=0.0002\n",
        "train_generator_MLE(gen, gen_optimizer, data_file_tensor_train, data_file_tensor_test, MLE_TRAIN_EPOCHS) # MLE_TRAIN_EPOCHS\n",
        "\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# salvando o resultado da aprendizagem\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_mle.pytorch')\n",
        "# epoch 1 : .......... average_train_NLL = 1.8447 average_test_NLL = 1.9937"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o treinamento do gerador baseado em MLE...\n",
            "epoch 1 : .......... average_train_NLL = 4.5138 average_test_NLL = 3.3173\n",
            "epoch 2 : .......... average_train_NLL = 3.0475 average_test_NLL = 2.9099\n",
            "epoch 3 : .......... average_train_NLL = 2.7634 average_test_NLL = 2.7012\n",
            "epoch 4 : .......... average_train_NLL = 2.5905 average_test_NLL = 2.5820\n",
            "epoch 5 : .......... average_train_NLL = 2.4759 average_test_NLL = 2.4898\n",
            "epoch 6 : .......... average_train_NLL = 2.3922 average_test_NLL = 2.4348\n",
            "epoch 7 : .......... average_train_NLL = 2.3276 average_test_NLL = 2.3860\n",
            "epoch 8 : .......... average_train_NLL = 2.2767 average_test_NLL = 2.3403\n",
            "epoch 9 : .......... average_train_NLL = 2.2326 average_test_NLL = 2.3062\n",
            "epoch 10 : .......... average_train_NLL = 2.1932 average_test_NLL = 2.2736\n",
            "epoch 11 : .......... average_train_NLL = 2.1576 average_test_NLL = 2.2472\n",
            "epoch 12 : .......... average_train_NLL = 2.1273 average_test_NLL = 2.2134\n",
            "epoch 13 : .......... average_train_NLL = 2.0967 average_test_NLL = 2.1897\n",
            "epoch 14 : .......... average_train_NLL = 2.0708 average_test_NLL = 2.1588\n",
            "epoch 15 : .......... average_train_NLL = 2.0448 average_test_NLL = 2.1387\n",
            "epoch 16 : .......... average_train_NLL = 2.0203 average_test_NLL = 2.1249\n",
            "epoch 17 : .......... average_train_NLL = 1.9998 average_test_NLL = 2.1043\n",
            "epoch 18 : .......... average_train_NLL = 1.9795 average_test_NLL = 2.0884\n",
            "epoch 19 : .......... average_train_NLL = 1.9593 average_test_NLL = 2.0754\n",
            "epoch 20 : .......... average_train_NLL = 1.9408 average_test_NLL = 2.0592\n",
            "epoch 21 : .......... average_train_NLL = 1.9224 average_test_NLL = 2.0461\n",
            "epoch 22 : .......... average_train_NLL = 1.9051 average_test_NLL = 2.0338\n",
            "epoch 23 : .......... average_train_NLL = 1.8887 average_test_NLL = 2.0233\n",
            "epoch 24 : .......... average_train_NLL = 1.8735 average_test_NLL = 2.0136\n",
            "epoch 25 : .......... average_train_NLL = 1.8589 average_test_NLL = 2.0049\n",
            "epoch 26 : .......... average_train_NLL = 1.8453 average_test_NLL = 1.9942\n",
            "epoch 27 : .......... average_train_NLL = 1.8322 average_test_NLL = 1.9856\n",
            "epoch 28 : .......... average_train_NLL = 1.8196 average_test_NLL = 1.9764\n",
            "epoch 29 : .......... average_train_NLL = 1.8075 average_test_NLL = 1.9678\n",
            "epoch 30 : .......... average_train_NLL = 1.7959 average_test_NLL = 1.9609\n",
            "average_train_NLL = 1.8009 average_test_NLL = 1.9609\n",
            "CPU times: user 5min 17s, sys: 887 ms, total: 5min 18s\n",
            "Wall time: 5min 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vE1qrmlgJNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab82d8f-7df7-4cea-bf62-cfddc744c766"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 1.8009 average_test_NLL = 1.9609\n",
            "CPU times: user 7.4 s, sys: 14 ms, total: 7.42 s\n",
            "Wall time: 7.42 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2AFMeIuIg6R"
      },
      "source": [
        "Gerando textos de amostra com base em MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGaETrFgIfzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbcb672-45dc-4697-defe-3ce9d7550c65"
      },
      "source": [
        "# # exemplos de textos gerados\n",
        "print(\"Exemplos de textos gerados com base em MLE\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tExemplo: \", line, ' '*(100-len(line)), '\\tAvaliação: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos de textos gerados com base em MLE\n",
            "Degree: 1\n",
            "# 0 \tExemplo:  The train traveling down the track on town track just set out of the park .                           \tAvaliação:  [0.5803810000880093, 0.4539847774172143, 0.1531682455208201, 0.08078132896612913]\n",
            "# 1 \tExemplo:  The fence sitting inside the bathroom surrounded by trees and tube .                                  \tAvaliação:  [0.41675437673324534, 0.268229131353767, 0.10322080150552766, 0.05891010340986106]\n",
            "# 2 \tExemplo:  A train moving tracks next to a wooden size platform in the country in a dimly environment .          \tAvaliação:  [0.6529286250990105, 0.4558685532582043, 0.2732231510487644, 0.12834826432879642]\n",
            "# 3 \tExemplo:  A woman on the tennis court preparing to hit with a bat .                                             \tAvaliação:  [0.4893604849295929, 0.34174500988297, 0.22012248449054683, 0.1079711005739161]\n",
            "# 4 \tExemplo:  A cat is sitting on a train along with many other riders ' s figurine .                               \tAvaliação:  [0.6282808624375432, 0.5086223840955505, 0.3903594390682207, 0.31085206075418725]\n",
            "# 5 \tExemplo:  Many girls play children are standing at the train goes .                                             \tAvaliação:  [0.3402785236893603, 0.2343197292238376, 0.16586105071157164, 0.08609373184361885]\n",
            "# 6 \tExemplo:  A dog sitting on the side of a brown bed next to a computer equipment .                               \tAvaliação:  [0.7398435111918139, 0.6724640591076463, 0.572370695651743, 0.4222055277665569]\n",
            "# 7 \tExemplo:  A big giraffe are tied to eat a bottle of wine .                                                      \tAvaliação:  [0.533113989983183, 0.3982378626139663, 0.293597382795084, 0.21546550289591512]\n",
            "# 8 \tExemplo:  A photo of a girl with young kites in waves .                                                         \tAvaliação:  [0.39735970711951313, 0.29744417462950146, 0.19835441454182887, 0.09934122243585623]\n",
            "# 9 \tExemplo:  A skier is in a soccer ball high in the ocean .                                                       \tAvaliação:  [0.5619514869490163, 0.44432257867347535, 0.2680165156355778, 0.12638782754962138]\n",
            "# 10 \tExemplo:  A pair of meat and sheep are sitting together and wearing a suit .                                    \tAvaliação:  [0.5758289219624358, 0.3327475090445512, 0.12133158735615288, 0.06704325740058405]\n",
            "# 11 \tExemplo:  A man sitting at girls next to each other next to each other .                                        \tAvaliação:  [0.533113989983183, 0.4799049519403644, 0.42461633178803443, 0.3605766584996779]\n",
            "# 12 \tExemplo:  A woman laying on girl eats fun while children being now .                                            \tAvaliação:  [0.3402785236893603, 0.2343197292238376, 0.16586105071157164, 0.08609373184361885]\n",
            "# 13 \tExemplo:  The older flag is prepared to be the plane at the park .                                              \tAvaliação:  [0.4893604849295929, 0.34174500988297, 0.22012248449054683, 0.1079711005739161]\n",
            "# 14 \tExemplo:  The room is bottle , sink , and small drinking from pens and glasses .                                \tAvaliação:  [0.5758289219624358, 0.38090081277744137, 0.23877931071514819, 0.11523206875414535]\n",
            "# 15 \tExemplo:  A man skateboards down a graze eating some big ripe jelly .                                           \tAvaliação:  [0.3402785236893603, 0.08632412632135038, 0.0441049072731168, 0.029837713127693215]\n",
            "# 16 \tExemplo:  Green black and grey cat taking a nap with a two television .                                         \tAvaliação:  [0.5231483637805969, 0.39325936742827655, 0.24456656109396324, 0.11746099218395799]\n",
            "# 17 \tExemplo:  A bowl full of what looks like Two big fruits .                                                       \tAvaliação:  [0.41675437673324534, 0.3070457069283656, 0.20313747122261766, 0.1012530319921446]\n",
            "# 18 \tExemplo:  A hand , baseball on a angry area with a view behind him .                                            \tAvaliação:  [0.4893604849295929, 0.34174500988297, 0.12378396963260613, 0.06812515889872198]\n",
            "# 19 \tExemplo:  A large purple umbrella standing on a piece of bag .                                                  \tAvaliação:  [0.45014617508912413, 0.32323518297936166, 0.2111187176080899, 0.10442329545559932]\n",
            "# 20 \tExemplo:  Two people at a market pose for an clocks close to finish in the air .                                \tAvaliação:  [0.6282808624375432, 0.4443225786734753, 0.3187271473320672, 0.14518148959789903]\n",
            "# 21 \tExemplo:  the dish who is decorated with strawberries , mushrooms , chocolate and knife .                       \tAvaliação:  [0.4530597729822598, 0.225084799456331, 0.09049975320972704, 0.05302661682525778]\n",
            "# 22 \tExemplo:  A boy wearing a helmet holding a large kite in it .                                                   \tAvaliação:  [0.533113989983183, 0.36182311050064736, 0.12919925124488807, 0.07049916949671992]\n",
            "# 23 \tExemplo:  A couple of elephants standing next to each other .                                                   \tAvaliação:  [0.42919753763947605, 0.37125357768697886, 0.30826276460621843, 0.2573468506325473]\n",
            "# 24 \tExemplo:  A man and serving on a man playing baseball with his bat with an extended .                           \tAvaliação:  [0.5803810000880093, 0.38290559082342246, 0.13480517058692587, 0.07293588276546237]\n",
            "# 25 \tExemplo:  Someone wearing plaid sweater ready to hit the tennis tricycle .                                      \tAvaliação:  [0.1538967528127731, 0.05086223840955505, 0.029660903203497246, 0.021723184998105653]\n",
            "# 26 \tExemplo:  A bowl filled with berries and cantaloupe are lined up by on a table .                                \tAvaliação:  [0.6069769786668839, 0.5232669734616001, 0.3987590721833036, 0.17367786227241042]\n",
            "# 27 \tExemplo:  The people are on skis posing for a soccer ball .                                                     \tAvaliação:  [0.5104177855340404, 0.4167251379930962, 0.2554318471365747, 0.12161749074046846]\n",
            "# 28 \tExemplo:  A man Various hot dogs stand in a piece of pizza sitting .                                            \tAvaliação:  [0.4530597729822598, 0.3246284552986226, 0.2118008548235711, 0.10469312669112453]\n",
            "# 29 \tExemplo:  A women who is sitting in a chair and two workers looking in a computer .                             \tAvaliação:  [0.7398435111918139, 0.5970835291097519, 0.4402449689810936, 0.29794186008488804]\n",
            "# 30 \tExemplo:  A woman that is on her skis while a vehicle from their way to other vehicles .                        \tAvaliação:  [0.7626132357679226, 0.5446306254550225, 0.31222258402876674, 0.14280632873431442]\n",
            "# 31 \tExemplo:  A full view of red , and a sandwich cut pieces .                                                      \tAvaliação:  [0.5026246899500345, 0.347892817097899, 0.22308576866161578, 0.10913234729182814]\n",
            "# 32 \tExemplo:  A giraffe standing to some rocks in the middle of a grassy field .                                    \tAvaliação:  [0.6649099662043687, 0.5813634471819698, 0.4315229271655712, 0.29321021982166245]\n",
            "# 33 \tExemplo:  A girl sitting on a picnic man watching guitar and holding a Wii controller .                         \tAvaliação:  [0.5428967140306369, 0.43422081861268574, 0.31327681146619374, 0.22694394676932841]\n",
            "# 34 \tExemplo:  A cop sitting with a cross frowning and a donut cluttered toilet .                                    \tAvaliação:  [0.4893604849295929, 0.2369527555554263, 0.0940554774384672, 0.05468689644952395]\n",
            "# 35 \tExemplo:  A dog is sitting in a garage next to a cup of soda .                                                  \tAvaliação:  [0.6366028258614133, 0.5647438827324667, 0.4797543511401896, 0.36660395036046545]\n",
            "# 36 \tExemplo:  A large body of black t - up - - story dog beside a car .                                             \tAvaliação:  [0.6282808624375432, 0.40369385378392525, 0.24941747177008258, 0.11932116956929131]\n",
            "# 37 \tExemplo:  A counter with a chocolate sandwich on a plate with red whipped .                                     \tAvaliação:  [0.5026246899500345, 0.3829055908234224, 0.28507822708363717, 0.13278445727890759]\n",
            "# 38 \tExemplo:  A couple of birds sitting across on top of a beach near them .                                        \tAvaliação:  [0.6069769786668839, 0.4677501973766062, 0.2785468517364889, 0.13034506916523114]\n",
            "# 39 \tExemplo:  A woman eating a piece pizza with various pieces of cake .                                            \tAvaliação:  [0.5026246899500345, 0.2412154070004315, 0.0953216502610246, 0.055275062900335764]\n",
            "# 40 \tExemplo:  A person that is holding a young boy standing in a green field .                                      \tAvaliação:  [0.6920602346769048, 0.6639509405734763, 0.5122768853495414, 0.2122168245237715]\n",
            "# 41 \tExemplo:  Four skiers stand in grassy area with their boards in the background .                                \tAvaliação:  [0.5548826333938605, 0.4090062242255915, 0.2995316414137092, 0.13814340887248766]\n",
            "# 42 \tExemplo:  The man is in front of a red shaped cake .                                                            \tAvaliação:  [0.4812265031857878, 0.42578720527948616, 0.3416351427096076, 0.2794036231048865]\n",
            "# 43 \tExemplo:  A tray is well with a circle of meat large dough on a paper plate .                                   \tAvaliação:  [0.5026246899500346, 0.1119622739628565, 0.053603303127115566, 0.03487620690357151]\n",
            "# 44 \tExemplo:  A woman is on to play a ball in a match .                                                             \tAvaliação:  [0.45014617508912413, 0.32323518297936166, 0.2111187176080899, 0.10442329545559932]\n",
            "# 45 \tExemplo:  A beautiful woman standing next to a couch in front of each other .                                   \tAvaliação:  [0.6649099662043687, 0.5560541333192193, 0.4173552570984386, 0.2854833038569153]\n",
            "# 46 \tExemplo:  A male on a skateboard is near a skateboard in the air .                                              \tAvaliação:  [0.5548826333938605, 0.4681952501639962, 0.36684984164094486, 0.29578263349243455]\n",
            "# 47 \tExemplo:  A seed bench topped with food in front of them .                                                      \tAvaliação:  [0.42919753763947605, 0.3131273945313386, 0.24515235346013312, 0.18651976384997176]\n",
            "# 48 \tExemplo:  A giraffe standing in a grassy area with horns .                                                      \tAvaliação:  [0.42919753763947605, 0.39451579566877026, 0.3665882729601239, 0.3395712052221365]\n",
            "# 49 \tExemplo:  A group of people float in jackets in a field , and looks in a doorway .                              \tAvaliação:  [0.6805570473787206, 0.536458262707534, 0.367110852009989, 0.16256003406866554]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lZnWDHB7xsN"
      },
      "source": [
        "Avaliação da qualidade da geração de texto após treinamento usando MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R2_zZKV7yPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60109861-9869-42c6-866a-b692a7cdac1e"
      },
      "source": [
        "%%time\n",
        "print(\"Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com MLE\")\n",
        "# controle de qualidade da educação\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com MLE\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5293642270728148\n",
            "2 200 0.5177477282229925\n",
            "2 300 0.5187759811123885\n",
            "2 400 0.5224344367661522\n",
            "2 500 0.5226959797212712\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5226959797212712 \n",
            "\n",
            "3 100 0.3745155103422013\n",
            "3 200 0.3747070946116354\n",
            "3 300 0.3766445189439405\n",
            "3 400 0.3824035755361252\n",
            "3 500 0.3826083717484991\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.3826083717484991 \n",
            "\n",
            "4 100 0.23614238711588037\n",
            "4 200 0.2383679075019982\n",
            "4 300 0.24110822943618232\n",
            "4 400 0.24672461169817064\n",
            "4 500 0.24742168834243194\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.24742168834243194 \n",
            "\n",
            "5 100 0.13042908649105356\n",
            "5 200 0.14142368359462995\n",
            "5 300 0.14374599352648856\n",
            "5 400 0.14743754287257302\n",
            "5 500 0.1487098461666625\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.1487098461666625 \n",
            "\n",
            "CPU times: user 5min 49s, sys: 778 ms, total: 5min 49s\n",
            "Wall time: 5min 52s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5226959797212712,\n",
              " 0.3826083717484991,\n",
              " 0.24742168834243194,\n",
              " 0.1487098461666625]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILoM7VA7nKpO"
      },
      "source": [
        "Estimativa com exponenciação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ncMN88-nGy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f808d6-0cd6-4b55-8e99-3d9313d0b9bf"
      },
      "source": [
        "# exemplos de textos gerados\n",
        "print(\"Exemplos de textos gerados com base em MLE\")\n",
        "degree = 1.5\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tExemplo:\", line, ' '*(100-len(line)), '\\tAvaliação: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos de textos gerados com base em MLE\n",
            "Degree: 1.5\n",
            "# 0 \tExemplo: The man is doing the trick on a court near a man .                                                    \tAvaliação:  [0.5548826333938605, 0.37160681631842096, 0.13181065657459776, 0.07163684030886805]\n",
            "# 1 \tExemplo: A man holding up a donut in a bowl of flowers in a room .                                             \tAvaliação:  [0.716350399411379, 0.6109741448719966, 0.404727200247809, 0.17575428316242378]\n",
            "# 2 \tExemplo: A woman in a dress eating a pizza with a slice missing .                                              \tAvaliação:  [0.5548826333938605, 0.4090062242255915, 0.2518750835198491, 0.12026082240959093]\n",
            "# 3 \tExemplo: A green train down train station on the tracks near a mountain .                                      \tAvaliação:  [0.5231483637805969, 0.3572998474390311, 0.22759483012793272, 0.11089345578518284]\n",
            "# 4 \tExemplo: A lady is holding a tennis racket on a clay court .                                                   \tAvaliação:  [0.45014617508912413, 0.2823719413662334, 0.10727633416507679, 0.06075459680224768]\n",
            "# 5 \tExemplo: A young man walking on a snow covered slope and a ball .                                              \tAvaliação:  [0.6134458325505882, 0.5005841126806674, 0.4144866661186027, 0.17913665263472914]\n",
            "# 6 \tExemplo: People wearing snow gear on a big blue sky .                                                          \tAvaliação:  [0.3627381250550058, 0.19407576238520263, 0.08097785064266204, 0.048514214015354815]\n",
            "# 7 \tExemplo: A man standing in the snow on a snow board in the ocean .                                             \tAvaliação:  [0.6920602346769048, 0.5970835291097519, 0.47307400630367114, 0.3155871214483429]\n",
            "# 8 \tExemplo: The shaggy man on the kitchen counter with two pillows .                                              \tAvaliação:  [0.39735970711951313, 0.3273796750780409, 0.21314568971111159, 0.10522459120299207]\n",
            "# 9 \tExemplo: A man sitting on a bed in a room next to a laptop computer .                                          \tAvaliação:  [0.7433919416750281, 0.7362673044371594, 0.6960884152052168, 0.5671781954589323]\n",
            "# 10 \tExemplo: A cat is curled up on a bed in front of a television .                                                \tAvaliação:  [0.6920602346769048, 0.6639509405734763, 0.5669275668967321, 0.4812935724427397]\n",
            "# 11 \tExemplo: The surfer is riding a skateboard down a hill in the air on a ramp .                                  \tAvaliação:  [0.7108186533109109, 0.6321632020469774, 0.4152094006260531, 0.28430843556982]\n",
            "# 12 \tExemplo: A man is performing a trick on a wave in the ocean .                                                  \tAvaliação:  [0.5548826333938605, 0.4090062242255915, 0.2518750835198491, 0.12026082240959093]\n",
            "# 13 \tExemplo: A man with his arms up in the air on his board .                                                      \tAvaliação:  [0.6134458325505882, 0.5509641073413446, 0.47094777718650466, 0.391722444087928]\n",
            "# 14 \tExemplo: A man sitting on top of a couch with a plane in his hand .                                            \tAvaliação:  [0.7433919416750281, 0.6963890912495402, 0.5875766810867469, 0.46757566031593883]\n",
            "# 15 \tExemplo: A man folding a baseball mitt with a bat on a court up .                                              \tAvaliação:  [0.4893604849295929, 0.10998372642798453, 0.052891281824158635, 0.03450509896165494]\n",
            "# 16 \tExemplo: A man in a blue jacket and a woman holding a tennis racquet .                                         \tAvaliação:  [0.6366028258614133, 0.5647438827324667, 0.45372365197359754, 0.3052172947188026]\n",
            "# 17 \tExemplo: A man standing with his arms up to hit a tennis ball .                                                \tAvaliação:  [0.6134458325505882, 0.5005841126806674, 0.34854035170959624, 0.15594751385814556]\n",
            "# 18 \tExemplo: A man is sitting on a couch with her face and a woman a motorcycle .                                  \tAvaliação:  [0.7398435111918139, 0.624260333551995, 0.5171953073984757, 0.4222055277665569]\n",
            "# 19 \tExemplo: A man is on the beach over the ocean with a surfboard .                                               \tAvaliação:  [0.6134458325505882, 0.5509641073413446, 0.47094777718650466, 0.314451886543678]\n",
            "# 20 \tExemplo: A man sitting in a chair at a table eating a cake .                                                   \tAvaliação:  [0.6407232755171874, 0.5898890511424149, 0.5188040214030465, 0.4232558032555616]\n",
            "# 21 \tExemplo: A cat is sitting on a computer desk next to a laptop computer .                                       \tAvaliação:  [0.6920602346769048, 0.6639509405734763, 0.589202081622577, 0.4321091081416893]\n",
            "# 22 \tExemplo: A man eating a piece of pizza on a plate .                                                            \tAvaliação:  [0.5104177855340404, 0.4167251379930962, 0.30376137001310205, 0.13970181155244327]\n",
            "# 23 \tExemplo: A man and a woman standing next to each other .                                                       \tAvaliação:  [0.5380275868489703, 0.5250407733778476, 0.4754122362294423, 0.39469037777958105]\n",
            "# 24 \tExemplo: A man in a white shirt holding a tennis racket .                                                      \tAvaliação:  [0.42919753763947605, 0.3446412921261351, 0.22152015777624515, 0.10851920540253215]\n",
            "# 25 \tExemplo: A person lying in a bed next to a wall and a window .                                                 \tAvaliação:  [0.6366028258614133, 0.5873573073196627, 0.4940911248125205, 0.32675455150630617]\n",
            "# 26 \tExemplo: A woman with a pink surf board sitting in the middle of a tennis court .                              \tAvaliação:  [0.7108186533109109, 0.5813634471819698, 0.4637015624246032, 0.3567572848363358]\n",
            "# 27 \tExemplo: A man holding a tennis racket and a tennis ball with a racket .                                       \tAvaliação:  [0.45014617508912413, 0.32323518297936166, 0.2111187176080899, 0.10442329545559932]\n",
            "# 28 \tExemplo: A girl is sitting on a couch with her phone .                                                         \tAvaliação:  [0.5380275868489703, 0.45866536281292586, 0.388172465412544, 0.26939887898890685]\n",
            "# 29 \tExemplo: A man is eating a piece of pizza with a pizza on it .                                                 \tAvaliação:  [0.6134458325505882, 0.43730050179518515, 0.14892676349028391, 0.07898674271716548]\n",
            "# 30 \tExemplo: A young girl is holding a baseball bat while standing next to a woman and a giraffe .                 \tAvaliação:  [0.8429272304235246, 0.7572398297980701, 0.5653636138834072, 0.41806545797669464]\n",
            "# 31 \tExemplo: Man about to hit a soccer ball on a court .                                                           \tAvaliação:  [0.45014617508912413, 0.2823719413662334, 0.10727633416507679, 0.06075459680224768]\n",
            "# 32 \tExemplo: A man riding a skateboard in the air with a surfboard in the water .                                  \tAvaliação:  [0.7433919416750281, 0.716882776507279, 0.6240916750384193, 0.4524605448441326]\n",
            "# 33 \tExemplo: A man holding a Wii remote to his face from his face .                                                \tAvaliação:  [0.45014617508912413, 0.3557663528269982, 0.22686182598679874, 0.11060764410745492]\n",
            "# 34 \tExemplo: A man holding a tennis racquet in a field with his surfboard in the water .                           \tAvaliação:  [0.7398435111918139, 0.624260333551995, 0.45518966025586544, 0.19307672079928953]\n",
            "# 35 \tExemplo: A little boy standing on top of a baseball field .                                                    \tAvaliação:  [0.5380275868489703, 0.45866536281292586, 0.3264128346656048, 0.2345253458551372]\n",
            "# 36 \tExemplo: A little girl standing in a bathroom with a green toothbrush .                                        \tAvaliação:  [0.5619514869490163, 0.5196828406118894, 0.4507482544534971, 0.348762069035715]\n",
            "# 37 \tExemplo: A man standing in a field with other boards in the water .                                            \tAvaliação:  [0.6134458325505882, 0.5269782107608059, 0.45548571872797966, 0.38139945326989394]\n",
            "# 38 \tExemplo: A man in a wet suit standing in front of a large pizza .                                              \tAvaliação:  [0.6366028258614133, 0.5647438827324667, 0.5021277621795815, 0.43675651176119695]\n",
            "# 39 \tExemplo: A man with a tennis racket is running to hit the ball .                                               \tAvaliação:  [0.435285750066007, 0.27612271191669263, 0.18759202316167214, 0.09500522640872923]\n",
            "# 40 \tExemplo: A brown bear laying with a wooden seat and a white toothbrush .                                       \tAvaliação:  [0.5231483637805969, 0.4236258116837369, 0.3403336518440549, 0.2785517669300084]\n",
            "# 41 \tExemplo: A man with a surf board in a park and there is a ball up to of the net .                              \tAvaliação:  [0.8944271909999159, 0.7084390461217407, 0.4522432940641193, 0.19207626942331976]\n",
            "# 42 \tExemplo: A group of young men standing in the top of a living room .                                           \tAvaliação:  [0.6920602346769048, 0.6639509405734763, 0.5416668574934416, 0.22190230544737718]\n",
            "# 43 \tExemplo: A man on a high surfboard in a park .                                                                 \tAvaliação:  [0.42919753763947605, 0.3446412921261351, 0.2634333477440361, 0.12465583273147404]\n",
            "# 44 \tExemplo: A man is standing in front of a wooden floor in a room .                                              \tAvaliação:  [0.6920602346769048, 0.6639509405734763, 0.589202081622577, 0.4963630217015944]\n",
            "# 45 \tExemplo: A man is standing in a living room with a laptop .                                                    \tAvaliação:  [0.5893796917545019, 0.5778821454656745, 0.5309354663044072, 0.45668988354930307]\n",
            "# 46 \tExemplo: A man is standing on a beach with tennis rackets .                                                    \tAvaliação:  [0.42919753763947605, 0.39451579566877026, 0.32263864160302524, 0.26690401508436334]\n",
            "# 47 \tExemplo: A man in a blue shirt carrying a surfboard while standing in the ocean .                              \tAvaliação:  [0.6882472016116853, 0.6187088159078515, 0.4858671038559722, 0.20341829039890905]\n",
            "# 48 \tExemplo: A white bed with a floral pattern sign mounted on it .                                                \tAvaliação:  [0.39735970711951313, 0.2598414203059447, 0.10079037376973914, 0.05779779204056156]\n",
            "# 49 \tExemplo: The two men are playing a game of soccer ball .                                                       \tAvaliação:  [0.45014617508912413, 0.32323518297936166, 0.2111187176080899, 0.10442329545559932]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOr1E34CnJ_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43af950-7e10-47ee-913d-585442c4c436"
      },
      "source": [
        "%%time\n",
        "print(\"Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com MLE\")\n",
        "# controle de qualidade da educação\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com MLE\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5513005877690402\n",
            "2 200 0.5529753989584019\n",
            "2 300 0.5592306944409703\n",
            "2 400 0.5595382814981565\n",
            "2 500 0.5601664492111109\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5601664492111109 \n",
            "\n",
            "3 100 0.4606382121619048\n",
            "3 200 0.4618684565582859\n",
            "3 300 0.46878096063362346\n",
            "3 400 0.47007795098469557\n",
            "3 500 0.47195595945252483\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.47195595945252483 \n",
            "\n",
            "4 100 0.3517695060056129\n",
            "4 200 0.3559383287399828\n",
            "4 300 0.3613050667937825\n",
            "4 400 0.3618204616411319\n",
            "4 500 0.3652760221418807\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.3652760221418807 \n",
            "\n",
            "5 100 0.23378122392990164\n",
            "5 200 0.24110267354895967\n",
            "5 300 0.24716420870391498\n",
            "5 400 0.24830012621073533\n",
            "5 500 0.25284693317639867\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.25284693317639867 \n",
            "\n",
            "CPU times: user 5min 43s, sys: 732 ms, total: 5min 43s\n",
            "Wall time: 5min 46s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5601664492111109,\n",
              " 0.47195595945252483,\n",
              " 0.3652760221418807,\n",
              " 0.25284693317639867]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdrWQfpV7bie"
      },
      "source": [
        "Pré-treinamento do discriminador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVypqCS4ucWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba6d33a-4d6e-49f8-fc58-7c8ffb8f2d73"
      },
      "source": [
        "%%time\n",
        "# pré-treinamento do discriminador\n",
        "print('Iniciando o treinamento do discriminador...')\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters()) # , lr=0.0001\n",
        "# dis_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-5)#0.001\n",
        "# dis_optimizer = optim.Adadelta(gen.parameters())\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())#, lr=0.0001)#, weight_decay=1e-5)\n",
        "#, weight_decay=1e-5) # regularização\n",
        "train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, DIS_TRAIN_ITERATIONS, DIS_TRAIN_EPOCHS)# 25, 1 | (15, 3), (25, 1)\n",
        "\n",
        "# salvando o resultado da aprendizagem\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_pretraining_dis.pytorch')\n",
        "\n",
        "# ANTES DO TREINO: val_acc = 0.5230\n",
        "# d-step 50 epoch 1 : .......... average_loss = 0.2859, train_acc = 0.9136, val_acc = 0.5240"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o treinamento do discriminador...\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.4396, train_acc = 0.8496, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.3491, train_acc = 0.8884, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.3403, train_acc = 0.8904, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.3445, train_acc = 0.8877, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.3305, train_acc = 0.8912, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 6 epoch 1 : .......... average_loss = 0.3381, train_acc = 0.8879, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 7 epoch 1 : .......... average_loss = 0.3319, train_acc = 0.8864, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 8 epoch 1 : .......... average_loss = 0.3292, train_acc = 0.8880, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 9 epoch 1 : .......... average_loss = 0.3176, train_acc = 0.8921, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 10 epoch 1 : .......... average_loss = 0.3232, train_acc = 0.8883, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 11 epoch 1 : .......... average_loss = 0.3253, train_acc = 0.8871, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 12 epoch 1 : .......... average_loss = 0.3192, train_acc = 0.8898, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 13 epoch 1 : .......... average_loss = 0.3133, train_acc = 0.8913, val_acc = 0.5010\n",
            "ANTES DO TREINO: val_acc = 0.5010\n",
            "d-step 14 epoch 1 : .......... average_loss = 0.3191, train_acc = 0.8893, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 15 epoch 1 : .......... average_loss = 0.3212, train_acc = 0.8878, val_acc = 0.5020\n",
            "ANTES DO TREINO: val_acc = 0.5010\n",
            "d-step 16 epoch 1 : .......... average_loss = 0.3215, train_acc = 0.8877, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 17 epoch 1 : .......... average_loss = 0.3130, train_acc = 0.8901, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 18 epoch 1 : .......... average_loss = 0.3090, train_acc = 0.8933, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 19 epoch 1 : .......... average_loss = 0.3271, train_acc = 0.8837, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 20 epoch 1 : .......... average_loss = 0.3141, train_acc = 0.8882, val_acc = 0.5000\n",
            "ANTES DO TREINO: val_acc = 0.5000\n",
            "d-step 21 epoch 1 : .......... average_loss = 0.3164, train_acc = 0.8903, val_acc = 0.5010\n",
            "ANTES DO TREINO: val_acc = 0.5010\n",
            "d-step 22 epoch 1 : .......... average_loss = 0.3218, train_acc = 0.8840, val_acc = 0.5010\n",
            "ANTES DO TREINO: val_acc = 0.5010\n",
            "d-step 23 epoch 1 : .......... average_loss = 0.3074, train_acc = 0.8911, val_acc = 0.5010\n",
            "ANTES DO TREINO: val_acc = 0.5010\n",
            "d-step 24 epoch 1 : .......... average_loss = 0.3104, train_acc = 0.8888, val_acc = 0.5030\n",
            "ANTES DO TREINO: val_acc = 0.5030\n",
            "d-step 25 epoch 1 : .......... average_loss = 0.3088, train_acc = 0.8900, val_acc = 0.5030\n",
            "ANTES DO TREINO: val_acc = 0.5020\n",
            "d-step 26 epoch 1 : .......... average_loss = 0.3107, train_acc = 0.8893, val_acc = 0.5100\n",
            "ANTES DO TREINO: val_acc = 0.5100\n",
            "d-step 27 epoch 1 : .......... average_loss = 0.3070, train_acc = 0.8904, val_acc = 0.5120\n",
            "ANTES DO TREINO: val_acc = 0.5100\n",
            "d-step 28 epoch 1 : .......... average_loss = 0.2996, train_acc = 0.8934, val_acc = 0.5180\n",
            "ANTES DO TREINO: val_acc = 0.5170\n",
            "d-step 29 epoch 1 : .......... average_loss = 0.3040, train_acc = 0.8912, val_acc = 0.5160\n",
            "ANTES DO TREINO: val_acc = 0.5130\n",
            "d-step 30 epoch 1 : .......... average_loss = 0.3025, train_acc = 0.8902, val_acc = 0.5360\n",
            "ANTES DO TREINO: val_acc = 0.5430\n",
            "d-step 31 epoch 1 : .......... average_loss = 0.3004, train_acc = 0.8932, val_acc = 0.5160\n",
            "ANTES DO TREINO: val_acc = 0.5190\n",
            "d-step 32 epoch 1 : .......... average_loss = 0.2962, train_acc = 0.8954, val_acc = 0.5320\n",
            "ANTES DO TREINO: val_acc = 0.5300\n",
            "d-step 33 epoch 1 : .......... average_loss = 0.2951, train_acc = 0.8925, val_acc = 0.5580\n",
            "ANTES DO TREINO: val_acc = 0.5490\n",
            "d-step 34 epoch 1 : .......... average_loss = 0.2995, train_acc = 0.8911, val_acc = 0.5280\n",
            "ANTES DO TREINO: val_acc = 0.5310\n",
            "d-step 35 epoch 1 : .......... average_loss = 0.2938, train_acc = 0.8939, val_acc = 0.5800\n",
            "ANTES DO TREINO: val_acc = 0.5780\n",
            "d-step 36 epoch 1 : .......... average_loss = 0.2964, train_acc = 0.8959, val_acc = 0.5490\n",
            "ANTES DO TREINO: val_acc = 0.5440\n",
            "d-step 37 epoch 1 : .......... average_loss = 0.2991, train_acc = 0.8934, val_acc = 0.5510\n",
            "ANTES DO TREINO: val_acc = 0.5580\n",
            "d-step 38 epoch 1 : .......... average_loss = 0.2920, train_acc = 0.8964, val_acc = 0.5810\n",
            "ANTES DO TREINO: val_acc = 0.5810\n",
            "d-step 39 epoch 1 : .......... average_loss = 0.2819, train_acc = 0.9017, val_acc = 0.5890\n",
            "ANTES DO TREINO: val_acc = 0.5850\n",
            "d-step 40 epoch 1 : .......... average_loss = 0.2861, train_acc = 0.8988, val_acc = 0.6140\n",
            "ANTES DO TREINO: val_acc = 0.6130\n",
            "d-step 41 epoch 1 : .......... average_loss = 0.2833, train_acc = 0.9012, val_acc = 0.5960\n",
            "ANTES DO TREINO: val_acc = 0.5940\n",
            "d-step 42 epoch 1 : .......... average_loss = 0.2722, train_acc = 0.9058, val_acc = 0.6000\n",
            "ANTES DO TREINO: val_acc = 0.6070\n",
            "d-step 43 epoch 1 : .......... average_loss = 0.2760, train_acc = 0.9024, val_acc = 0.5730\n",
            "ANTES DO TREINO: val_acc = 0.5740\n",
            "d-step 44 epoch 1 : .......... average_loss = 0.2722, train_acc = 0.9042, val_acc = 0.6050\n",
            "ANTES DO TREINO: val_acc = 0.6090\n",
            "d-step 45 epoch 1 : .......... average_loss = 0.2785, train_acc = 0.9026, val_acc = 0.6110\n",
            "ANTES DO TREINO: val_acc = 0.6140\n",
            "d-step 46 epoch 1 : .......... average_loss = 0.2766, train_acc = 0.9023, val_acc = 0.6020\n",
            "ANTES DO TREINO: val_acc = 0.6020\n",
            "d-step 47 epoch 1 : .......... average_loss = 0.2789, train_acc = 0.9032, val_acc = 0.6050\n",
            "ANTES DO TREINO: val_acc = 0.6010\n",
            "d-step 48 epoch 1 : .......... average_loss = 0.2737, train_acc = 0.9043, val_acc = 0.6200\n",
            "ANTES DO TREINO: val_acc = 0.6200\n",
            "d-step 49 epoch 1 : .......... average_loss = 0.2870, train_acc = 0.8978, val_acc = 0.5680\n",
            "ANTES DO TREINO: val_acc = 0.5740\n",
            "d-step 50 epoch 1 : .......... average_loss = 0.2781, train_acc = 0.9040, val_acc = 0.5750\n",
            "ANTES DO TREINO: val_acc = 0.5770\n",
            "d-step 51 epoch 1 : .......... average_loss = 0.2745, train_acc = 0.9021, val_acc = 0.5980\n",
            "ANTES DO TREINO: val_acc = 0.6000\n",
            "d-step 52 epoch 1 : .......... average_loss = 0.2698, train_acc = 0.9061, val_acc = 0.6020\n",
            "ANTES DO TREINO: val_acc = 0.6050\n",
            "d-step 53 epoch 1 : .......... average_loss = 0.2739, train_acc = 0.9052, val_acc = 0.6330\n",
            "ANTES DO TREINO: val_acc = 0.6330\n",
            "d-step 54 epoch 1 : .......... average_loss = 0.2679, train_acc = 0.9075, val_acc = 0.6140\n",
            "ANTES DO TREINO: val_acc = 0.6160\n",
            "d-step 55 epoch 1 : .......... average_loss = 0.2722, train_acc = 0.9052, val_acc = 0.6070\n",
            "ANTES DO TREINO: val_acc = 0.6100\n",
            "d-step 56 epoch 1 : .......... average_loss = 0.2592, train_acc = 0.9100, val_acc = 0.6420\n",
            "ANTES DO TREINO: val_acc = 0.6420\n",
            "d-step 57 epoch 1 : .......... average_loss = 0.2659, train_acc = 0.9074, val_acc = 0.6260\n",
            "ANTES DO TREINO: val_acc = 0.6290\n",
            "d-step 58 epoch 1 : .......... average_loss = 0.2626, train_acc = 0.9097, val_acc = 0.6310\n",
            "ANTES DO TREINO: val_acc = 0.6310\n",
            "d-step 59 epoch 1 : .......... average_loss = 0.2617, train_acc = 0.9098, val_acc = 0.6360\n",
            "ANTES DO TREINO: val_acc = 0.6380\n",
            "d-step 60 epoch 1 : .......... average_loss = 0.2609, train_acc = 0.9093, val_acc = 0.6510\n",
            "ANTES DO TREINO: val_acc = 0.6430\n",
            "d-step 61 epoch 1 : .......... average_loss = 0.2704, train_acc = 0.9064, val_acc = 0.6350\n",
            "ANTES DO TREINO: val_acc = 0.6330\n",
            "d-step 62 epoch 1 : .......... average_loss = 0.2649, train_acc = 0.9074, val_acc = 0.5730\n",
            "ANTES DO TREINO: val_acc = 0.5790\n",
            "d-step 63 epoch 1 : .......... average_loss = 0.2615, train_acc = 0.9108, val_acc = 0.6470\n",
            "ANTES DO TREINO: val_acc = 0.6430\n",
            "d-step 64 epoch 1 : .......... average_loss = 0.2615, train_acc = 0.9112, val_acc = 0.6130\n",
            "ANTES DO TREINO: val_acc = 0.6210\n",
            "d-step 65 epoch 1 : .......... average_loss = 0.2502, train_acc = 0.9143, val_acc = 0.6470\n",
            "ANTES DO TREINO: val_acc = 0.6430\n",
            "d-step 66 epoch 1 : .......... average_loss = 0.2528, train_acc = 0.9155, val_acc = 0.6260\n",
            "ANTES DO TREINO: val_acc = 0.6240\n",
            "d-step 67 epoch 1 : .......... average_loss = 0.2601, train_acc = 0.9101, val_acc = 0.6520\n",
            "ANTES DO TREINO: val_acc = 0.6530\n",
            "d-step 68 epoch 1 : .......... average_loss = 0.2475, train_acc = 0.9163, val_acc = 0.6750\n",
            "ANTES DO TREINO: val_acc = 0.6740\n",
            "d-step 69 epoch 1 : .......... average_loss = 0.2538, train_acc = 0.9135, val_acc = 0.6520\n",
            "ANTES DO TREINO: val_acc = 0.6490\n",
            "d-step 70 epoch 1 : .......... average_loss = 0.2566, train_acc = 0.9111, val_acc = 0.6310\n",
            "ANTES DO TREINO: val_acc = 0.6320\n",
            "d-step 71 epoch 1 : .......... average_loss = 0.2557, train_acc = 0.9115, val_acc = 0.6540\n",
            "ANTES DO TREINO: val_acc = 0.6600\n",
            "d-step 72 epoch 1 : .......... average_loss = 0.2543, train_acc = 0.9134, val_acc = 0.6790\n",
            "ANTES DO TREINO: val_acc = 0.6740\n",
            "d-step 73 epoch 1 : .......... average_loss = 0.2470, train_acc = 0.9159, val_acc = 0.6620\n",
            "ANTES DO TREINO: val_acc = 0.6580\n",
            "d-step 74 epoch 1 : .......... average_loss = 0.2544, train_acc = 0.9142, val_acc = 0.6910\n",
            "ANTES DO TREINO: val_acc = 0.6910\n",
            "d-step 75 epoch 1 : .......... average_loss = 0.2539, train_acc = 0.9139, val_acc = 0.6750\n",
            "ANTES DO TREINO: val_acc = 0.6780\n",
            "d-step 76 epoch 1 : .......... average_loss = 0.2542, train_acc = 0.9141, val_acc = 0.6790\n",
            "ANTES DO TREINO: val_acc = 0.6680\n",
            "d-step 77 epoch 1 : .......... average_loss = 0.2493, train_acc = 0.9159, val_acc = 0.6790\n",
            "ANTES DO TREINO: val_acc = 0.6750\n",
            "d-step 78 epoch 1 : .......... average_loss = 0.2516, train_acc = 0.9149, val_acc = 0.6650\n",
            "ANTES DO TREINO: val_acc = 0.6710\n",
            "d-step 79 epoch 1 : .......... average_loss = 0.2413, train_acc = 0.9182, val_acc = 0.6650\n",
            "ANTES DO TREINO: val_acc = 0.6630\n",
            "d-step 80 epoch 1 : .......... average_loss = 0.2479, train_acc = 0.9163, val_acc = 0.6620\n",
            "ANTES DO TREINO: val_acc = 0.6650\n",
            "d-step 81 epoch 1 : .......... average_loss = 0.2468, train_acc = 0.9176, val_acc = 0.6960\n",
            "ANTES DO TREINO: val_acc = 0.6880\n",
            "d-step 82 epoch 1 : .......... average_loss = 0.2411, train_acc = 0.9191, val_acc = 0.6720\n",
            "ANTES DO TREINO: val_acc = 0.6760\n",
            "d-step 83 epoch 1 : .......... average_loss = 0.2506, train_acc = 0.9169, val_acc = 0.6670\n",
            "ANTES DO TREINO: val_acc = 0.6630\n",
            "d-step 84 epoch 1 : .......... average_loss = 0.2474, train_acc = 0.9164, val_acc = 0.6800\n",
            "ANTES DO TREINO: val_acc = 0.6810\n",
            "d-step 85 epoch 1 : .......... average_loss = 0.2417, train_acc = 0.9206, val_acc = 0.6700\n",
            "ANTES DO TREINO: val_acc = 0.6720\n",
            "d-step 86 epoch 1 : .......... average_loss = 0.2429, train_acc = 0.9176, val_acc = 0.6910\n",
            "ANTES DO TREINO: val_acc = 0.6820\n",
            "d-step 87 epoch 1 : .......... average_loss = 0.2459, train_acc = 0.9171, val_acc = 0.6730\n",
            "ANTES DO TREINO: val_acc = 0.6680\n",
            "d-step 88 epoch 1 : .......... average_loss = 0.2426, train_acc = 0.9185, val_acc = 0.6850\n",
            "ANTES DO TREINO: val_acc = 0.6780\n",
            "d-step 89 epoch 1 : .......... average_loss = 0.2491, train_acc = 0.9161, val_acc = 0.6820\n",
            "ANTES DO TREINO: val_acc = 0.6880\n",
            "d-step 90 epoch 1 : .......... average_loss = 0.2489, train_acc = 0.9164, val_acc = 0.6960\n",
            "ANTES DO TREINO: val_acc = 0.6920\n",
            "d-step 91 epoch 1 : .......... average_loss = 0.2387, train_acc = 0.9221, val_acc = 0.6880\n",
            "ANTES DO TREINO: val_acc = 0.6870\n",
            "d-step 92 epoch 1 : .......... average_loss = 0.2402, train_acc = 0.9197, val_acc = 0.6760\n",
            "ANTES DO TREINO: val_acc = 0.6750\n",
            "d-step 93 epoch 1 : .......... average_loss = 0.2346, train_acc = 0.9219, val_acc = 0.6790\n",
            "ANTES DO TREINO: val_acc = 0.6780\n",
            "d-step 94 epoch 1 : .......... average_loss = 0.2340, train_acc = 0.9230, val_acc = 0.6630\n",
            "ANTES DO TREINO: val_acc = 0.6640\n",
            "d-step 95 epoch 1 : .......... average_loss = 0.2379, train_acc = 0.9203, val_acc = 0.6620\n",
            "ANTES DO TREINO: val_acc = 0.6580\n",
            "d-step 96 epoch 1 : .......... average_loss = 0.2344, train_acc = 0.9215, val_acc = 0.6910\n",
            "ANTES DO TREINO: val_acc = 0.6920\n",
            "d-step 97 epoch 1 : .......... average_loss = 0.2471, train_acc = 0.9176, val_acc = 0.6580\n",
            "ANTES DO TREINO: val_acc = 0.6650\n",
            "d-step 98 epoch 1 : .......... average_loss = 0.2349, train_acc = 0.9230, val_acc = 0.6830\n",
            "ANTES DO TREINO: val_acc = 0.6870\n",
            "d-step 99 epoch 1 : .......... average_loss = 0.2394, train_acc = 0.9205, val_acc = 0.6710\n",
            "ANTES DO TREINO: val_acc = 0.6730\n",
            "d-step 100 epoch 1 : .......... average_loss = 0.2333, train_acc = 0.9235, val_acc = 0.6860\n",
            "ANTES DO TREINO: val_acc = 0.6800\n",
            "d-step 101 epoch 1 : .......... average_loss = 0.2387, train_acc = 0.9203, val_acc = 0.6570\n",
            "ANTES DO TREINO: val_acc = 0.6600\n",
            "d-step 102 epoch 1 : .......... average_loss = 0.2282, train_acc = 0.9254, val_acc = 0.6840\n",
            "ANTES DO TREINO: val_acc = 0.6870\n",
            "d-step 103 epoch 1 : .......... average_loss = 0.2332, train_acc = 0.9230, val_acc = 0.6970\n",
            "ANTES DO TREINO: val_acc = 0.6970\n",
            "d-step 104 epoch 1 : .......... average_loss = 0.2286, train_acc = 0.9260, val_acc = 0.7100\n",
            "ANTES DO TREINO: val_acc = 0.7090\n",
            "d-step 105 epoch 1 : .......... average_loss = 0.2295, train_acc = 0.9243, val_acc = 0.7080\n",
            "ANTES DO TREINO: val_acc = 0.7050\n",
            "d-step 106 epoch 1 : .......... average_loss = 0.2314, train_acc = 0.9220, val_acc = 0.7140\n",
            "ANTES DO TREINO: val_acc = 0.7050\n",
            "d-step 107 epoch 1 : .......... average_loss = 0.2277, train_acc = 0.9263, val_acc = 0.6830\n",
            "ANTES DO TREINO: val_acc = 0.6840\n",
            "d-step 108 epoch 1 : .......... average_loss = 0.2237, train_acc = 0.9274, val_acc = 0.6730\n",
            "ANTES DO TREINO: val_acc = 0.6800\n",
            "d-step 109 epoch 1 : .......... average_loss = 0.2221, train_acc = 0.9279, val_acc = 0.6960\n",
            "ANTES DO TREINO: val_acc = 0.6960\n",
            "d-step 110 epoch 1 : .......... average_loss = 0.2334, train_acc = 0.9242, val_acc = 0.6760\n",
            "ANTES DO TREINO: val_acc = 0.6750\n",
            "d-step 111 epoch 1 : .......... average_loss = 0.2324, train_acc = 0.9251, val_acc = 0.6550\n",
            "ANTES DO TREINO: val_acc = 0.6510\n",
            "d-step 112 epoch 1 : .......... average_loss = 0.2258, train_acc = 0.9272, val_acc = 0.6940\n",
            "ANTES DO TREINO: val_acc = 0.6930\n",
            "d-step 113 epoch 1 : .......... average_loss = 0.2275, train_acc = 0.9280, val_acc = 0.7100\n",
            "ANTES DO TREINO: val_acc = 0.7070\n",
            "d-step 114 epoch 1 : .......... average_loss = 0.2268, train_acc = 0.9275, val_acc = 0.7080\n",
            "ANTES DO TREINO: val_acc = 0.7070\n",
            "d-step 115 epoch 1 : .......... average_loss = 0.2226, train_acc = 0.9287, val_acc = 0.7090\n",
            "ANTES DO TREINO: val_acc = 0.7060\n",
            "d-step 116 epoch 1 : .......... average_loss = 0.2302, train_acc = 0.9269, val_acc = 0.6990\n",
            "ANTES DO TREINO: val_acc = 0.6980\n",
            "d-step 117 epoch 1 : .......... average_loss = 0.2200, train_acc = 0.9295, val_acc = 0.6810\n",
            "ANTES DO TREINO: val_acc = 0.6850\n",
            "d-step 118 epoch 1 : .......... average_loss = 0.2236, train_acc = 0.9286, val_acc = 0.7100\n",
            "ANTES DO TREINO: val_acc = 0.7050\n",
            "d-step 119 epoch 1 : .......... average_loss = 0.2201, train_acc = 0.9287, val_acc = 0.7080\n",
            "ANTES DO TREINO: val_acc = 0.7090\n",
            "d-step 120 epoch 1 : .......... average_loss = 0.2180, train_acc = 0.9304, val_acc = 0.7020\n",
            "ANTES DO TREINO: val_acc = 0.7040\n",
            "d-step 121 epoch 1 : .......... average_loss = 0.2234, train_acc = 0.9281, val_acc = 0.7310\n",
            "ANTES DO TREINO: val_acc = 0.7270\n",
            "d-step 122 epoch 1 : .......... average_loss = 0.2174, train_acc = 0.9296, val_acc = 0.6980\n",
            "ANTES DO TREINO: val_acc = 0.7040\n",
            "d-step 123 epoch 1 : .......... average_loss = 0.2203, train_acc = 0.9304, val_acc = 0.7360\n",
            "ANTES DO TREINO: val_acc = 0.7330\n",
            "d-step 124 epoch 1 : .......... average_loss = 0.2200, train_acc = 0.9299, val_acc = 0.7230\n",
            "ANTES DO TREINO: val_acc = 0.7270\n",
            "d-step 125 epoch 1 : .......... average_loss = 0.2111, train_acc = 0.9337, val_acc = 0.7230\n",
            "ANTES DO TREINO: val_acc = 0.7150\n",
            "d-step 126 epoch 1 : .......... average_loss = 0.2258, train_acc = 0.9276, val_acc = 0.7130\n",
            "ANTES DO TREINO: val_acc = 0.7160\n",
            "d-step 127 epoch 1 : .......... average_loss = 0.2193, train_acc = 0.9290, val_acc = 0.7310\n",
            "ANTES DO TREINO: val_acc = 0.7270\n",
            "d-step 128 epoch 1 : .......... average_loss = 0.2106, train_acc = 0.9324, val_acc = 0.7220\n",
            "ANTES DO TREINO: val_acc = 0.7200\n",
            "d-step 129 epoch 1 : .......... average_loss = 0.2252, train_acc = 0.9272, val_acc = 0.7390\n",
            "ANTES DO TREINO: val_acc = 0.7440\n",
            "d-step 130 epoch 1 : .......... average_loss = 0.2166, train_acc = 0.9304, val_acc = 0.6710\n",
            "ANTES DO TREINO: val_acc = 0.6790\n",
            "d-step 131 epoch 1 : .......... average_loss = 0.2144, train_acc = 0.9325, val_acc = 0.7350\n",
            "ANTES DO TREINO: val_acc = 0.7360\n",
            "d-step 132 epoch 1 : .......... average_loss = 0.2149, train_acc = 0.9321, val_acc = 0.7030\n",
            "ANTES DO TREINO: val_acc = 0.7030\n",
            "d-step 133 epoch 1 : .......... average_loss = 0.2206, train_acc = 0.9293, val_acc = 0.7300\n",
            "ANTES DO TREINO: val_acc = 0.7310\n",
            "d-step 134 epoch 1 : .......... average_loss = 0.2048, train_acc = 0.9374, val_acc = 0.7270\n",
            "ANTES DO TREINO: val_acc = 0.7280\n",
            "d-step 135 epoch 1 : .......... average_loss = 0.2229, train_acc = 0.9295, val_acc = 0.7050\n",
            "ANTES DO TREINO: val_acc = 0.7060\n",
            "d-step 136 epoch 1 : .......... average_loss = 0.2138, train_acc = 0.9318, val_acc = 0.6950\n",
            "ANTES DO TREINO: val_acc = 0.6980\n",
            "d-step 137 epoch 1 : .......... average_loss = 0.2109, train_acc = 0.9332, val_acc = 0.7380\n",
            "ANTES DO TREINO: val_acc = 0.7340\n",
            "d-step 138 epoch 1 : .......... average_loss = 0.2194, train_acc = 0.9295, val_acc = 0.7420\n",
            "ANTES DO TREINO: val_acc = 0.7430\n",
            "d-step 139 epoch 1 : .......... average_loss = 0.2137, train_acc = 0.9323, val_acc = 0.7310\n",
            "ANTES DO TREINO: val_acc = 0.7340\n",
            "d-step 140 epoch 1 : .......... average_loss = 0.2215, train_acc = 0.9294, val_acc = 0.7480\n",
            "ANTES DO TREINO: val_acc = 0.7470\n",
            "d-step 141 epoch 1 : .......... average_loss = 0.2079, train_acc = 0.9348, val_acc = 0.7440\n",
            "ANTES DO TREINO: val_acc = 0.7510\n",
            "d-step 142 epoch 1 : .......... average_loss = 0.2129, train_acc = 0.9345, val_acc = 0.7270\n",
            "ANTES DO TREINO: val_acc = 0.7340\n",
            "d-step 143 epoch 1 : .......... average_loss = 0.2009, train_acc = 0.9377, val_acc = 0.7150\n",
            "ANTES DO TREINO: val_acc = 0.7160\n",
            "d-step 144 epoch 1 : .......... average_loss = 0.2053, train_acc = 0.9359, val_acc = 0.7320\n",
            "ANTES DO TREINO: val_acc = 0.7360\n",
            "d-step 145 epoch 1 : .......... average_loss = 0.2080, train_acc = 0.9346, val_acc = 0.7520\n",
            "ANTES DO TREINO: val_acc = 0.7470\n",
            "d-step 146 epoch 1 : .......... average_loss = 0.2079, train_acc = 0.9348, val_acc = 0.7260\n",
            "ANTES DO TREINO: val_acc = 0.7240\n",
            "d-step 147 epoch 1 : .......... average_loss = 0.2027, train_acc = 0.9374, val_acc = 0.7430\n",
            "ANTES DO TREINO: val_acc = 0.7370\n",
            "d-step 148 epoch 1 : .......... average_loss = 0.2053, train_acc = 0.9365, val_acc = 0.7340\n",
            "ANTES DO TREINO: val_acc = 0.7350\n",
            "d-step 149 epoch 1 : .......... average_loss = 0.2036, train_acc = 0.9366, val_acc = 0.7130\n",
            "ANTES DO TREINO: val_acc = 0.7180\n",
            "d-step 150 epoch 1 : .......... average_loss = 0.2104, train_acc = 0.9338, val_acc = 0.7390\n",
            "ANTES DO TREINO: val_acc = 0.7350\n",
            "d-step 151 epoch 1 : .......... average_loss = 0.2079, train_acc = 0.9346, val_acc = 0.7570\n",
            "ANTES DO TREINO: val_acc = 0.7520\n",
            "d-step 152 epoch 1 : .......... average_loss = 0.2068, train_acc = 0.9353, val_acc = 0.7390\n",
            "ANTES DO TREINO: val_acc = 0.7360\n",
            "d-step 153 epoch 1 : .......... average_loss = 0.2090, train_acc = 0.9357, val_acc = 0.7220\n",
            "ANTES DO TREINO: val_acc = 0.7310\n",
            "d-step 154 epoch 1 : .......... average_loss = 0.2117, train_acc = 0.9345, val_acc = 0.7470\n",
            "ANTES DO TREINO: val_acc = 0.7440\n",
            "d-step 155 epoch 1 : .......... average_loss = 0.2049, train_acc = 0.9360, val_acc = 0.7160\n",
            "ANTES DO TREINO: val_acc = 0.7250\n",
            "d-step 156 epoch 1 : .......... average_loss = 0.2063, train_acc = 0.9352, val_acc = 0.7650\n",
            "ANTES DO TREINO: val_acc = 0.7600\n",
            "d-step 157 epoch 1 : .......... average_loss = 0.2061, train_acc = 0.9365, val_acc = 0.7610\n",
            "ANTES DO TREINO: val_acc = 0.7580\n",
            "d-step 158 epoch 1 : .......... average_loss = 0.2032, train_acc = 0.9373, val_acc = 0.7540\n",
            "ANTES DO TREINO: val_acc = 0.7500\n",
            "d-step 159 epoch 1 : .......... average_loss = 0.2038, train_acc = 0.9382, val_acc = 0.7460\n",
            "ANTES DO TREINO: val_acc = 0.7530\n",
            "d-step 160 epoch 1 : .......... average_loss = 0.1935, train_acc = 0.9409, val_acc = 0.7700\n",
            "ANTES DO TREINO: val_acc = 0.7710\n",
            "d-step 161 epoch 1 : .......... average_loss = 0.2034, train_acc = 0.9372, val_acc = 0.7430\n",
            "ANTES DO TREINO: val_acc = 0.7380\n",
            "d-step 162 epoch 1 : .......... average_loss = 0.2022, train_acc = 0.9372, val_acc = 0.7450\n",
            "ANTES DO TREINO: val_acc = 0.7490\n",
            "d-step 163 epoch 1 : .......... average_loss = 0.2051, train_acc = 0.9367, val_acc = 0.7480\n",
            "ANTES DO TREINO: val_acc = 0.7480\n",
            "d-step 164 epoch 1 : .......... average_loss = 0.2039, train_acc = 0.9365, val_acc = 0.7640\n",
            "ANTES DO TREINO: val_acc = 0.7650\n",
            "d-step 165 epoch 1 : .......... average_loss = 0.1977, train_acc = 0.9407, val_acc = 0.7170\n",
            "ANTES DO TREINO: val_acc = 0.7150\n",
            "d-step 166 epoch 1 : .......... average_loss = 0.1978, train_acc = 0.9397, val_acc = 0.7490\n",
            "ANTES DO TREINO: val_acc = 0.7540\n",
            "d-step 167 epoch 1 : .......... average_loss = 0.1964, train_acc = 0.9387, val_acc = 0.7610\n",
            "ANTES DO TREINO: val_acc = 0.7600\n",
            "d-step 168 epoch 1 : .......... average_loss = 0.2009, train_acc = 0.9379, val_acc = 0.7360\n",
            "ANTES DO TREINO: val_acc = 0.7380\n",
            "d-step 169 epoch 1 : .......... average_loss = 0.1992, train_acc = 0.9393, val_acc = 0.7480\n",
            "ANTES DO TREINO: val_acc = 0.7390\n",
            "d-step 170 epoch 1 : .......... average_loss = 0.2000, train_acc = 0.9389, val_acc = 0.7450\n",
            "ANTES DO TREINO: val_acc = 0.7370\n",
            "d-step 171 epoch 1 : .......... average_loss = 0.2035, train_acc = 0.9366, val_acc = 0.7700\n",
            "ANTES DO TREINO: val_acc = 0.7640\n",
            "d-step 172 epoch 1 : .......... average_loss = 0.2029, train_acc = 0.9376, val_acc = 0.7730\n",
            "ANTES DO TREINO: val_acc = 0.7760\n",
            "d-step 173 epoch 1 : .......... average_loss = 0.1892, train_acc = 0.9429, val_acc = 0.7530\n",
            "ANTES DO TREINO: val_acc = 0.7580\n",
            "d-step 174 epoch 1 : .......... average_loss = 0.1954, train_acc = 0.9408, val_acc = 0.7640\n",
            "ANTES DO TREINO: val_acc = 0.7620\n",
            "d-step 175 epoch 1 : .......... average_loss = 0.1972, train_acc = 0.9388, val_acc = 0.7500\n",
            "ANTES DO TREINO: val_acc = 0.7530\n",
            "d-step 176 epoch 1 : .......... average_loss = 0.1963, train_acc = 0.9410, val_acc = 0.7620\n",
            "ANTES DO TREINO: val_acc = 0.7750\n",
            "d-step 177 epoch 1 : .......... average_loss = 0.1973, train_acc = 0.9411, val_acc = 0.7400\n",
            "ANTES DO TREINO: val_acc = 0.7380\n",
            "d-step 178 epoch 1 : .......... average_loss = 0.1945, train_acc = 0.9408, val_acc = 0.7540\n",
            "ANTES DO TREINO: val_acc = 0.7560\n",
            "d-step 179 epoch 1 : .......... average_loss = 0.1921, train_acc = 0.9425, val_acc = 0.7710\n",
            "ANTES DO TREINO: val_acc = 0.7690\n",
            "d-step 180 epoch 1 : .......... average_loss = 0.1982, train_acc = 0.9399, val_acc = 0.7700\n",
            "ANTES DO TREINO: val_acc = 0.7700\n",
            "d-step 181 epoch 1 : .......... average_loss = 0.1937, train_acc = 0.9412, val_acc = 0.7580\n",
            "ANTES DO TREINO: val_acc = 0.7490\n",
            "d-step 182 epoch 1 : .......... average_loss = 0.2013, train_acc = 0.9386, val_acc = 0.7560\n",
            "ANTES DO TREINO: val_acc = 0.7590\n",
            "d-step 183 epoch 1 : .......... average_loss = 0.1915, train_acc = 0.9415, val_acc = 0.7810\n",
            "ANTES DO TREINO: val_acc = 0.7770\n",
            "d-step 184 epoch 1 : .......... average_loss = 0.1898, train_acc = 0.9423, val_acc = 0.7510\n",
            "ANTES DO TREINO: val_acc = 0.7500\n",
            "d-step 185 epoch 1 : .......... average_loss = 0.1847, train_acc = 0.9449, val_acc = 0.7600\n",
            "ANTES DO TREINO: val_acc = 0.7640\n",
            "d-step 186 epoch 1 : .......... average_loss = 0.1878, train_acc = 0.9433, val_acc = 0.7840\n",
            "ANTES DO TREINO: val_acc = 0.7820\n",
            "d-step 187 epoch 1 : .......... average_loss = 0.1921, train_acc = 0.9431, val_acc = 0.7710\n",
            "ANTES DO TREINO: val_acc = 0.7670\n",
            "d-step 188 epoch 1 : .......... average_loss = 0.1914, train_acc = 0.9423, val_acc = 0.7480\n",
            "ANTES DO TREINO: val_acc = 0.7530\n",
            "d-step 189 epoch 1 : .......... average_loss = 0.1959, train_acc = 0.9404, val_acc = 0.7570\n",
            "ANTES DO TREINO: val_acc = 0.7570\n",
            "d-step 190 epoch 1 : .......... average_loss = 0.1881, train_acc = 0.9443, val_acc = 0.7240\n",
            "ANTES DO TREINO: val_acc = 0.7280\n",
            "d-step 191 epoch 1 : .......... average_loss = 0.1917, train_acc = 0.9421, val_acc = 0.7560\n",
            "ANTES DO TREINO: val_acc = 0.7530\n",
            "d-step 192 epoch 1 : .......... average_loss = 0.1858, train_acc = 0.9448, val_acc = 0.7730\n",
            "ANTES DO TREINO: val_acc = 0.7750\n",
            "d-step 193 epoch 1 : .......... average_loss = 0.1826, train_acc = 0.9465, val_acc = 0.7570\n",
            "ANTES DO TREINO: val_acc = 0.7610\n",
            "d-step 194 epoch 1 : .......... average_loss = 0.1891, train_acc = 0.9434, val_acc = 0.7730\n",
            "ANTES DO TREINO: val_acc = 0.7770\n",
            "d-step 195 epoch 1 : .......... average_loss = 0.1893, train_acc = 0.9434, val_acc = 0.7470\n",
            "ANTES DO TREINO: val_acc = 0.7480\n",
            "d-step 196 epoch 1 : .......... average_loss = 0.1926, train_acc = 0.9417, val_acc = 0.7590\n",
            "ANTES DO TREINO: val_acc = 0.7610\n",
            "d-step 197 epoch 1 : .......... average_loss = 0.1882, train_acc = 0.9440, val_acc = 0.7640\n",
            "ANTES DO TREINO: val_acc = 0.7650\n",
            "d-step 198 epoch 1 : .......... average_loss = 0.1825, train_acc = 0.9467, val_acc = 0.7790\n",
            "ANTES DO TREINO: val_acc = 0.7870\n",
            "d-step 199 epoch 1 : .......... average_loss = 0.1862, train_acc = 0.9443, val_acc = 0.7670\n",
            "ANTES DO TREINO: val_acc = 0.7650\n",
            "d-step 200 epoch 1 : .......... average_loss = 0.1869, train_acc = 0.9435, val_acc = 0.7720\n",
            "ANTES DO TREINO: val_acc = 0.7710\n",
            "d-step 201 epoch 1 : .......... average_loss = 0.1911, train_acc = 0.9417, val_acc = 0.7660\n",
            "ANTES DO TREINO: val_acc = 0.7620\n",
            "d-step 202 epoch 1 : .......... average_loss = 0.1867, train_acc = 0.9431, val_acc = 0.7800\n",
            "ANTES DO TREINO: val_acc = 0.7770\n",
            "d-step 203 epoch 1 : .......... average_loss = 0.1843, train_acc = 0.9445, val_acc = 0.7540\n",
            "ANTES DO TREINO: val_acc = 0.7520\n",
            "d-step 204 epoch 1 : .......... average_loss = 0.1794, train_acc = 0.9469, val_acc = 0.7890\n",
            "ANTES DO TREINO: val_acc = 0.7850\n",
            "d-step 205 epoch 1 : .......... average_loss = 0.1927, train_acc = 0.9433, val_acc = 0.7720\n",
            "ANTES DO TREINO: val_acc = 0.7760\n",
            "d-step 206 epoch 1 : .......... average_loss = 0.1886, train_acc = 0.9426, val_acc = 0.7840\n",
            "ANTES DO TREINO: val_acc = 0.7880\n",
            "d-step 207 epoch 1 : .......... average_loss = 0.1827, train_acc = 0.9463, val_acc = 0.7420\n",
            "ANTES DO TREINO: val_acc = 0.7420\n",
            "d-step 208 epoch 1 : .......... average_loss = 0.1861, train_acc = 0.9448, val_acc = 0.7840\n",
            "ANTES DO TREINO: val_acc = 0.7830\n",
            "d-step 209 epoch 1 : .......... average_loss = 0.1836, train_acc = 0.9447, val_acc = 0.7790\n",
            "ANTES DO TREINO: val_acc = 0.7850\n",
            "d-step 210 epoch 1 : .......... average_loss = 0.1780, train_acc = 0.9479, val_acc = 0.7670\n",
            "ANTES DO TREINO: val_acc = 0.7710\n",
            "d-step 211 epoch 1 : .......... average_loss = 0.1761, train_acc = 0.9490, val_acc = 0.7820\n",
            "ANTES DO TREINO: val_acc = 0.7750\n",
            "d-step 212 epoch 1 : .......... average_loss = 0.1816, train_acc = 0.9466, val_acc = 0.7700\n",
            "ANTES DO TREINO: val_acc = 0.7610\n",
            "d-step 213 epoch 1 : .......... average_loss = 0.1805, train_acc = 0.9469, val_acc = 0.7650\n",
            "ANTES DO TREINO: val_acc = 0.7610\n",
            "d-step 214 epoch 1 : .......... average_loss = 0.1793, train_acc = 0.9472, val_acc = 0.7650\n",
            "ANTES DO TREINO: val_acc = 0.7650\n",
            "d-step 215 epoch 1 : .......... average_loss = 0.1743, train_acc = 0.9480, val_acc = 0.7800\n",
            "ANTES DO TREINO: val_acc = 0.7730\n",
            "d-step 216 epoch 1 : .......... average_loss = 0.1824, train_acc = 0.9453, val_acc = 0.7490\n",
            "ANTES DO TREINO: val_acc = 0.7470\n",
            "d-step 217 epoch 1 : .......... average_loss = 0.1797, train_acc = 0.9470, val_acc = 0.7860\n",
            "ANTES DO TREINO: val_acc = 0.7970\n",
            "d-step 218 epoch 1 : .......... average_loss = 0.1793, train_acc = 0.9469, val_acc = 0.7820\n",
            "ANTES DO TREINO: val_acc = 0.7750\n",
            "d-step 219 epoch 1 : .......... average_loss = 0.1832, train_acc = 0.9458, val_acc = 0.7910\n",
            "ANTES DO TREINO: val_acc = 0.7950\n",
            "d-step 220 epoch 1 : .......... average_loss = 0.1787, train_acc = 0.9467, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7840\n",
            "d-step 221 epoch 1 : .......... average_loss = 0.1784, train_acc = 0.9479, val_acc = 0.7820\n",
            "ANTES DO TREINO: val_acc = 0.7800\n",
            "d-step 222 epoch 1 : .......... average_loss = 0.1819, train_acc = 0.9467, val_acc = 0.7560\n",
            "ANTES DO TREINO: val_acc = 0.7520\n",
            "d-step 223 epoch 1 : .......... average_loss = 0.1840, train_acc = 0.9465, val_acc = 0.7830\n",
            "ANTES DO TREINO: val_acc = 0.7880\n",
            "d-step 224 epoch 1 : .......... average_loss = 0.1793, train_acc = 0.9478, val_acc = 0.7650\n",
            "ANTES DO TREINO: val_acc = 0.7680\n",
            "d-step 225 epoch 1 : .......... average_loss = 0.1719, train_acc = 0.9502, val_acc = 0.7670\n",
            "ANTES DO TREINO: val_acc = 0.7660\n",
            "d-step 226 epoch 1 : .......... average_loss = 0.1679, train_acc = 0.9510, val_acc = 0.7600\n",
            "ANTES DO TREINO: val_acc = 0.7560\n",
            "d-step 227 epoch 1 : .......... average_loss = 0.1705, train_acc = 0.9505, val_acc = 0.7800\n",
            "ANTES DO TREINO: val_acc = 0.7800\n",
            "d-step 228 epoch 1 : .......... average_loss = 0.1750, train_acc = 0.9488, val_acc = 0.7810\n",
            "ANTES DO TREINO: val_acc = 0.7900\n",
            "d-step 229 epoch 1 : .......... average_loss = 0.1751, train_acc = 0.9489, val_acc = 0.7960\n",
            "ANTES DO TREINO: val_acc = 0.7920\n",
            "d-step 230 epoch 1 : .......... average_loss = 0.1728, train_acc = 0.9504, val_acc = 0.7920\n",
            "ANTES DO TREINO: val_acc = 0.7900\n",
            "d-step 231 epoch 1 : .......... average_loss = 0.1713, train_acc = 0.9496, val_acc = 0.7990\n",
            "ANTES DO TREINO: val_acc = 0.8050\n",
            "d-step 232 epoch 1 : .......... average_loss = 0.1836, train_acc = 0.9465, val_acc = 0.7720\n",
            "ANTES DO TREINO: val_acc = 0.7690\n",
            "d-step 233 epoch 1 : .......... average_loss = 0.1788, train_acc = 0.9480, val_acc = 0.7940\n",
            "ANTES DO TREINO: val_acc = 0.7810\n",
            "d-step 234 epoch 1 : .......... average_loss = 0.1709, train_acc = 0.9509, val_acc = 0.7830\n",
            "ANTES DO TREINO: val_acc = 0.7850\n",
            "d-step 235 epoch 1 : .......... average_loss = 0.1793, train_acc = 0.9485, val_acc = 0.7890\n",
            "ANTES DO TREINO: val_acc = 0.7860\n",
            "d-step 236 epoch 1 : .......... average_loss = 0.1787, train_acc = 0.9472, val_acc = 0.8000\n",
            "ANTES DO TREINO: val_acc = 0.8010\n",
            "d-step 237 epoch 1 : .......... average_loss = 0.1749, train_acc = 0.9498, val_acc = 0.7970\n",
            "ANTES DO TREINO: val_acc = 0.7960\n",
            "d-step 238 epoch 1 : .......... average_loss = 0.1736, train_acc = 0.9489, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7980\n",
            "d-step 239 epoch 1 : .......... average_loss = 0.1764, train_acc = 0.9486, val_acc = 0.7910\n",
            "ANTES DO TREINO: val_acc = 0.7960\n",
            "d-step 240 epoch 1 : .......... average_loss = 0.1714, train_acc = 0.9505, val_acc = 0.7980\n",
            "ANTES DO TREINO: val_acc = 0.8030\n",
            "d-step 241 epoch 1 : .......... average_loss = 0.1685, train_acc = 0.9515, val_acc = 0.8030\n",
            "ANTES DO TREINO: val_acc = 0.7980\n",
            "d-step 242 epoch 1 : .......... average_loss = 0.1798, train_acc = 0.9472, val_acc = 0.7380\n",
            "ANTES DO TREINO: val_acc = 0.7450\n",
            "d-step 243 epoch 1 : .......... average_loss = 0.1710, train_acc = 0.9501, val_acc = 0.8080\n",
            "ANTES DO TREINO: val_acc = 0.8160\n",
            "d-step 244 epoch 1 : .......... average_loss = 0.1696, train_acc = 0.9506, val_acc = 0.7920\n",
            "ANTES DO TREINO: val_acc = 0.7930\n",
            "d-step 245 epoch 1 : .......... average_loss = 0.1768, train_acc = 0.9487, val_acc = 0.7910\n",
            "ANTES DO TREINO: val_acc = 0.7970\n",
            "d-step 246 epoch 1 : .......... average_loss = 0.1594, train_acc = 0.9541, val_acc = 0.7970\n",
            "ANTES DO TREINO: val_acc = 0.8000\n",
            "d-step 247 epoch 1 : .......... average_loss = 0.1757, train_acc = 0.9493, val_acc = 0.7820\n",
            "ANTES DO TREINO: val_acc = 0.7790\n",
            "d-step 248 epoch 1 : .......... average_loss = 0.1619, train_acc = 0.9536, val_acc = 0.8080\n",
            "ANTES DO TREINO: val_acc = 0.7980\n",
            "d-step 249 epoch 1 : .......... average_loss = 0.1664, train_acc = 0.9519, val_acc = 0.7780\n",
            "ANTES DO TREINO: val_acc = 0.7770\n",
            "d-step 250 epoch 1 : .......... average_loss = 0.1780, train_acc = 0.9474, val_acc = 0.7880\n",
            "ANTES DO TREINO: val_acc = 0.7810\n",
            "d-step 251 epoch 1 : .......... average_loss = 0.1733, train_acc = 0.9501, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7940\n",
            "d-step 252 epoch 1 : .......... average_loss = 0.1697, train_acc = 0.9506, val_acc = 0.7950\n",
            "ANTES DO TREINO: val_acc = 0.7840\n",
            "d-step 253 epoch 1 : .......... average_loss = 0.1668, train_acc = 0.9539, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7860\n",
            "d-step 254 epoch 1 : .......... average_loss = 0.1673, train_acc = 0.9524, val_acc = 0.8070\n",
            "ANTES DO TREINO: val_acc = 0.8070\n",
            "d-step 255 epoch 1 : .......... average_loss = 0.1614, train_acc = 0.9538, val_acc = 0.7440\n",
            "ANTES DO TREINO: val_acc = 0.7460\n",
            "d-step 256 epoch 1 : .......... average_loss = 0.1681, train_acc = 0.9502, val_acc = 0.7780\n",
            "ANTES DO TREINO: val_acc = 0.7820\n",
            "d-step 257 epoch 1 : .......... average_loss = 0.1716, train_acc = 0.9509, val_acc = 0.7880\n",
            "ANTES DO TREINO: val_acc = 0.7880\n",
            "d-step 258 epoch 1 : .......... average_loss = 0.1663, train_acc = 0.9538, val_acc = 0.7670\n",
            "ANTES DO TREINO: val_acc = 0.7660\n",
            "d-step 259 epoch 1 : .......... average_loss = 0.1691, train_acc = 0.9515, val_acc = 0.7670\n",
            "ANTES DO TREINO: val_acc = 0.7700\n",
            "d-step 260 epoch 1 : .......... average_loss = 0.1680, train_acc = 0.9514, val_acc = 0.8000\n",
            "ANTES DO TREINO: val_acc = 0.7960\n",
            "d-step 261 epoch 1 : .......... average_loss = 0.1712, train_acc = 0.9507, val_acc = 0.7810\n",
            "ANTES DO TREINO: val_acc = 0.7790\n",
            "d-step 262 epoch 1 : .......... average_loss = 0.1669, train_acc = 0.9516, val_acc = 0.8120\n",
            "ANTES DO TREINO: val_acc = 0.8150\n",
            "d-step 263 epoch 1 : .......... average_loss = 0.1697, train_acc = 0.9515, val_acc = 0.8180\n",
            "ANTES DO TREINO: val_acc = 0.8170\n",
            "d-step 264 epoch 1 : .......... average_loss = 0.1665, train_acc = 0.9520, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7820\n",
            "d-step 265 epoch 1 : .......... average_loss = 0.1609, train_acc = 0.9539, val_acc = 0.7920\n",
            "ANTES DO TREINO: val_acc = 0.7870\n",
            "d-step 266 epoch 1 : .......... average_loss = 0.1661, train_acc = 0.9515, val_acc = 0.7870\n",
            "ANTES DO TREINO: val_acc = 0.7960\n",
            "d-step 267 epoch 1 : .......... average_loss = 0.1659, train_acc = 0.9520, val_acc = 0.8150\n",
            "ANTES DO TREINO: val_acc = 0.8060\n",
            "d-step 268 epoch 1 : .......... average_loss = 0.1626, train_acc = 0.9548, val_acc = 0.8090\n",
            "ANTES DO TREINO: val_acc = 0.8090\n",
            "d-step 269 epoch 1 : .......... average_loss = 0.1585, train_acc = 0.9553, val_acc = 0.7970\n",
            "ANTES DO TREINO: val_acc = 0.7960\n",
            "d-step 270 epoch 1 : .......... average_loss = 0.1623, train_acc = 0.9548, val_acc = 0.7960\n",
            "ANTES DO TREINO: val_acc = 0.7970\n",
            "d-step 271 epoch 1 : .......... average_loss = 0.1647, train_acc = 0.9528, val_acc = 0.7980\n",
            "ANTES DO TREINO: val_acc = 0.7920\n",
            "d-step 272 epoch 1 : .......... average_loss = 0.1637, train_acc = 0.9541, val_acc = 0.7940\n",
            "ANTES DO TREINO: val_acc = 0.7970\n",
            "d-step 273 epoch 1 : .......... average_loss = 0.1607, train_acc = 0.9548, val_acc = 0.7890\n",
            "ANTES DO TREINO: val_acc = 0.7910\n",
            "d-step 274 epoch 1 : .......... average_loss = 0.1641, train_acc = 0.9529, val_acc = 0.8110\n",
            "ANTES DO TREINO: val_acc = 0.8060\n",
            "d-step 275 epoch 1 : .......... average_loss = 0.1622, train_acc = 0.9537, val_acc = 0.7940\n",
            "ANTES DO TREINO: val_acc = 0.7870\n",
            "d-step 276 epoch 1 : .......... average_loss = 0.1626, train_acc = 0.9536, val_acc = 0.8000\n",
            "ANTES DO TREINO: val_acc = 0.8010\n",
            "d-step 277 epoch 1 : .......... average_loss = 0.1700, train_acc = 0.9507, val_acc = 0.8010\n",
            "ANTES DO TREINO: val_acc = 0.8020\n",
            "d-step 278 epoch 1 : .......... average_loss = 0.1602, train_acc = 0.9547, val_acc = 0.8040\n",
            "ANTES DO TREINO: val_acc = 0.8000\n",
            "d-step 279 epoch 1 : .......... average_loss = 0.1651, train_acc = 0.9535, val_acc = 0.7870\n",
            "ANTES DO TREINO: val_acc = 0.7970\n",
            "d-step 280 epoch 1 : .......... average_loss = 0.1625, train_acc = 0.9534, val_acc = 0.8120\n",
            "ANTES DO TREINO: val_acc = 0.8130\n",
            "d-step 281 epoch 1 : .......... average_loss = 0.1573, train_acc = 0.9554, val_acc = 0.8120\n",
            "ANTES DO TREINO: val_acc = 0.8150\n",
            "d-step 282 epoch 1 : .......... average_loss = 0.1602, train_acc = 0.9546, val_acc = 0.7560\n",
            "ANTES DO TREINO: val_acc = 0.7550\n",
            "d-step 283 epoch 1 : .......... average_loss = 0.1613, train_acc = 0.9536, val_acc = 0.7970\n",
            "ANTES DO TREINO: val_acc = 0.7990\n",
            "d-step 284 epoch 1 : .......... average_loss = 0.1590, train_acc = 0.9546, val_acc = 0.7840\n",
            "ANTES DO TREINO: val_acc = 0.7810\n",
            "d-step 285 epoch 1 : .......... average_loss = 0.1573, train_acc = 0.9569, val_acc = 0.7960\n",
            "ANTES DO TREINO: val_acc = 0.8060\n",
            "d-step 286 epoch 1 : .......... average_loss = 0.1509, train_acc = 0.9584, val_acc = 0.8000\n",
            "ANTES DO TREINO: val_acc = 0.7980\n",
            "d-step 287 epoch 1 : .......... average_loss = 0.1661, train_acc = 0.9522, val_acc = 0.8070\n",
            "ANTES DO TREINO: val_acc = 0.8010\n",
            "d-step 288 epoch 1 : .......... average_loss = 0.1632, train_acc = 0.9530, val_acc = 0.8190\n",
            "ANTES DO TREINO: val_acc = 0.8130\n",
            "d-step 289 epoch 1 : .......... average_loss = 0.1542, train_acc = 0.9561, val_acc = 0.7750\n",
            "ANTES DO TREINO: val_acc = 0.7740\n",
            "d-step 290 epoch 1 : .......... average_loss = 0.1643, train_acc = 0.9534, val_acc = 0.8050\n",
            "ANTES DO TREINO: val_acc = 0.8060\n",
            "d-step 291 epoch 1 : .......... average_loss = 0.1633, train_acc = 0.9534, val_acc = 0.8000\n",
            "ANTES DO TREINO: val_acc = 0.8000\n",
            "d-step 292 epoch 1 : .......... average_loss = 0.1594, train_acc = 0.9542, val_acc = 0.8130\n",
            "ANTES DO TREINO: val_acc = 0.8090\n",
            "d-step 293 epoch 1 : .......... average_loss = 0.1625, train_acc = 0.9533, val_acc = 0.8310\n",
            "ANTES DO TREINO: val_acc = 0.8350\n",
            "d-step 294 epoch 1 : .......... average_loss = 0.1620, train_acc = 0.9536, val_acc = 0.8220\n",
            "ANTES DO TREINO: val_acc = 0.8120\n",
            "d-step 295 epoch 1 : .......... average_loss = 0.1560, train_acc = 0.9559, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7970\n",
            "d-step 296 epoch 1 : .......... average_loss = 0.1586, train_acc = 0.9552, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7930\n",
            "d-step 297 epoch 1 : .......... average_loss = 0.1625, train_acc = 0.9542, val_acc = 0.8120\n",
            "ANTES DO TREINO: val_acc = 0.8180\n",
            "d-step 298 epoch 1 : .......... average_loss = 0.1614, train_acc = 0.9533, val_acc = 0.8040\n",
            "ANTES DO TREINO: val_acc = 0.8040\n",
            "d-step 299 epoch 1 : .......... average_loss = 0.1545, train_acc = 0.9556, val_acc = 0.8180\n",
            "ANTES DO TREINO: val_acc = 0.8200\n",
            "d-step 300 epoch 1 : .......... average_loss = 0.1614, train_acc = 0.9539, val_acc = 0.8040\n",
            "CPU times: user 27min, sys: 9.41 s, total: 27min 10s\n",
            "Wall time: 27min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Znhasa7gr5"
      },
      "source": [
        "Aprendizagem competitiva. Treinamento de um gerador com base no aprendizado por reforço"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oELznd8Bs6-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66cdead0-2c5e-4284-e122-28761b50ba1f"
      },
      "source": [
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# average_train_NLL = 1.7516 average_test_NLL = 1.9832"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 1.8009 average_test_NLL = 1.9609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9gy5KOOuibf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df31fc2-0ba0-4bd7-e946-d63e0ed450cb"
      },
      "source": [
        "%%time\n",
        "# gen_optimizer = optim.Adagrad(gen.parameters(), lr=0.0005)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "# gen_optimizer = optim.Adam(gen.parameters(), lr=0.0001)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters(), lr=0.001)#, lr=0.002\n",
        "\n",
        "# Gerador de Aprendizagem Adversarial\n",
        "print('\\nStarting Adversarial Training...')\n",
        "\n",
        "for epoch in range(ADV_TRAIN_EPOCHS):# ADV_TRAIN_EPOCHS\n",
        "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
        "    # treinamento de gerador\n",
        "    print('\\nAdversarial Training Generator : ', end='')\n",
        "    train_generator_PG(gen, gen_optimizer, dis, 1)\n",
        "\n",
        "    # teste nll\n",
        "    print('\\nTesting Generator : ', end='')\n",
        "    test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "\n",
        "    # treinamento discriminador\n",
        "    print('\\nAdversarial Training Discriminator : ')\n",
        "    train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, 5, 1)#3, 1\n",
        "\n",
        "# salvando o resultado da aprendizagem\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')\n",
        "# epoch 3 : .......... average_train_NLL = 1.8005 average_test_NLL = 1.9824\n",
        "# average_train_NLL = 1.7340 average_test_NLL = 2.0599"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Adversarial Training...\n",
            "\n",
            "--------\n",
            "EPOCH 1\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8014 average_test_NLL = 1.9605\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8150\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1510, train_acc = 0.9581, val_acc = 0.7910\n",
            "ANTES DO TREINO: val_acc = 0.7940\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1592, train_acc = 0.9550, val_acc = 0.8220\n",
            "ANTES DO TREINO: val_acc = 0.8250\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1639, train_acc = 0.9538, val_acc = 0.8170\n",
            "ANTES DO TREINO: val_acc = 0.8220\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1607, train_acc = 0.9536, val_acc = 0.8160\n",
            "ANTES DO TREINO: val_acc = 0.8110\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1597, train_acc = 0.9552, val_acc = 0.8200\n",
            "\n",
            "--------\n",
            "EPOCH 2\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8020 average_test_NLL = 1.9602\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8030\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1600, train_acc = 0.9543, val_acc = 0.7820\n",
            "ANTES DO TREINO: val_acc = 0.7790\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1602, train_acc = 0.9549, val_acc = 0.7910\n",
            "ANTES DO TREINO: val_acc = 0.7920\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1555, train_acc = 0.9569, val_acc = 0.8220\n",
            "ANTES DO TREINO: val_acc = 0.8280\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1547, train_acc = 0.9562, val_acc = 0.8040\n",
            "ANTES DO TREINO: val_acc = 0.8120\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1522, train_acc = 0.9577, val_acc = 0.8260\n",
            "\n",
            "--------\n",
            "EPOCH 3\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8026 average_test_NLL = 1.9600\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8520\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1625, train_acc = 0.9543, val_acc = 0.8520\n",
            "ANTES DO TREINO: val_acc = 0.8420\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1563, train_acc = 0.9561, val_acc = 0.8220\n",
            "ANTES DO TREINO: val_acc = 0.8230\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1551, train_acc = 0.9566, val_acc = 0.8390\n",
            "ANTES DO TREINO: val_acc = 0.8450\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1570, train_acc = 0.9554, val_acc = 0.8450\n",
            "ANTES DO TREINO: val_acc = 0.8440\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1477, train_acc = 0.9599, val_acc = 0.8360\n",
            "\n",
            "--------\n",
            "EPOCH 4\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8032 average_test_NLL = 1.9599\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8240\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1534, train_acc = 0.9575, val_acc = 0.8230\n",
            "ANTES DO TREINO: val_acc = 0.8300\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1537, train_acc = 0.9575, val_acc = 0.8390\n",
            "ANTES DO TREINO: val_acc = 0.8310\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1508, train_acc = 0.9568, val_acc = 0.8290\n",
            "ANTES DO TREINO: val_acc = 0.8280\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1495, train_acc = 0.9586, val_acc = 0.8140\n",
            "ANTES DO TREINO: val_acc = 0.8170\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1506, train_acc = 0.9589, val_acc = 0.8250\n",
            "\n",
            "--------\n",
            "EPOCH 5\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8037 average_test_NLL = 1.9597\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8110\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1508, train_acc = 0.9575, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7990\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1539, train_acc = 0.9576, val_acc = 0.8170\n",
            "ANTES DO TREINO: val_acc = 0.8260\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1526, train_acc = 0.9576, val_acc = 0.8170\n",
            "ANTES DO TREINO: val_acc = 0.8110\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1486, train_acc = 0.9585, val_acc = 0.8130\n",
            "ANTES DO TREINO: val_acc = 0.8080\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1526, train_acc = 0.9578, val_acc = 0.7990\n",
            "\n",
            "--------\n",
            "EPOCH 6\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8041 average_test_NLL = 1.9595\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8140\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1508, train_acc = 0.9569, val_acc = 0.8210\n",
            "ANTES DO TREINO: val_acc = 0.8290\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1540, train_acc = 0.9557, val_acc = 0.8210\n",
            "ANTES DO TREINO: val_acc = 0.8190\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1599, train_acc = 0.9546, val_acc = 0.8020\n",
            "ANTES DO TREINO: val_acc = 0.8080\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1554, train_acc = 0.9571, val_acc = 0.8080\n",
            "ANTES DO TREINO: val_acc = 0.8160\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1392, train_acc = 0.9615, val_acc = 0.8020\n",
            "\n",
            "--------\n",
            "EPOCH 7\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8044 average_test_NLL = 1.9594\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8130\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1486, train_acc = 0.9580, val_acc = 0.8270\n",
            "ANTES DO TREINO: val_acc = 0.8270\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1504, train_acc = 0.9567, val_acc = 0.8250\n",
            "ANTES DO TREINO: val_acc = 0.8240\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1508, train_acc = 0.9576, val_acc = 0.8450\n",
            "ANTES DO TREINO: val_acc = 0.8470\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1464, train_acc = 0.9590, val_acc = 0.8310\n",
            "ANTES DO TREINO: val_acc = 0.8240\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1518, train_acc = 0.9574, val_acc = 0.8330\n",
            "\n",
            "--------\n",
            "EPOCH 8\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8046 average_test_NLL = 1.9591\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8080\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1537, train_acc = 0.9564, val_acc = 0.8100\n",
            "ANTES DO TREINO: val_acc = 0.8150\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1527, train_acc = 0.9568, val_acc = 0.8050\n",
            "ANTES DO TREINO: val_acc = 0.8050\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1475, train_acc = 0.9583, val_acc = 0.7870\n",
            "ANTES DO TREINO: val_acc = 0.7890\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1570, train_acc = 0.9564, val_acc = 0.8280\n",
            "ANTES DO TREINO: val_acc = 0.8250\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1553, train_acc = 0.9562, val_acc = 0.8200\n",
            "\n",
            "--------\n",
            "EPOCH 9\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8047 average_test_NLL = 1.9589\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8110\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1568, train_acc = 0.9559, val_acc = 0.8250\n",
            "ANTES DO TREINO: val_acc = 0.8200\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1542, train_acc = 0.9557, val_acc = 0.8210\n",
            "ANTES DO TREINO: val_acc = 0.8280\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1533, train_acc = 0.9576, val_acc = 0.7960\n",
            "ANTES DO TREINO: val_acc = 0.7980\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1470, train_acc = 0.9590, val_acc = 0.8000\n",
            "ANTES DO TREINO: val_acc = 0.8050\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1471, train_acc = 0.9584, val_acc = 0.8010\n",
            "\n",
            "--------\n",
            "EPOCH 10\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8047 average_test_NLL = 1.9586\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.7980\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1482, train_acc = 0.9578, val_acc = 0.8230\n",
            "ANTES DO TREINO: val_acc = 0.8190\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1528, train_acc = 0.9575, val_acc = 0.8090\n",
            "ANTES DO TREINO: val_acc = 0.8070\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1422, train_acc = 0.9593, val_acc = 0.8130\n",
            "ANTES DO TREINO: val_acc = 0.8120\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1466, train_acc = 0.9585, val_acc = 0.8200\n",
            "ANTES DO TREINO: val_acc = 0.8170\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1488, train_acc = 0.9582, val_acc = 0.8220\n",
            "\n",
            "--------\n",
            "EPOCH 11\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8046 average_test_NLL = 1.9583\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8360\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1501, train_acc = 0.9561, val_acc = 0.8360\n",
            "ANTES DO TREINO: val_acc = 0.8340\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1532, train_acc = 0.9564, val_acc = 0.8300\n",
            "ANTES DO TREINO: val_acc = 0.8250\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1528, train_acc = 0.9571, val_acc = 0.8340\n",
            "ANTES DO TREINO: val_acc = 0.8340\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1493, train_acc = 0.9574, val_acc = 0.7910\n",
            "ANTES DO TREINO: val_acc = 0.7840\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1512, train_acc = 0.9571, val_acc = 0.8350\n",
            "\n",
            "--------\n",
            "EPOCH 12\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8045 average_test_NLL = 1.9579\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8150\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1522, train_acc = 0.9565, val_acc = 0.8260\n",
            "ANTES DO TREINO: val_acc = 0.8170\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1534, train_acc = 0.9573, val_acc = 0.8130\n",
            "ANTES DO TREINO: val_acc = 0.8110\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1446, train_acc = 0.9607, val_acc = 0.8140\n",
            "ANTES DO TREINO: val_acc = 0.8140\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1569, train_acc = 0.9551, val_acc = 0.7940\n",
            "ANTES DO TREINO: val_acc = 0.7970\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1468, train_acc = 0.9593, val_acc = 0.8090\n",
            "\n",
            "--------\n",
            "EPOCH 13\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8043 average_test_NLL = 1.9576\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8230\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1512, train_acc = 0.9564, val_acc = 0.8190\n",
            "ANTES DO TREINO: val_acc = 0.8160\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1490, train_acc = 0.9580, val_acc = 0.8360\n",
            "ANTES DO TREINO: val_acc = 0.8370\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1562, train_acc = 0.9551, val_acc = 0.8320\n",
            "ANTES DO TREINO: val_acc = 0.8370\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1535, train_acc = 0.9571, val_acc = 0.8220\n",
            "ANTES DO TREINO: val_acc = 0.8160\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1483, train_acc = 0.9579, val_acc = 0.8100\n",
            "\n",
            "--------\n",
            "EPOCH 14\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8041 average_test_NLL = 1.9572\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8120\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1522, train_acc = 0.9564, val_acc = 0.8260\n",
            "ANTES DO TREINO: val_acc = 0.8250\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1577, train_acc = 0.9550, val_acc = 0.8260\n",
            "ANTES DO TREINO: val_acc = 0.8210\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1451, train_acc = 0.9597, val_acc = 0.8170\n",
            "ANTES DO TREINO: val_acc = 0.8210\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1546, train_acc = 0.9548, val_acc = 0.8270\n",
            "ANTES DO TREINO: val_acc = 0.8330\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1486, train_acc = 0.9584, val_acc = 0.8240\n",
            "\n",
            "--------\n",
            "EPOCH 15\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8038 average_test_NLL = 1.9568\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.7900\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1547, train_acc = 0.9548, val_acc = 0.7990\n",
            "ANTES DO TREINO: val_acc = 0.7900\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1513, train_acc = 0.9577, val_acc = 0.7970\n",
            "ANTES DO TREINO: val_acc = 0.7960\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1457, train_acc = 0.9591, val_acc = 0.7720\n",
            "ANTES DO TREINO: val_acc = 0.7620\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1478, train_acc = 0.9577, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7870\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1501, train_acc = 0.9580, val_acc = 0.7960\n",
            "\n",
            "--------\n",
            "EPOCH 16\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8036 average_test_NLL = 1.9565\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8160\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1531, train_acc = 0.9567, val_acc = 0.8010\n",
            "ANTES DO TREINO: val_acc = 0.7960\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1553, train_acc = 0.9556, val_acc = 0.8100\n",
            "ANTES DO TREINO: val_acc = 0.8120\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1487, train_acc = 0.9589, val_acc = 0.8170\n",
            "ANTES DO TREINO: val_acc = 0.8130\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1515, train_acc = 0.9564, val_acc = 0.8070\n",
            "ANTES DO TREINO: val_acc = 0.8080\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1587, train_acc = 0.9535, val_acc = 0.7780\n",
            "\n",
            "--------\n",
            "EPOCH 17\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8032 average_test_NLL = 1.9562\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8190\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1540, train_acc = 0.9558, val_acc = 0.8470\n",
            "ANTES DO TREINO: val_acc = 0.8460\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1654, train_acc = 0.9513, val_acc = 0.8050\n",
            "ANTES DO TREINO: val_acc = 0.8070\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1624, train_acc = 0.9523, val_acc = 0.8310\n",
            "ANTES DO TREINO: val_acc = 0.8380\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1523, train_acc = 0.9559, val_acc = 0.8340\n",
            "ANTES DO TREINO: val_acc = 0.8370\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1497, train_acc = 0.9570, val_acc = 0.8350\n",
            "\n",
            "--------\n",
            "EPOCH 18\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8029 average_test_NLL = 1.9558\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.7990\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1590, train_acc = 0.9542, val_acc = 0.7980\n",
            "ANTES DO TREINO: val_acc = 0.7980\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1463, train_acc = 0.9584, val_acc = 0.7970\n",
            "ANTES DO TREINO: val_acc = 0.7940\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1497, train_acc = 0.9572, val_acc = 0.8110\n",
            "ANTES DO TREINO: val_acc = 0.8130\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1581, train_acc = 0.9537, val_acc = 0.7900\n",
            "ANTES DO TREINO: val_acc = 0.7940\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1530, train_acc = 0.9558, val_acc = 0.8040\n",
            "\n",
            "--------\n",
            "EPOCH 19\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8026 average_test_NLL = 1.9555\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8360\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1556, train_acc = 0.9546, val_acc = 0.8250\n",
            "ANTES DO TREINO: val_acc = 0.8240\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1549, train_acc = 0.9563, val_acc = 0.8370\n",
            "ANTES DO TREINO: val_acc = 0.8350\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1493, train_acc = 0.9577, val_acc = 0.8240\n",
            "ANTES DO TREINO: val_acc = 0.8250\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1527, train_acc = 0.9562, val_acc = 0.8340\n",
            "ANTES DO TREINO: val_acc = 0.8320\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1533, train_acc = 0.9563, val_acc = 0.8500\n",
            "\n",
            "--------\n",
            "EPOCH 20\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8023 average_test_NLL = 1.9552\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8420\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1517, train_acc = 0.9568, val_acc = 0.8450\n",
            "ANTES DO TREINO: val_acc = 0.8440\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1552, train_acc = 0.9566, val_acc = 0.8340\n",
            "ANTES DO TREINO: val_acc = 0.8350\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1469, train_acc = 0.9580, val_acc = 0.8340\n",
            "ANTES DO TREINO: val_acc = 0.8340\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1507, train_acc = 0.9563, val_acc = 0.8440\n",
            "ANTES DO TREINO: val_acc = 0.8450\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1499, train_acc = 0.9573, val_acc = 0.8380\n",
            "\n",
            "--------\n",
            "EPOCH 21\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8020 average_test_NLL = 1.9550\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8200\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1574, train_acc = 0.9547, val_acc = 0.8260\n",
            "ANTES DO TREINO: val_acc = 0.8240\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1511, train_acc = 0.9564, val_acc = 0.8370\n",
            "ANTES DO TREINO: val_acc = 0.8290\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1505, train_acc = 0.9568, val_acc = 0.8140\n",
            "ANTES DO TREINO: val_acc = 0.8210\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1522, train_acc = 0.9560, val_acc = 0.8270\n",
            "ANTES DO TREINO: val_acc = 0.8240\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1494, train_acc = 0.9584, val_acc = 0.8180\n",
            "\n",
            "--------\n",
            "EPOCH 22\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8017 average_test_NLL = 1.9547\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8220\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1551, train_acc = 0.9549, val_acc = 0.8170\n",
            "ANTES DO TREINO: val_acc = 0.8160\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1644, train_acc = 0.9517, val_acc = 0.8340\n",
            "ANTES DO TREINO: val_acc = 0.8390\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1598, train_acc = 0.9532, val_acc = 0.8220\n",
            "ANTES DO TREINO: val_acc = 0.8190\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1559, train_acc = 0.9542, val_acc = 0.8290\n",
            "ANTES DO TREINO: val_acc = 0.8370\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1573, train_acc = 0.9547, val_acc = 0.8320\n",
            "\n",
            "--------\n",
            "EPOCH 23\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8015 average_test_NLL = 1.9545\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8380\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1522, train_acc = 0.9554, val_acc = 0.8150\n",
            "ANTES DO TREINO: val_acc = 0.8160\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1585, train_acc = 0.9540, val_acc = 0.8180\n",
            "ANTES DO TREINO: val_acc = 0.8170\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1560, train_acc = 0.9543, val_acc = 0.8270\n",
            "ANTES DO TREINO: val_acc = 0.8290\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1483, train_acc = 0.9579, val_acc = 0.8410\n",
            "ANTES DO TREINO: val_acc = 0.8410\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1542, train_acc = 0.9562, val_acc = 0.8260\n",
            "\n",
            "--------\n",
            "EPOCH 24\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8012 average_test_NLL = 1.9543\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.8130\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1503, train_acc = 0.9573, val_acc = 0.8250\n",
            "ANTES DO TREINO: val_acc = 0.8330\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1604, train_acc = 0.9523, val_acc = 0.8040\n",
            "ANTES DO TREINO: val_acc = 0.8150\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1528, train_acc = 0.9568, val_acc = 0.8110\n",
            "ANTES DO TREINO: val_acc = 0.8100\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1525, train_acc = 0.9558, val_acc = 0.8210\n",
            "ANTES DO TREINO: val_acc = 0.8290\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1513, train_acc = 0.9567, val_acc = 0.8000\n",
            "\n",
            "--------\n",
            "EPOCH 25\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 1.8009 average_test_NLL = 1.9540\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ANTES DO TREINO: val_acc = 0.7930\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1578, train_acc = 0.9545, val_acc = 0.7790\n",
            "ANTES DO TREINO: val_acc = 0.7800\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1516, train_acc = 0.9566, val_acc = 0.8120\n",
            "ANTES DO TREINO: val_acc = 0.8070\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1578, train_acc = 0.9538, val_acc = 0.8040\n",
            "ANTES DO TREINO: val_acc = 0.8130\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1537, train_acc = 0.9557, val_acc = 0.7970\n",
            "ANTES DO TREINO: val_acc = 0.8000\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1547, train_acc = 0.9556, val_acc = 0.8100\n",
            "CPU times: user 40min 48s, sys: 19min 56s, total: 1h 44s\n",
            "Wall time: 1h 1min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3-xXxc3rQ6"
      },
      "source": [
        "Testando o gerador no conjunto de treinamento após o treinamento adversário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWz3XBxE3nOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0dee8d-8723-4df1-8d02-5791e2221fbe"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# average_train_NLL = 1.5186 average_test_NLL = 2.0730\n",
        "# average_train_NLL = 1.4459 average_test_NLL = 1.9926"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 1.8009 average_test_NLL = 1.9540\n",
            "CPU times: user 7.41 s, sys: 10.5 ms, total: 7.42 s\n",
            "Wall time: 7.42 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF9S-MHOJm7d"
      },
      "source": [
        "Gerando textos de amostra com base no SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLUxNkP7LhHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffa9c35-0245-4fb1-89ed-0d3cbef80cb1"
      },
      "source": [
        "# exemplos de textos gerados\n",
        "print(\"Exemplos de textos gerados com base no SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tExemplo: \", line, ' '*(100-len(line)), '\\tAvaliação: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos de textos gerados com base no SeqGAN\n",
            "Degree: 1\n",
            "# 0 \tExemplo:  The street scene filled with broccoli all and a box of dessert .                                      \tAvaliação:  [0.435285750066007, 0.21915874168443503, 0.0887067909105404, 0.05218449657024714]\n",
            "# 1 \tExemplo:  A tabby cat sitting on top of a table full of tongs .                                                 \tAvaliação:  [0.5619514869490163, 0.5196828406118894, 0.4507482544534971, 0.37822261873373586]\n",
            "# 2 \tExemplo:  A young girl flying three kite in the kitchen to look .                                               \tAvaliação:  [0.435285750066007, 0.27612271191669263, 0.10549074689987335, 0.059944245366591306]\n",
            "# 3 \tExemplo:  A line of people playing a game with their square ' s leg in the water .                              \tAvaliação:  [0.6688560540599386, 0.4208926658419206, 0.2573453280190883, 0.12234579126368764]\n",
            "# 4 \tExemplo:  A lone dog on the couch against a toilet window above brush .                                         \tAvaliação:  [0.5231483637805969, 0.24773787754561394, 0.09724831363662378, 0.05616705675147311]\n",
            "# 5 \tExemplo:  Two men standing beside each other in the middle at an outdoor table .                                \tAvaliação:  [0.6366028258614133, 0.5131038694945721, 0.3929362089069849, 0.3124925321508283]\n",
            "# 6 \tExemplo:  The plate sits in a cup that is close to the plate .                                                  \tAvaliação:  [0.533113989983183, 0.36182311050064736, 0.12919925124488807, 0.07049916949671992]\n",
            "# 7 \tExemplo:  A motel room with a couch , a television and a desk .                                                 \tAvaliação:  [0.6134458325505882, 0.5005841126806674, 0.34854035170959624, 0.24716015309501005]\n",
            "# 8 \tExemplo:  A young girl in is getting ready to swing a tennis ball .                                             \tAvaliação:  [0.5619514869490163, 0.4721631957086834, 0.36917916399395617, 0.1632923161254164]\n",
            "# 9 \tExemplo:  A man and woman sitting on the counter watching himself .                                             \tAvaliação:  [0.4812265031857878, 0.40068110080455893, 0.3264128346656048, 0.14797548943405625]\n",
            "# 10 \tExemplo:  A young child sitting on a pretty chair as he rides a bike .                                          \tAvaliação:  [0.5758289219624358, 0.4799049519403644, 0.2839580552178997, 0.132366887820792]\n",
            "# 11 \tExemplo:  Several skiers , wander , one and all girls on the beach .                                            \tAvaliação:  [0.3554093266554554, 0.24121540700043156, 0.16950852799011137, 0.08760507090360199]\n",
            "# 12 \tExemplo:  A man in a jacket talking on a motorcycle .                                                           \tAvaliação:  [0.4588314677411235, 0.3881515247704053, 0.2880024889341061, 0.13387300015892484]\n",
            "# 13 \tExemplo:  A little girl is taking a picture of a remote .                                                       \tAvaliação:  [0.5104177855340404, 0.44283653888216973, 0.35184442107863445, 0.28606355926390736]\n",
            "# 14 \tExemplo:  A giraffe leaned up to eat of vegetables on a wall table .                                            \tAvaliação:  [0.5026246899500345, 0.2412154070004315, 0.0953216502610246, 0.055275062900335764]\n",
            "# 15 \tExemplo:  A woman walking across a grass hut near the beach .                                                   \tAvaliação:  [0.4812265031857878, 0.37195938466682343, 0.2789439259471503, 0.2068185698600316]\n",
            "# 16 \tExemplo:  A roast locomotive into out water on the beach next to a body of water .                              \tAvaliação:  [0.6069769786668839, 0.5470839496727063, 0.4903047069202663, 0.42850989181779603]\n",
            "# 17 \tExemplo:  A plate with cheese , whipped cream on top , table and a window .                                     \tAvaliação:  [0.6069769786668839, 0.4677501973766062, 0.33124989794664067, 0.14972716653207577]\n",
            "# 18 \tExemplo:  Boy in the casserole for a drink pulled by a car .                                                    \tAvaliação:  [0.45014617508912413, 0.3557663528269982, 0.22686182598679874, 0.11060764410745492]\n",
            "# 19 \tExemplo:  A boy is standing in a park next to wall shelves .                                                    \tAvaliação:  [0.533113989983183, 0.4558685532582043, 0.2732231510487644, 0.12834826432879642]\n",
            "# 20 \tExemplo:  Two people lean in the water while standing by a table .                                              \tAvaliação:  [0.5104177855340404, 0.3868533494388999, 0.1358462144575525, 0.07338613847361351]\n",
            "# 21 \tExemplo:  A bowl of soap sitting on a table next to a fireplace .                                               \tAvaliação:  [0.5026246899500345, 0.43831748336887005, 0.3751840463233443, 0.30114627316684345]\n",
            "# 22 \tExemplo:  A man is sitting at a table set contains her computer .                                               \tAvaliação:  [0.5026246899500345, 0.41247254393856775, 0.3584668928097086, 0.31489045433870755]\n",
            "# 23 \tExemplo:  An orange cat is laying with green leaves covering it on top .                                        \tAvaliação:  [0.5231483637805969, 0.3572998474390311, 0.12798597838061404, 0.06996904038245069]\n",
            "# 24 \tExemplo:  A little boy that is holding a milk on top of a crane .                                               \tAvaliação:  [0.533113989983183, 0.4799049519403644, 0.42461633178803443, 0.3605766584996779]\n",
            "# 25 \tExemplo:  A cow holds two different types of food on the sea .                                                  \tAvaliação:  [0.5026246899500345, 0.347892817097899, 0.22308576866161578, 0.10913234729182814]\n",
            "# 26 \tExemplo:  A living room with chairs , broccoli , wearing other bag and a toy floor .                            \tAvaliação:  [0.6155870112510925, 0.3982378626139663, 0.24688498672025874, 0.11835094996253125]\n",
            "# 27 \tExemplo:  A zebra is shown in the goal towards a snow crosswalk .                                               \tAvaliação:  [0.41675437673324534, 0.268229131353767, 0.10322080150552766, 0.05891010340986106]\n",
            "# 28 \tExemplo:  A cat that has a laptop around it ' s lap .                                                           \tAvaliação:  [0.533113989983183, 0.36182311050064736, 0.12919925124488807, 0.07049916949671992]\n",
            "# 29 \tExemplo:  A woman walks with her girl in a bathroom filled .                                                    \tAvaliação:  [0.45014617508912413, 0.32323518297936166, 0.11872077943222034, 0.0658866452025356]\n",
            "# 30 \tExemplo:  Black cat laying next to each other propped how to watch something in front of a window .             \tAvaliação:  [0.7847225456708954, 0.6492569105972453, 0.557491201908851, 0.44832263767055636]\n",
            "# 31 \tExemplo:  A boy with two glasses giving his mouth .                                                             \tAvaliação:  [0.3441236008058426, 0.1873780883921577, 0.07887272990342094, 0.047502613204364615]\n",
            "# 32 \tExemplo:  A very black and white airplane is warming in the sky .                                               \tAvaliação:  [0.4812265031857878, 0.40068110080455893, 0.2480201200336197, 0.11878607549052882]\n",
            "# 33 \tExemplo:  A bed with a red Frisbee and geese and a child in the grass .                                         \tAvaliação:  [0.6069769786668839, 0.49705875547910827, 0.346697783111003, 0.15528762763713394]\n",
            "# 34 \tExemplo:  A man with his legs crossed on top of a white carpet .                                                \tAvaliação:  [0.5848976518656018, 0.45633707214217845, 0.3598590234416894, 0.2535606877812186]\n",
            "# 35 \tExemplo:  There are two people standing next to each other with an apple .                                      \tAvaliação:  [0.5848976518656018, 0.48493050014758926, 0.3766410991613996, 0.26297724440774917]\n",
            "# 36 \tExemplo:  Someone is smiling with their remote while sitting next to a building .                               \tAvaliação:  [0.5848976518656018, 0.42362581168373686, 0.3403336518440549, 0.24249339760804947]\n",
            "# 37 \tExemplo:  A shirtless man and smiling woman in a small restaurant cafe .                                        \tAvaliação:  [0.435285750066007, 0.27612271191669263, 0.10549074689987335, 0.059944245366591306]\n",
            "# 38 \tExemplo:  A cat hooked up a keyboard in front of a large window over a table .                                  \tAvaliação:  [0.7398435111918139, 0.5337350774191416, 0.3657123090593231, 0.25685478804337497]\n",
            "# 39 \tExemplo:  A banana , broccoli made , large , two donuts , and other items .                                     \tAvaliação:  [0.5619514869490163, 0.37475617678431544, 0.23588448106534207, 0.11411309879546261]\n",
            "# 40 \tExemplo:  Two girls sitting next to each other holding a small large bull .                                     \tAvaliação:  [0.5231483637805969, 0.39325936742827655, 0.2908402945446888, 0.21384527762204014]\n",
            "# 41 \tExemplo:  A guy in the air with a flag in the ocean .                                                           \tAvaliação:  [0.533113989983183, 0.42898873304984025, 0.310441435588881, 0.14215421778491]\n",
            "# 42 \tExemplo:  A kitchen has a sides of an orange and white cat in it .                                              \tAvaliação:  [0.6649099662043687, 0.5282037458971186, 0.3628660825533186, 0.16105458919509583]\n",
            "# 43 \tExemplo:  A man with a kite .                                                                                   \tAvaliação:  [0.2809757434745081, 0.2360815978543417, 0.16679551613797314, 0.08648155715006021]\n",
            "# 44 \tExemplo:  A young lady playing tennis covers a ball with his phone .                                            \tAvaliação:  [0.435285750066007, 0.21915874168443503, 0.0887067909105404, 0.05218449657024714]\n",
            "# 45 \tExemplo:  Beach and blond women standing plate with kites counter . v .                                         \tAvaliação:  [0.380442955126341, 0.20034055040227947, 0.08293052535578581, 0.049447864072160404]\n",
            "# 46 \tExemplo:  A bus with a toy mouse and several containers of beverages .                                          \tAvaliação:  [0.45014617508912413, 0.32323518297936166, 0.11872077943222034, 0.0658866452025356]\n",
            "# 47 \tExemplo:  A group of people walking together , on skis high up alongside a snowy slope .                        \tAvaliação:  [0.7108186533109109, 0.5522454238333854, 0.3751840463233443, 0.16541370673239006]\n",
            "# 48 \tExemplo:  A desk with a computer set in front of a bucket .                                                     \tAvaliação:  [0.533113989983183, 0.42898873304984025, 0.3435599238920265, 0.24433067891686003]\n",
            "# 49 \tExemplo:  The woman holding a blue frisbee in a grassy area .                                                   \tAvaliação:  [0.5104177855340404, 0.4167251379930962, 0.33616721609689953, 0.2758203395105708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZUtKiv7n88"
      },
      "source": [
        "Avaliação da qualidade da geração com base no SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tets0DMEuDkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fadac5f4-d285-42b1-afa8-c2239915a726"
      },
      "source": [
        "%%time\n",
        "print(\"Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "# controle de qualidade da educação\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com SeqGAN\n",
            "Degree: 1\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5093269360756356\n",
            "2 200 0.5090302788246426\n",
            "2 300 0.5096131363695509\n",
            "2 400 0.5157009129314349\n",
            "2 500 0.5124317667785041\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5124317667785041 \n",
            "\n",
            "3 100 0.37824655498814763\n",
            "3 200 0.37499114212674145\n",
            "3 300 0.3777895329420967\n",
            "3 400 0.38550795051567127\n",
            "3 500 0.3824308100492639\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.3824308100492639 \n",
            "\n",
            "4 100 0.25843798349028135\n",
            "4 200 0.2555358919958465\n",
            "4 300 0.25651910617853324\n",
            "4 400 0.2624024319143163\n",
            "4 500 0.26082058408289294\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.26082058408289294 \n",
            "\n",
            "5 100 0.1614757084763551\n",
            "5 200 0.15864465507729197\n",
            "5 300 0.16054825967869626\n",
            "5 400 0.16473342785941336\n",
            "5 500 0.16414649785572483\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.16414649785572483 \n",
            "\n",
            "CPU times: user 5min 50s, sys: 777 ms, total: 5min 50s\n",
            "Wall time: 5min 53s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5124317667785041,\n",
              " 0.3824308100492639,\n",
              " 0.26082058408289294,\n",
              " 0.16414649785572483]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5RkMEMws99n"
      },
      "source": [
        "Estimativa com exponenciação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZle_Ydnb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12973d73-b17d-4aae-b484-c5939065992a"
      },
      "source": [
        "# exemplos de textos gerados\n",
        "print(\"Exemplos de textos gerados com base em SeqGAN com exponenciação\")\n",
        "degree = 1.5\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tExemplo: \", line, ' '*(100-len(line)), '\\tAvaliação: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos de textos gerados com base em SeqGAN com exponenciação\n",
            "Degree: 1.5\n",
            "# 0 \tExemplo:  A man takes a picture of a slice on top of a table .                                                  \tAvaliação:  [0.6649099662043687, 0.6046423508984526, 0.5492704080363613, 0.4906806884641922]\n",
            "# 1 \tExemplo:  A woman standing next to a man on a table with a kite .                                               \tAvaliação:  [0.6920602346769048, 0.6639509405734763, 0.6092033169091078, 0.5097976264749036]\n",
            "# 2 \tExemplo:  A boy is jumping in the air holding onto his surfboard .                                              \tAvaliação:  [0.5026246899500345, 0.347892817097899, 0.22308576866161578, 0.10913234729182814]\n",
            "# 3 \tExemplo:  A man standing in front of a TV with a laptop .                                                       \tAvaliação:  [0.5619514869490163, 0.5196828406118894, 0.4507482544534971, 0.40062241498668816]\n",
            "# 4 \tExemplo:  A group of uniformed people standing next to each other .                                             \tAvaliação:  [0.4588314677411235, 0.41247254393856775, 0.3584668928097086, 0.290362979195798]\n",
            "# 5 \tExemplo:  A group of people are sitting on the side of a large crowd .                                          \tAvaliação:  [0.6920602346769048, 0.6431887339803558, 0.6126355840680241, 0.5354658510115569]\n",
            "# 6 \tExemplo:  A blonde boy in a black living room with a checkered desk .                                           \tAvaliação:  [0.5231483637805969, 0.4236258116837369, 0.2585976536992378, 0.1228218593141609]\n",
            "# 7 \tExemplo:  A man in a purple sweater is playing baseball .                                                       \tAvaliação:  [0.3627381250550058, 0.2799056849071412, 0.18951629567590741, 0.0957840620111102]\n",
            "# 8 \tExemplo:  A group of people walking on top of a park bench .                                                    \tAvaliação:  [0.5893796917545019, 0.5579390770002352, 0.4496171332314307, 0.19118344596905382]\n",
            "# 9 \tExemplo:  A man standing on top of a boy in a white t - shirt .                                                 \tAvaliação:  [0.716350399411379, 0.6354387175256053, 0.46128925455321507, 0.3092820205492978]\n",
            "# 10 \tExemplo:  A young man is holding a wii remote while a man watches .                                             \tAvaliação:  [0.4701623459816272, 0.39451579566877026, 0.2915369229944523, 0.13518573171242573]\n",
            "# 11 \tExemplo:  A woman is holding a large piece of pizza .                                                           \tAvaliação:  [0.4588314677411235, 0.28599248869989347, 0.10830630507021792, 0.061220799289344076]\n",
            "# 12 \tExemplo:  A child sitting on a couch next to a flat screen TV .                                                 \tAvaliação:  [0.6134458325505882, 0.5005841126806674, 0.2930863323238684, 0.13576019603383874]\n",
            "# 13 \tExemplo:  A plate holds a wedding cake and whipped cream , on a table .                                         \tAvaliação:  [0.5848976518656018, 0.42362581168373686, 0.2585976536992378, 0.1228218593141609]\n",
            "# 14 \tExemplo:  A person is playing a game of Wii controller in front of a herd of doughnuts .                        \tAvaliação:  [0.6488856845230502, 0.45398477741721427, 0.27237593728146087, 0.1280297783563798]\n",
            "# 15 \tExemplo:  A man and woman are sitting on a table .                                                              \tAvaliação:  [0.4866642633922876, 0.4721631957086835, 0.419468515826214, 0.3570752508357733]\n",
            "# 16 \tExemplo:  A man looks on his board while standing next to a yellow fire hydrant .                               \tAvaliação:  [0.6589465276604692, 0.5527243880143493, 0.4940911248125205, 0.45083294673070695]\n",
            "# 17 \tExemplo:  A group of people riding a pair of skis in the snow .                                                 \tAvaliação:  [0.6407232755171874, 0.5424863881931092, 0.4402449689810936, 0.29794186008488804]\n",
            "# 18 \tExemplo:  A man standing next to a book shelf near the television .                                             \tAvaliação:  [0.5619514869490163, 0.44432257867347535, 0.3527295712700594, 0.28663914452183475]\n",
            "# 19 \tExemplo:  A person petting a baby elephant in a large room .                                                    \tAvaliação:  [0.4812265031857878, 0.37195938466682343, 0.2789439259471503, 0.2068185698600316]\n",
            "# 20 \tExemplo:  A man is standing on the beach next to a horse .                                                      \tAvaliação:  [0.5893796917545019, 0.5579390770002352, 0.49758315213471493, 0.40934810853757225]\n",
            "# 21 \tExemplo:  A plate with a sandwich and onion rings on top of it .                                                \tAvaliação:  [0.5848976518656018, 0.5104992364672556, 0.39143928185615157, 0.2712111425267761]\n",
            "# 22 \tExemplo:  A woman is holding a bat while standing in a row .                                                    \tAvaliação:  [0.5619514869490163, 0.49705875547910827, 0.346697783111003, 0.15528762763713394]\n",
            "# 23 \tExemplo:  A man and a woman sitting at a table talking in a living room .                                       \tAvaliação:  [0.6882472016116853, 0.6408240481696995, 0.5737416532455872, 0.4587471284873887]\n",
            "# 24 \tExemplo:  A young man in a suit tie holding a pizza .                                                           \tAvaliação:  [0.4812265031857878, 0.37195938466682343, 0.3087021994559367, 0.22428890077268346]\n",
            "# 25 \tExemplo:  A group of people standing on a beach near a beach .                                                  \tAvaliação:  [0.5104177855340404, 0.46618580376022084, 0.39293620890698494, 0.33888932982766257]\n",
            "# 26 \tExemplo:  A flat screen TV sitting on top of a couch .                                                          \tAvaliação:  [0.5380275868489703, 0.48284922775266165, 0.4464617303464354, 0.4157166269370052]\n",
            "# 27 \tExemplo:  A woman in a suit with a helmet and riding a tennis racket .                                          \tAvaliação:  [0.5848976518656018, 0.5104992364672556, 0.39143928185615157, 0.17112266228213385]\n",
            "# 28 \tExemplo:  A group of people standing around a table in a restaurant .                                           \tAvaliação:  [0.5893796917545019, 0.5778821454656745, 0.548958765126221, 0.508672234420547]\n",
            "# 29 \tExemplo:  A man holding a white frisbee in the middle of a street .                                             \tAvaliação:  [0.6134458325505882, 0.5509641073413446, 0.47094777718650466, 0.391722444087928]\n",
            "# 30 \tExemplo:  A group of people are sitting on a bench in front of a wooden table .                                 \tAvaliação:  [0.7947194142390263, 0.7890315913375405, 0.7673683363382612, 0.7043639186417306]\n",
            "# 31 \tExemplo:  A white plate holding a white and tan bowl of salad .                                                 \tAvaliação:  [0.4701623459816272, 0.3327475090445512, 0.12133158735615288, 0.06704325740058405]\n",
            "# 32 \tExemplo:  A man is sitting in a chair standing next to a building .                                             \tAvaliação:  [0.6134458325505882, 0.5730257633814818, 0.5076404185889566, 0.38355438962873406]\n",
            "# 33 \tExemplo:  A man in a blue shirt with a baseball bat .                                                           \tAvaliação:  [0.4812265031857878, 0.37195938466682343, 0.2789439259471503, 0.1304936956280769]\n",
            "# 34 \tExemplo:  A man is holding a tennis racket and a bat .                                                          \tAvaliação:  [0.4588314677411235, 0.3603279566248174, 0.27237593728146087, 0.20291352414933153]\n",
            "# 35 \tExemplo:  A boy is on the bottom of the waves of a baseball game .                                              \tAvaliação:  [0.5848976518656018, 0.45633707214217845, 0.2734337278147286, 0.12842739402168749]\n",
            "# 36 \tExemplo:  A group of people flying kites in the sky with a surf board .                                         \tAvaliação:  [0.6920602346769048, 0.6834900197659399, 0.6583197778046525, 0.5671781954589322]\n",
            "# 37 \tExemplo:  A man with a kite all looking in the distance .                                                       \tAvaliação:  [0.4812265031857878, 0.40068110080455893, 0.29494729140780945, 0.13644936951252412]\n",
            "# 38 \tExemplo:  A person relaxing on a table with a kitchen .                                                         \tAvaliação:  [0.40717253552297766, 0.35844138825363964, 0.27130567714631193, 0.20227541866575535]\n",
            "# 39 \tExemplo:  A train is on the tracks in a boat .                                                                  \tAvaliação:  [0.4588314677411235, 0.3603279566248174, 0.12879862858915844, 0.0703242314352732]\n",
            "# 40 \tExemplo:  A man with a white shirt sitting on a bench .                                                         \tAvaliação:  [0.5380275868489703, 0.5250407733778476, 0.4542291944311804, 0.3509150848958905]\n",
            "# 41 \tExemplo:  A cat sits on the floor and computer in the bed .                                                     \tAvaliação:  [0.5893796917545019, 0.5131038694945721, 0.42223743521617985, 0.288151836175237]\n",
            "# 42 \tExemplo:  A group of men on a beach with a bat .                                                                \tAvaliação:  [0.5380275868489703, 0.48284922775266165, 0.28526364391471365, 0.13285354392258636]\n",
            "# 43 \tExemplo:  A large train with lots of people in front of it .                                                    \tAvaliação:  [0.5619514869490163, 0.4721631957086834, 0.36917916399395617, 0.2588008802083805]\n",
            "# 44 \tExemplo:  A woman in tan dress sitting on a bench in front of a beach .                                         \tAvaliação:  [0.6882472016116853, 0.6408240481696995, 0.593218064069945, 0.5218449657024715]\n",
            "# 45 \tExemplo:  A view of a room with a hard wood sofa .                                                              \tAvaliação:  [0.4812265031857878, 0.42578720527948616, 0.3416351427096076, 0.2432349814809369]\n",
            "# 46 \tExemplo:  Two men are trying to play a game on a game .                                                         \tAvaliação:  [0.4812265031857878, 0.37195938466682343, 0.2345629473857563, 0.1136013602356153]\n",
            "# 47 \tExemplo:  A man holding a kite in a field with a few people .                                                   \tAvaliação:  [0.6407232755171874, 0.6109741448719966, 0.5326509505811611, 0.39859896596407934]\n",
            "# 48 \tExemplo:  A man holding a Wii controller and a woman holding a game remote .                                    \tAvaliação:  [0.5026246899500345, 0.41247254393856775, 0.33359103227594633, 0.2386423391385826]\n",
            "# 49 \tExemplo:  A man sitting on a bed next to a laptop .                                                             \tAvaliação:  [0.5380275868489703, 0.5250407733778476, 0.4940911248125205, 0.40704825447159776]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ATYRFjknb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd93f3d-60c2-4a22-8a0d-df441bd02bca"
      },
      "source": [
        "%%time\n",
        "print(\"Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com SeqGAN\")\n",
        "# controle de qualidade da educação\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avaliação da qualidade da geração de texto baseada em BLEU após treinamento com SeqGAN\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5549611905245981\n",
            "2 200 0.5656522528298974\n",
            "2 300 0.566306108313174\n",
            "2 400 0.5655395303058187\n",
            "2 500 0.5645866166564775\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5645866166564775 \n",
            "\n",
            "3 100 0.49315955473500955\n",
            "3 200 0.5038688095408669\n",
            "3 300 0.5032140960425149\n",
            "3 400 0.5015572251494816\n",
            "3 500 0.49865083503454527\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.49865083503454527 \n",
            "\n",
            "4 100 0.413040595201514\n",
            "4 200 0.4194801251658673\n",
            "4 300 0.4171087254822016\n",
            "4 400 0.41547211693344827\n",
            "4 500 0.4119848242411157\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.4119848242411157 \n",
            "\n",
            "5 100 0.3122351335296429\n",
            "5 200 0.31678152978945984\n",
            "5 300 0.3141256740663774\n",
            "5 400 0.3117888980796234\n",
            "5 500 0.307158973269923\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.307158973269923 \n",
            "\n",
            "CPU times: user 5min 41s, sys: 688 ms, total: 5min 42s\n",
            "Wall time: 5min 44s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5645866166564775,\n",
              " 0.49865083503454527,\n",
              " 0.4119848242411157,\n",
              " 0.307158973269923]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhrWW-2bKH9E"
      },
      "source": [
        "Carregando um modelo salvo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHsreqY23P-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d53ddc3-99d0-4017-b510-279973916d60"
      },
      "source": [
        "# carregando modelos\n",
        "[data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM,\n",
        " DIS_HIDDEN_DIM] = load_models(FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')#[seqgan_mle, seqgan_pretraining_dis, seqgan_adversarial_training]\n",
        "\n",
        "if(CUDA):\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_tensor_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state\n",
            "default_parameters\n",
            "data_file_tensor_train\n",
            "Generator\n",
            "Discriminator\n",
            "CUDA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0c1e57d4af32>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(name, map_location=device)\n",
            "<ipython-input-13-0c1e57d4af32>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_file_tensor_train = torch.tensor(state['data_file_tensor_train'])\n",
            "<ipython-input-35-d6ff76ccee68>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_file_tensor_train = torch.tensor(data_file_tensor_train).cuda()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxiSFluHn55b"
      },
      "source": [
        "Carregando um modelo salvo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWqjB09kjCHN"
      },
      "source": [
        "degree = 1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhYDh_ByyqIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12055499-6bfc-42af-8a89-756f2c468121"
      },
      "source": [
        "# plágio do conjunto de treinamento\n",
        "samples = gen.sample(1500, degree=degree).cpu().detach().numpy().tolist()\n",
        "# samples = data_file_test.tolist()[:500]\n",
        "train_samples = data_file_train.tolist()\n",
        "n = 0\n",
        "for i in range(len(samples)):\n",
        "  if samples[i] in train_samples:\n",
        "    n += 1\n",
        "  if i%(len(samples)//10) == 0:\n",
        "    print(i/len(samples)*100, \"%\")\n",
        "print(\"O número de exemplos gerados que corresponderam à amostra de treinamento: \", n, \"de\", len(samples))\n",
        "print(\"Plágio: \", n/len(samples)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 %\n",
            "10.0 %\n",
            "20.0 %\n",
            "30.0 %\n",
            "40.0 %\n",
            "50.0 %\n",
            "60.0 %\n",
            "70.0 %\n",
            "80.0 %\n",
            "90.0 %\n",
            "O número de exemplos gerados que corresponderam à amostra de treinamento:  10 de 1500\n",
            "Plágio:  0.6666666666666667 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOzmSGPN7Jc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e2cb4c-7d7a-4818-ef2e-0d3d672f7bd8"
      },
      "source": [
        "# originalidade dos exemplos\n",
        "N_samples = 1500\n",
        "samples_1 = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "samples_2 = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "\n",
        "n = 0\n",
        "for i in range(len(samples_1)):\n",
        "  if samples_1[i] in samples_2:\n",
        "    n += 1\n",
        "  if i%(len(samples_1)//10) == 0:\n",
        "    print(i/len(samples_1)*100, \"%\")\n",
        "\n",
        "print(\"Originalidade dos exemplos gerados\")\n",
        "print(\"O número de exemplos da amostra 1 correspondeu aos exemplos da amostra 2: \", n, \"de\", len(samples_1))\n",
        "print(\"Plágio: \", n/len(samples_1)*100, \"%\")\n",
        "print(\"Originalidade: \", (1-n/len(samples_1))*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 %\n",
            "10.0 %\n",
            "20.0 %\n",
            "30.0 %\n",
            "40.0 %\n",
            "50.0 %\n",
            "60.0 %\n",
            "70.0 %\n",
            "80.0 %\n",
            "90.0 %\n",
            "Originalidade dos exemplos gerados\n",
            "O número de exemplos da amostra 1 correspondeu aos exemplos da amostra 2:  24 de 1500\n",
            "Plágio:  1.6 %\n",
            "Originalidade:  98.4 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY0ev9FO94ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe6ef47-df9c-454e-e7af-2376ef24b433"
      },
      "source": [
        "# originalidade dos exemplos abordagem 2\n",
        "N_samples = 1500\n",
        "samples = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "\n",
        "i = 0\n",
        "n = 0\n",
        "while len(samples)>0:\n",
        "  if samples[0] not in samples[1:]:\n",
        "    n += 1\n",
        "  if i%(N_samples//10) == 0:\n",
        "    print(i/N_samples*100, \"%\")\n",
        "  del(samples[0])\n",
        "  i += 1\n",
        "\n",
        "print(\"Originalidade dos exemplos gerados\")\n",
        "print(\"Exemplos originais gerados: \", n, \"de\", N_samples)\n",
        "print(\"Originalidade: \", n/N_samples*100, \"%\")\n",
        "print(\"Plágio: \", (1-n/N_samples)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 %\n",
            "10.0 %\n",
            "20.0 %\n",
            "30.0 %\n",
            "40.0 %\n",
            "50.0 %\n",
            "60.0 %\n",
            "70.0 %\n",
            "80.0 %\n",
            "90.0 %\n",
            "Originalidade dos exemplos gerados\n",
            "Exemplos originais gerados:  1490 de 1500\n",
            "Originalidade:  99.33333333333333 %\n",
            "Plágio:  0.666666666666671 %\n"
          ]
        }
      ]
    }
  ]
}